#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import sqlite3
import sys
import time
import torch
from typing import Dict, List, Any, Optional
from robot_functions import RobotFunctions

# GPU ê°ì§€ ë° ìµœì í™” í•¨ìˆ˜
def check_gpu_availability():
    """GPU ì‚¬ìš© ê°€ëŠ¥ì„±ì„ ìì„¸íˆ í™•ì¸"""
    print("ğŸ” GPU í™˜ê²½ í™•ì¸ ì¤‘...")
    
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        total_memory = torch.cuda.get_device_properties(current_device).total_memory
        
        # ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        try:
            reserved_memory = torch.cuda.memory_reserved(current_device)
            free_memory = total_memory - reserved_memory
        except Exception as e:
            print(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
            reserved_memory = 0
            free_memory = total_memory
        
        print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥!")
        print(f"  ğŸ® GPU ê°œìˆ˜: {device_count}")
        print(f"  ğŸ® í˜„ì¬ GPU: {device_name}")
        print(f"  ğŸ’¾ ì´ ë©”ëª¨ë¦¬: {total_memory / 1024**3:.1f}GB")
        print(f"  ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥: {free_memory / 1024**3:.1f}GB")
        
        # CUDA ë²„ì „ í™•ì¸
        print(f"  ğŸ”§ CUDA ë²„ì „: {torch.version.cuda}")
        print(f"  ğŸ”§ PyTorch ë²„ì „: {torch.__version__}")
        
        return True, current_device
    else:
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€")
        print("  ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
        
        # CPU ì •ë³´
        print(f"  ğŸ”§ PyTorch ë²„ì „: {torch.__version__}")
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            print("  ğŸ MPS (Apple Silicon) ê°ì§€ë¨")
            return True, torch.device("mps")
        
        return False, torch.device("cpu")

class CustomStreamer:
    """ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¬ë¨¸"""
    
    def __init__(self, tokenizer, skip_prompt=True, skip_special_tokens=True, 
                 decode_kwargs=None, fast_mode=False, debug_mode=False):
        self.tokenizer = tokenizer
        self.skip_prompt = skip_prompt
        self.skip_special_tokens = skip_special_tokens
        self.decode_kwargs = decode_kwargs or {}
        self.token_cache = []
        self.print_len = 0
        self.current_length = 0
        self.fast_mode = fast_mode  # ë¹ ë¥¸ ëª¨ë“œ ì„¤ì •
        self.debug_mode = debug_mode  # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •

    def put(self, value):
        """ìƒˆë¡œìš´ í† í°ì„ ë°›ì„ ë•Œ í˜¸ì¶œë¨"""
        try:
            # ë””ë²„ê·¸ ì •ë³´
            if self.debug_mode:
                print(f"ğŸ” ìŠ¤íŠ¸ë¦¬ë¨¸ ì…ë ¥: shape={value.shape}, dim={value.dim()}")
            
            # í…ì„œ ì°¨ì› ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            if value.dim() == 0:
                # ìŠ¤ì¹¼ë¼ë¥¼ 1ì°¨ì› í…ì„œë¡œ ë³€í™˜
                value = value.unsqueeze(0)
            elif value.dim() == 1:
                # 1ì°¨ì› í…ì„œë¥¼ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜ (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
                value = value.unsqueeze(0)
            
            # ë°°ì¹˜ í¬ê¸° í™•ì¸
            if value.shape[0] > 1:
                if self.debug_mode:
                    print(f"âš ï¸ ë°°ì¹˜ í¬ê¸° {value.shape[0]} ë¬´ì‹œë¨")
                return

            # ë¹ˆ í…ì„œ ì²´í¬
            if value.numel() == 0:
                if self.debug_mode:
                    print("âš ï¸ ë¹ˆ í…ì„œ ë¬´ì‹œë¨")
                return
            
            # í…ì„œ ìœ íš¨ì„± ì²´í¬
            if not torch.is_tensor(value):
                if self.debug_mode:
                    print("âš ï¸ í…ì„œê°€ ì•„ë‹Œ ê°ì²´ ë¬´ì‹œë¨")
                return
                
            # í† í° ì‹œí€€ìŠ¤ ì¶”ì¶œ
            token_sequence = value[0].tolist()
            
            if self.debug_mode:
                print(f"ğŸ” í† í° ì‹œí€€ìŠ¤ ê¸¸ì´: {len(token_sequence)}, í˜„ì¬ ê¸¸ì´: {self.current_length}")
            
            # í”„ë¡¬í”„íŠ¸ ê±´ë„ˆë›°ê¸° ë¡œì§ (ê°„ì†Œí™”)
            if self.skip_prompt and len(token_sequence) <= 1:
                # ì²« ë²ˆì§¸ í† í°ë§Œ ê±´ë„ˆë›°ê¸° (í”„ë¡¬í”„íŠ¸ ì‹œì‘ í† í°)
                if self.debug_mode:
                    print(f"ğŸ” ì²« ë²ˆì§¸ í† í° ê±´ë„ˆë›°ê¸°: {token_sequence}")
                return
                
            # ìƒˆë¡œìš´ í† í° ì²˜ë¦¬ (ê°„ì†Œí™”)
            if len(token_sequence) > 0:
                # ëª¨ë“  í† í°ì„ ìºì‹œì— ì¶”ê°€
                self.token_cache.extend(token_sequence)
                
                if self.debug_mode:
                    print(f"ğŸ” í† í° ìºì‹œì— ì¶”ê°€: {len(token_sequence)}ê°œ í† í°")
                    print(f"ğŸ” ì´ ìºì‹œ ê¸¸ì´: {len(self.token_cache)}")
                
                # ì „ì²´ í† í° ìºì‹œë¥¼ ë””ì½”ë”©
                try:
                    text = self.tokenizer.decode(self.token_cache, skip_special_tokens=self.skip_special_tokens)
                    
                    # ì¶œë ¥ ê°€ëŠ¥í•œ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    if len(text) > self.print_len:
                        new_text = text[self.print_len:]
                        self.print_len = len(text)
                        
                        if self.debug_mode:
                            print(f"ğŸ” ì¶œë ¥í•  í…ìŠ¤íŠ¸: '{new_text}'")
                        
                        # ì¦‰ì‹œ ì¶œë ¥ (ë²„í¼ë§ ì—†ì´)
                        print(new_text, end='', flush=True)
                        
                        # ë¹ ë¥¸ ëª¨ë“œì— ë”°ë¥¸ ì§€ì—°ì‹œê°„ ì¡°ì •
                        if self.fast_mode:
                            time.sleep(0.001)  # ë” ë¹ ë¥¸ ì¶œë ¥
                        else:
                            time.sleep(0.002)  # ì¼ë°˜ ì†ë„
                        
                except Exception as e:
                    if self.debug_mode:
                        print(f"âš ï¸ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                    pass
                    
        except Exception as e:
            # ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            if self.debug_mode:
                print(f"âš ï¸ ìŠ¤íŠ¸ë¦¬ë¨¸ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            pass

    def end(self):
        """ìƒì„±ì´ ëë‚¬ì„ ë•Œ í˜¸ì¶œë¨"""
        print()  # ë§ˆì§€ë§‰ì— ê°œí–‰ ì¶”ê°€
        sys.stdout.flush()

class RobotSystem:
    def __init__(self, db_path: str = "hospital.db", use_real_model: bool = False, 
                 model_name: str = "LGAI-EXAONE/EXAONE-4.0-1.2B", use_reasoning: bool = False, 
                 debug_mode: bool = False, fast_mode: bool = False):
        self.robot_functions = RobotFunctions(db_path)
        self.conversation_history: List[Dict[str, str]] = []
        self.use_real_model = use_real_model
        self.use_reasoning = use_reasoning  # Reasoning ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        self.fast_mode = fast_mode  # ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ
        
        # ë§¥ë½ íŒŒì•…ì„ ìœ„í•œ ì´ì „ ì§ˆë¬¸ ì¶”ì 
        self.last_user_question = ""
        self.last_response = ""
        
        # ë””ë²„ê¹… ëª¨ë“œ ì„¤ì •
        self.debug_mode = debug_mode
        
        # ëª¨ë¸ ì„¤ì • ì €ì¥
        self.model_name = model_name
        
        # GPU í™˜ê²½ í™•ì¸
        self.gpu_available, self.device = check_gpu_availability()
        
        # ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ ì„¤ì •
        if fast_mode:
            print("âš¡ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ í™œì„±í™”!")
            print("  - ë” ì§§ì€ ì‘ë‹µ ìƒì„± (1024 vs 2048 í† í°)")
            print("  - EXAONE 4.0 ê³µì‹ ê¶Œì¥ê°’ ìœ ì§€")
            print("  - ìµœì†Œ ìŠ¤íŠ¸ë¦¬ë° ì§€ì—°ì‹œê°„ (0.001ì´ˆ)")
        
        # ì‹¤ì œ EXAONE ëª¨ë¸ ì‚¬ìš© ì‹œ
        if use_real_model:
            self._init_exaone_model()
    
    def debug_print(self, message: str):
        """ë””ë²„ê¹… ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥"""
        if self.debug_mode:
            print(message)
    
    def _init_exaone_model(self):
        """ê°„ë‹¨í•œ EXAONE ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            
            print(f"ğŸ”„ {self.model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            print("ğŸ“ í† í¬ë‚˜ì´ì € ë¡œë”©...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )
            
            # ëª¨ë¸ ë¡œë“œ (ê°„ë‹¨í•œ ë°©ì‹)
            print("ğŸ¤– ëª¨ë¸ ë¡œë”©...")
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )
            
            # GPUë¡œ ì´ë™ (ê°€ëŠ¥í•œ ê²½ìš°)
            if self.gpu_available:
                self.model = self.model.to('cuda')
                print("âœ… GPUë¡œ ëª¨ë¸ ì´ë™ ì™„ë£Œ")
            else:
                self.model = self.model.to('cpu')
                print("âœ… CPUë¡œ ëª¨ë¸ ì´ë™ ì™„ë£Œ")
            
            # í† í¬ë‚˜ì´ì € ì„¤ì •
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜...")
            self.use_real_model = False
    
    def add_to_history(self, role: str, content: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€"""
        self.conversation_history.append({
            "role": role,
            "content": content
        })
        
        # íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì •ë¦¬ (ìµœê·¼ 12ê°œ ëŒ€í™”ë§Œ ìœ ì§€ - ë§¥ë½ ê°•í™”)
        if len(self.conversation_history) > 24:
            self.conversation_history = self.conversation_history[-24:]
    
    def get_function_prompt(self, user_input: str) -> str:
        """ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return user_input
    
    def get_contextual_function_prompt(self, contextual_input: str) -> str:
        """ë‹¨ìˆœí™”ëœ ë§¥ë½ í”„ë¡¬í”„íŠ¸ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return contextual_input
    
    def get_response_prompt(self, user_input: str, function_result: str) -> str:
        """ë‹¨ìˆœí™”ëœ ì‘ë‹µ í”„ë¡¬í”„íŠ¸ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return function_result
    
    def _should_use_reasoning(self, user_input: str) -> bool:
        """ë³µì¡í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì—¬ Reasoning ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        user_lower = user_input.lower()
        
        # ë³µì¡í•œ ì§ˆë¬¸ íŒ¨í„´ë“¤
        reasoning_patterns = [
            # "ì™œ", "ì–´ë–»ê²Œ", "ë¬´ì—‡ ë•Œë¬¸ì—" ë“±ì˜ ì§ˆë¬¸
            "ì™œ", "ì–´ë–»ê²Œ", "ë¬´ì—‡ ë•Œë¬¸ì—", "ì–´ë–¤ ì´ìœ ë¡œ",
            # ë¹„êµ ì§ˆë¬¸
            "ì°¨ì´ì ", "ë‹¤ë¥¸ ì ", "ë¹„êµ", "ì–´ë–¤ ê²ƒì´",
            # ì„¤ëª… ìš”ì²­
            "ì„¤ëª…í•´", "ì•Œë ¤ì¤˜", "ì´ìœ ê°€", "ì›ì¸ì´",
            # ë³µí•©ì ì¸ ì§ˆë¬¸
            "ê°€ì¥ ì¤‘ìš”í•œ", "ê°€ì¥ ì¢‹ì€", "ì–´ë–¤ ê²ƒì´ ë”",
            # ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸
            "ë§Œì•½", "ë§Œì•½ì—", "ê°€ì •í•´ë³´ë©´", "ìƒê°í•´ë³´ë©´",
            # ë¶„ì„ ìš”ì²­
            "ë¶„ì„", "ê²€í† ", "ê³ ë ¤", "ìƒê°í•´ë³´ë©´",
            # ìˆ«ì + ë¬¸ì œ (ì˜ˆ: "3ë²ˆ ë¬¸ì œ")
            "ë²ˆ ë¬¸ì œ", "ë²ˆì§¸ ë¬¸ì œ", "ë¬¸ì œ ê°™ì•„"
        ]
        
        # ë³µì¡í•œ ì§ˆë¬¸ íŒ¨í„´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        for pattern in reasoning_patterns:
            if pattern in user_lower:
                return True
        
        # ì§ˆë¬¸ ê¸¸ì´ê°€ ê¸¸ë©´ ë³µì¡í•  ê°€ëŠ¥ì„±
        if len(user_input) > 30:
            return True
            
        return False
    
    def _is_context_related(self, user_input: str) -> bool:
        """í˜„ì¬ ì§ˆë¬¸ì´ ì´ì „ ì§ˆë¬¸ê³¼ ì—°ê´€ì„±ì´ ìˆëŠ”ì§€ íŒë‹¨"""
        if not self.last_user_question:
            return False
            
        user_lower = user_input.lower()
        last_question_lower = self.last_user_question.lower()
        
        # ë§¥ë½ ì—°ê´€ì„± íŒ¨í„´ë“¤
        context_patterns = [
            # ìˆ«ì + ë¬¸ì œ (ì˜ˆ: "3ë²ˆ ë¬¸ì œ")
            "ë²ˆ ë¬¸ì œ", "ë²ˆì§¸ ë¬¸ì œ", "ë¬¸ì œ ê°™ì•„",
            # ë‹¨ê³„ë³„ ì§ˆë¬¸
            "ë‹¨ê³„", "ë‹¨ê³„ê°€", "ë‹¨ê³„ëŠ”",
            # ì¶”ê°€ ì§ˆë¬¸
            "ê·¸ë¦¬ê³ ", "ë˜í•œ", "ì¶”ê°€ë¡œ", "ë”",
            # êµ¬ì²´í™”
            "êµ¬ì²´ì ìœ¼ë¡œ", "ìì„¸íˆ", "ì˜ˆë¥¼ ë“¤ì–´",
            # í™•ì¸
            "ë§ë‚˜", "ë§ì•„", "ê·¸ë˜", "ë„¤",
            # ë°˜ëŒ€
            "ì•„ë‹ˆ", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ",
            # ì´í•´ ê´€ë ¨
            "ì´í•´ê°€", "ì´í•´ê°€ ì•ˆ", "ì˜ ì´í•´", "ëª¨ë¥´ê² ì–´",
            # ë‹¨ì–´ ê´€ë ¨
            "ë‹¨ì–´", "ìš©ì–´", "ë§ì´"
        ]
        
        # íŒ¨í„´ ë§¤ì¹­
        for pattern in context_patterns:
            if pattern in user_lower:
                return True
        
        # í‚¤ì›Œë“œ ì—°ê´€ì„± í™•ì¸
        common_keywords = ["ct", "x-ray", "xray", "ì˜ìƒ", "ê²€ì‚¬", "ì¥ë¹„", "ë¬¸ì œ", "ë‹¨ê³„", "ì´í•´", "ì„¤ëª…", "ëª¨ë¥´ê² ì–´", "ì•Œë ¤ì¤˜"]
        current_keywords = [kw for kw in common_keywords if kw in user_lower]
        last_keywords = [kw for kw in common_keywords if kw in last_question_lower]
        
        if current_keywords and last_keywords:
            print(f"ğŸ” í‚¤ì›Œë“œ ì—°ê´€ì„± ë°œê²¬: {current_keywords} â†” {last_keywords}")
            return True
        
        # ì¶”ê°€: ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì¶”ê°€ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        follow_up_patterns = [
            "ìì„¸íˆ", "êµ¬ì²´ì ìœ¼ë¡œ", "ë”", "ì¶”ê°€ë¡œ", "ê·¸ë¦¬ê³ ", "ë˜í•œ",
            "ì„¤ëª…í•´", "ì•Œë ¤ì¤˜", "ëª¨ë¥´ê² ì–´", "ì´í•´ê°€ ì•ˆ", "ì˜ ëª¨ë¥´ê² ì–´",
            "ë„ˆê°€", "ë‹¹ì‹ ì´", "ë¡œë´‡ì´", "ì˜ì›…ì´ê°€", "ë§í•œ", "ì„¤ëª…í•œ"
        ]
        
        for pattern in follow_up_patterns:
            if pattern in user_lower:
                print(f"ğŸ” í›„ì† ì§ˆë¬¸ íŒ¨í„´ ë°œê²¬: '{pattern}'")
                return True
            
        return False

    def process_user_input(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ - ìë™ ëª¨ë“œ ì „í™˜ í¬í•¨"""
        # íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        self.add_to_history("ì‚¬ìš©ì", user_input)
        
        # ë§¥ë½ íŒŒì•…: ì´ì „ ì§ˆë¬¸ê³¼ ì—°ê´€ì„± í™•ì¸
        context_related = self._is_context_related(user_input)
        self.debug_print(f"ğŸ” ë§¥ë½ ë¶„ì„: '{user_input}'")
        self.debug_print(f"ğŸ” ì´ì „ ì§ˆë¬¸: '{self.last_user_question}'")
        self.debug_print(f"ğŸ” ë§¥ë½ ì—°ê´€ì„±: {context_related}")
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if not self.last_user_question:
            self.debug_print("ğŸ†• ì²« ë²ˆì§¸ ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹")
            context_related = False
        
        try:
            if self.use_real_model:
                # ìë™ìœ¼ë¡œ ë³µì¡í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
                should_reasoning = self._should_use_reasoning(user_input)
                
                if should_reasoning and not self.use_reasoning:
                    self.debug_print("ğŸ§  ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€! Reasoning ëª¨ë“œë¡œ ìë™ ì „í™˜")
                    self.use_reasoning = True
                elif not should_reasoning and self.use_reasoning:
                    self.debug_print("ğŸ’¬ ì¼ë°˜ ì§ˆë¬¸ ê°ì§€! Non-reasoning ëª¨ë“œë¡œ ìë™ ì „í™˜")
                    self.use_reasoning = False
                
                # ë§¥ë½ ì •ë³´ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                if context_related and self.last_user_question:
                    self.debug_print(f"ğŸ”— ë§¥ë½ ì—°ê´€ì„± ê°ì§€: '{self.last_user_question}' â†’ '{user_input}'")
                    # ì´ì „ ì§ˆë¬¸ì„ ì°¸ì¡°í•˜ëŠ” ë§¥ë½ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                    contextual_input = f"""ì´ì „ ëŒ€í™” ë§¥ë½:
ì‚¬ìš©ì: {self.last_user_question}
ì˜ì›…ì´: {self.last_response}

í˜„ì¬ ì§ˆë¬¸: {user_input}

ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì—°ê´€ëœ ì§ˆë¬¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 
ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ í˜„ì¬ ì§ˆë¬¸ì— ì ì ˆíˆ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë§Œì•½ ì‚¬ìš©ìê°€ "ë„ˆê°€ ì„¤ëª…í•œ", "ë‹¹ì‹ ì´ ë§í•œ" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´,
ì´ì „ ëŒ€í™”ì—ì„œ ìì‹ ì´ ì„¤ëª…í•œ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    self.debug_print(f"ğŸ“ ë§¥ë½ í”„ë¡¬í”„íŠ¸ ìƒì„±: {contextual_input[:100]}...")
                else:
                    contextual_input = user_input
                    self.debug_print(f"ğŸ“ ì¼ë°˜ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {contextual_input}")
                
                self.debug_print(f"ğŸ¯ ìµœì¢… ì…ë ¥: {contextual_input[:50]}...")
                
                # ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
                if self.use_reasoning:
                    # Reasoning ëª¨ë“œ (<think> ë¸”ë¡ ì‚¬ìš©)
                    response = self._call_real_exaone_reasoning(contextual_input)
                else:
                    # Non-reasoning ëª¨ë“œ (Agentic tool use)
                    response = self._call_real_exaone_simple(contextual_input)
            else:
                # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
                response = self._simple_simulation(user_input)
            
            # íˆìŠ¤í† ë¦¬ì— ì‘ë‹µ ì¶”ê°€
            self.add_to_history("ì˜ì›…ì´", response)
            
            # ì´ì „ ì§ˆë¬¸ê³¼ ì‘ë‹µ ì¶”ì  ì—…ë°ì´íŠ¸
            self.last_user_question = user_input
            self.last_response = response
            
            return response
            
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return "ì–´ë¨¸, ì˜ì›…ì´ê°€ ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”! ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
    
    def _call_real_exaone_simple(self, user_input: str) -> str:
        """ëŒ€í­ ê°œì„ ëœ Agentic tool use - ë§¥ë½ ì¸ì‹ê³¼ í•¨ìˆ˜ ì„ íƒ ê°œì„ """
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë§¥ë½ êµ¬ì„±
            conversation_context = ""
            if len(self.conversation_history) > 1:
                # ìµœê·¼ 4ê°œ ëŒ€í™”ë§Œ í¬í•¨ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ)
                recent_history = self.conversation_history[-8:]  # 4ìŒì˜ ëŒ€í™”
                context_items = []
                for entry in recent_history:
                    context_items.append(f"{entry['role']}: {entry['content']}")
                conversation_context = "\n".join(context_items)
            
            # tools ì •ì˜ (ê³µì‹ ë¬¸ì„œ ë°©ì‹)
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "query_facility",
                        "description": "ë³‘ì› ë‚´ ì‹œì„¤ì˜ ìœ„ì¹˜ë¥¼ ì¡°íšŒí•  ë•Œ ì‚¬ìš©. 'ì–´ë””ì•¼', 'ìœ„ì¹˜', 'ì°¾ì•„' ë“±ì˜ ì§ˆë¬¸ì— ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["facility"],
                            "properties": {
                                "facility": {
                                    "type": "string",
                                    "description": "ì¡°íšŒí•  ì‹œì„¤ëª… (CT, X-ray, ì´ˆìŒíŒŒ, íì•”, ìœ„ì•”, ëŒ€ì¥ì•”, ìœ ë°©ì•”, ë‡Œì¢…ì–‘ ë“±)"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function", 
                    "function": {
                        "name": "navigate",
                        "description": "ì‚¬ìš©ìë¥¼ íŠ¹ì • ìœ„ì¹˜ë¡œ ì•ˆë‚´í•  ë•Œ ì‚¬ìš©. 'ì•ˆë‚´í•´ì¤˜', 'ë°ë ¤ë‹¤ì¤˜', 'ë™í–‰í•´ì¤˜', 'ê°€ì' ë“±ì˜ ìš”ì²­ì— ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["target"],
                            "properties": {
                                "target": {
                                    "type": "string",
                                    "description": "ì•ˆë‚´í•  ëª©ì ì§€"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "start_registration",
                        "description": "ì ‘ìˆ˜ë‚˜ ì˜ˆì•½ í™•ì¸ì„ ìš”ì²­í•  ë•Œ ì‚¬ìš©. 'ì ‘ìˆ˜', 'ì ‘ìˆ˜í•˜ë ¤ë©´', 'ì˜ˆì•½ í™•ì¸', 'ì˜ˆì•½ ë‚´ì—­', 'ì˜ˆì•½ ì •ë³´' ë“±ì˜ ìš”ì²­ì— ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": [],
                            "properties": {}
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "general_response",
                        "description": "ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ì¸ì‚¬, ì„¤ëª…ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["message"],
                            "properties": {
                                "message": {
                                    "type": "string",
                                    "description": "ì‚¬ìš©ìì˜ ë©”ì‹œì§€"
                                }
                            }
                        }
                    }
                }
            ]
            
            # ê°œì„ ëœ ì§€ì‹œì‚¬í•­ê³¼ ë§¥ë½ì„ í¬í•¨í•œ ë©”ì‹œì§€
            system_prompt = f"""ë‹¹ì‹ ì€ ë³‘ì› ì•ˆë‚´ ë¡œë´‡ì…ë‹ˆë‹¤. ì´ë¦„ì€ 'ì˜ì›…ì´'ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ì¤‘ìš”í•œ ê·œì¹™:
1. ìœ„ì¹˜ ì§ˆë¬¸('ì–´ë””ì•¼', 'ì–´ë””ìˆì–´', 'ì°¾ì•„')ì€ query_facility ì‚¬ìš©
2. ì´ë™ ìš”ì²­('ì•ˆë‚´í•´ì¤˜', 'ë°ë ¤ë‹¤ì¤˜', 'ë™í–‰í•´ì¤˜', 'ê°€ì', 'ê°€ì ¸ë‹¤ì¤˜')ì€ navigate ì‚¬ìš©  
3. ì ‘ìˆ˜/ì˜ˆì•½ ìš”ì²­('ì ‘ìˆ˜', 'ì ‘ìˆ˜í•˜ë ¤ë©´', 'ì˜ˆì•½ í™•ì¸', 'ì˜ˆì•½ ë‚´ì—­', 'ì˜ˆì•½ ì •ë³´')ì€ start_registration ì‚¬ìš©
4. ì¼ë°˜ ëŒ€í™”('ì•ˆë…•', 'ê³ ë§ˆì›Œ', 'ë­ì•¼')ëŠ” general_response ì‚¬ìš©
5. ì‘ë‹µì€ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ (ê¸¸ê³  í˜„í•™ì ì¸ ë‹µë³€ ê¸ˆì§€)
6. ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì´ì „ ì–¸ê¸‰ëœ ì¥ì†Œë¥¼ ê¸°ì–µí•˜ì„¸ìš”

{f"ì´ì „ ëŒ€í™” ë§¥ë½:{conversation_context}" if conversation_context else ""}

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"""
            
            # ê³µì‹ ë¬¸ì„œ ë°©ì‹ìœ¼ë¡œ ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "user", "content": system_prompt}]
            
            # ê³µì‹ ë¬¸ì„œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            input_ids = self.tokenizer.apply_chat_template(
                messages,
                tokenize=True,
                add_generation_prompt=True,
                return_tensors="pt",
                tools=tools,
            )
            
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ê°œì„ ëœ ìƒì„± ë¡œì§
            print(f"ğŸ¤– {'ğŸ§  Reasoning' if self.use_reasoning else 'ğŸ’¬'} ëª¨ë“œë¡œ ì‹¤ì‹œê°„ ë‹µë³€ ì¤‘:", end=" ", flush=True)
            
            # TextIteratorStreamer ê°•ì œ ì‚¬ìš© (ì„œë²„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•´)
            from transformers import TextIteratorStreamer
            from threading import Thread
            
            streamer = TextIteratorStreamer(
                self.tokenizer,
                skip_prompt=True,
                skip_special_tokens=True
            )
            
            # ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì • (EXAONE 4.0 ê³µì‹ ê¶Œì¥ê°’ ì¤€ìˆ˜)
            if self.fast_mode:
                # ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ (ê³µì‹ ê¶Œì¥ê°’ ê¸°ë°˜ + ìµœì í™”)
                max_tokens = 1024  # ë” ì§§ì€ ì‘ë‹µ
                temperature = 0.6 if self.use_reasoning else 0.1  # ê³µì‹ ê¶Œì¥ê°’ ìœ ì§€
                top_p = 0.95  # ê³µì‹ ê¶Œì¥ê°’ ê³ ì •
            else:
                # ì¼ë°˜ ëª¨ë“œ ì„¤ì • (EXAONE 4.0 ê³µì‹ ê¶Œì¥ê°’)
                max_tokens = 2048
                temperature = 0.6 if self.use_reasoning else 0.1  # ê³µì‹ ê¶Œì¥ê°’
                top_p = 0.95  # ê³µì‹ ê¶Œì¥ê°’ ê³ ì •
            
            generation_kwargs = {
                "input_ids": input_ids.to(self.model.device),
                "max_new_tokens": max_tokens,
                "do_sample": True,
                "temperature": temperature,
                "top_p": top_p,
                "repetition_penalty": 1.1,
                "pad_token_id": self.tokenizer.pad_token_id,
                "eos_token_id": self.tokenizer.eos_token_id,
                "attention_mask": None,
                "streamer": streamer,  # ìŠ¤íŠ¸ë¦¬ë¨¸ ì‚¬ìš©
            }
            
            # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
            if hasattr(streamer, '__iter__'):  # TextIteratorStreamerì¸ ê²½ìš°
                # ìŠ¤ë ˆë“œ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° (ì‘ë™í•˜ëŠ” ë°©ì‹)
                thread = Thread(target=self.model.generate, kwargs=generation_kwargs)
                thread.start()
                
                # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ë° í•¨ìˆ˜ í˜¸ì¶œ ê°ì§€
                full_streamed_text = ""
                for text in streamer:
                    print(text, end="", flush=True)
                    full_streamed_text += text
                
                thread.join()  # ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬
                if "<tool_call>" in full_streamed_text:
                    print("\nğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ í˜•ì‹ ê°ì§€ë¨")
                    function_result = self._parse_and_execute_tool_call_improved(full_streamed_text, user_input)
                    print(f"ğŸ¤– ë‹µë³€: {function_result}")
                    return function_result
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                    if full_streamed_text.strip() and "Available Tools" not in full_streamed_text:
                        return full_streamed_text.strip()
                    else:
                        print("\nâŒ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                        fallback_result = self._fallback_response(user_input)
                        print(f"ğŸ¤– ë‹µë³€: {fallback_result}")
                        return fallback_result
            # TextIteratorStreamerë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ else ë¸”ë¡ ì œê±°
            
            # ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (ì´ë¯¸ ì¶œë ¥ë¨)
            return ""
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_response(user_input)
    
    def _generate_simple_response(self, user_input: str) -> str:
        """ë§¥ë½ì„ ê³ ë ¤í•œ ê°„ë‹¨í•œ ìì—°ì–´ ì‘ë‹µ ìƒì„±"""
        user_lower = user_input.lower().strip()
        
        # ë§¥ë½ì—ì„œ ìµœê·¼ ì–¸ê¸‰ëœ ì‹œì„¤ ì°¾ê¸°
        recent_facility = self._extract_recent_facility()
        
        # ì¸ì‚¬ë§
        if any(word in user_lower for word in ["ì•ˆë…•", "hello", "hi"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë³‘ì› ì•ˆë‚´ ë¡œë´‡ ì˜ì›…ì´ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        
        # ê°ì‚¬ ì¸ì‚¬
        elif any(word in user_lower for word in ["ê³ ë§ˆ", "ê°ì‚¬", "thank"]):
            return "ì²œë§Œì—ìš”! ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        
        # ë¡œë´‡ ì •ë³´ ì§ˆë¬¸
        elif any(word in user_lower for word in ["ëˆ„êµ¬", "ì´ë¦„", "ë­ì•¼", "ë­”ê°€", "ì •ì²´"]):
            return "ì €ëŠ” ë³‘ì› ì•ˆë‚´ ë¡œë´‡ ì˜ì›…ì´ì…ë‹ˆë‹¤. ë³‘ì› ì‹œì„¤ ì•ˆë‚´ì™€ ê¸¸ì°¾ê¸°ë¥¼ ë„ì™€ë“œë ¤ìš”!"
        
        # ë§¥ë½ ê¸°ë°˜ ì‘ë‹µ
        elif recent_facility and any(word in user_lower for word in ["ê·¸ê³³", "ê±°ê¸°", "ê·¸ ê³³", "ê·¸ê±°", "ê·¸ ì‹œì„¤"]):
            return f"ë„¤, {recent_facility} ë§ì”€ì´ì‹œì£ ? ë” ìì„¸í•œ ì•ˆë‚´ê°€ í•„ìš”í•˜ì‹œë‚˜ìš”?"
        
        # ê¸°ë³¸ ì‘ë‹µ
        else:
            return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë³‘ì› ì‹œì„¤ ì•ˆë‚´ë‚˜ ìœ„ì¹˜ ì¡°íšŒë¥¼ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”."
    
    def _extract_recent_facility(self) -> Optional[str]:
        """ëŒ€í™” ë§¥ë½ì—ì„œ ìµœê·¼ ì–¸ê¸‰ëœ ì‹œì„¤ëª… ì¶”ì¶œ"""
        if len(self.conversation_history) == 0:
            return None
            
        # ìµœê·¼ 6ê°œ ëŒ€í™”ì—ì„œ ì‹œì„¤ëª… ì°¾ê¸°
        for entry in reversed(self.conversation_history[-6:]):
            content = entry['content'].lower()
            # ì‹œì„¤ëª… ì§ì ‘ ë§¤ì¹­
            facilities = {
                'ct': 'CT', 'x-ray': 'X-ray', 'ì—‘ìŠ¤ë ˆì´': 'X-ray', 'xray': 'X-ray',
                'ì´ˆìŒíŒŒ': 'ì´ˆìŒíŒŒ', 'íì•”': 'íì•”', 'ìœ„ì•”': 'ìœ„ì•”', 'ëŒ€ì¥ì•”': 'ëŒ€ì¥ì•”', 
                'ìœ ë°©ì•”': 'ìœ ë°©ì•”', 'ë‡Œì¢…ì–‘': 'ë‡Œì¢…ì–‘', 'ì‹œí‹°': 'CT', 'ì”¨í‹°': 'CT'
            }
            
            for key, facility in facilities.items():
                if key in content:
                    return facility
                    
        return None

    def _parse_and_execute_tool_call_improved(self, response: str, user_input: str) -> str:
        """ê°œì„ ëœ í•¨ìˆ˜ í˜¸ì¶œ íŒŒì‹± ë° ì‹¤í–‰"""
        try:
            import re
            import json
            
            # <tool_call> íƒœê·¸ì—ì„œ JSON ì¶”ì¶œ
            tool_call_pattern = r'<tool_call>\s*({[^<]*})\s*</tool_call>'
            matches = re.findall(tool_call_pattern, response, re.DOTALL)
            
            print(f"ğŸ” ì°¾ì€ í•¨ìˆ˜ í˜¸ì¶œ: {len(matches)}ê°œ")
            
            for match in matches:
                tool_call_json = match.strip()
                print(f"ğŸ” ê²€ì‚¬ ì¤‘ì¸ JSON: {tool_call_json}")
                
                # ì˜ˆì‹œ í…ìŠ¤íŠ¸ ë¬´ì‹œ
                if any(placeholder in tool_call_json for placeholder in [
                    "function_1_name", "argument_1_name", "function_2_name", "argument_2_name"
                ]):
                    print("âŒ ì˜ˆì‹œ í…ìŠ¤íŠ¸ ë¬´ì‹œ")
                    continue
                
                try:
                    tool_call = json.loads(tool_call_json)
                    function_name = tool_call.get("name")
                    arguments = tool_call.get("arguments", {})
                    
                    print(f"ğŸ”§ ì‹¤í–‰í•  í•¨ìˆ˜: {function_name}({arguments})")
                    
                    if function_name == "query_facility":
                        facility = arguments.get("facility", "")
                        result = self.robot_functions.query_facility(facility)
                        
                        if "error" not in result["result"]:
                            return f"ë„¤! {facility}ëŠ” {result['result']}ì— ìˆì–´ìš”. ğŸ˜Š"
                        else:
                            return f"ì£„ì†¡í•´ìš”, {facility}ëŠ” ì´ ë³‘ì›ì— ì—†ëŠ” ì‹œì„¤ì´ì—ìš”. ë‹¤ë¥¸ ì‹œì„¤ì„ ì°¾ì•„ë“œë¦´ê¹Œìš”?"
                    
                    elif function_name == "navigate":
                        target = arguments.get("target", "")
                        
                        # ë§Œì•½ targetì´ ìœ„ì¹˜ ì„¤ëª…ì´ë©´ ë§¥ë½ì—ì„œ ì‹¤ì œ ì‹œì„¤ëª… ì°¾ê¸°
                        if any(word in target for word in ["ì™¼ìª½", "ì˜¤ë¥¸ìª½", "ì¤‘ì•™", "ìƒë‹¨", "í•˜ë‹¨", "ì˜ìƒì˜í•™ê³¼", "ì•”ì„¼í„°"]):
                            recent_facility = self._extract_recent_facility()
                            if recent_facility:
                                print(f"ğŸ¯ ë§¥ë½ì—ì„œ ì¶”ì¶œí•œ ì‹œì„¤: {recent_facility}")
                                target = recent_facility
                            else:
                                return "ì–´ë–¤ ì‹œì„¤ë¡œ ì•ˆë‚´í•´ë“œë¦´ê¹Œìš”? êµ¬ì²´ì ì¸ ì‹œì„¤ëª…ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
                        
                        result = self.robot_functions.navigate(target)
                        
                        if "error" not in result.get("result", ""):
                            return f"ì¢‹ì•„ìš”! {target}ë¡œ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”. ì €ë¥¼ ë”°ë¼ì˜¤ì„¸ìš”! ğŸš€"
                        else:
                            return f"ì£„ì†¡í•´ìš”, {target}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì •í™•í•œ ì‹œì„¤ëª…ì„ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
                    
                    elif function_name == "start_registration":
                        result = self.robot_functions.start_registration()
                        return result["result"]
                    
                    elif function_name == "general_response":
                        message = arguments.get("message", user_input)
                        # ëª¨ë¸ì´ ì¶”ì¶œí•œ ë©”ì‹œì§€ë¥¼ ì§ì ‘ ì‚¬ìš©
                        if message and message != user_input:
                            return message
                        else:
                            return self._generate_simple_response(message)
                    
                    else:
                        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜: {function_name}")
                        continue
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
                except Exception as e:
                    print(f"âŒ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  í•¨ìˆ˜ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ fallback
            print("âŒ ëª¨ë“  í•¨ìˆ˜ í˜¸ì¶œ ì‹¤íŒ¨")
            return self._fallback_response(user_input)
                
        except Exception as e:
            print(f"âŒ í•¨ìˆ˜ í˜¸ì¶œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._fallback_response(user_input)
    
    def _fallback_response(self, user_input: str) -> str:
        """ê°œì„ ëœ fallback ì‘ë‹µ - ë§¥ë½ ê³ ë ¤"""
        user_lower = user_input.lower().strip()
        
        # ë§¥ë½ì—ì„œ ì‹œì„¤ëª… ì¶”ì¶œ
        recent_facility = self._extract_recent_facility()
        
        # ì´ë™ ìš”ì²­ì¸ë° ëª©ì ì§€ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°
        if any(word in user_lower for word in ["ì•ˆë‚´", "ê°€ì", "ë™í–‰", "ë°ë ¤ë‹¤", "ì´ë™"]):
            if recent_facility:
                return f"{recent_facility}ë¡œ ì•ˆë‚´í•´ë“œë¦´ê¹Œìš”?"
            else:
                return "ì–´ë””ë¡œ ì•ˆë‚´í•´ë“œë¦´ê¹Œìš”?"
        
        # ìœ„ì¹˜ ì§ˆë¬¸ì¸ë° ì‹œì„¤ëª…ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°  
        elif any(word in user_lower for word in ["ì–´ë””", "ìœ„ì¹˜", "ì°¾ì•„"]):
            return "ì–´ë–¤ ì‹œì„¤ì„ ì°¾ìœ¼ì‹œë‚˜ìš”? CT, X-ray, ì´ˆìŒíŒŒ, ê°ì¢… ì•”ì„¼í„° ë“±ì´ ìˆì–´ìš”."
        
        # ì ‘ìˆ˜/ì˜ˆì•½ ìš”ì²­
        elif any(word in user_lower for word in ["ì ‘ìˆ˜", "ì ‘ìˆ˜í•˜ë ¤ë©´", "ì ‘ìˆ˜í•˜ê³  ì‹¶ì–´ìš”", "ì˜ˆì•½", "ì˜ˆì•½ í™•ì¸", "ì˜ˆì•½ ë‚´ì—­", "ì˜ˆì•½ ì •ë³´"]):
            return "ì ‘ìˆ˜ í™”ë©´ìœ¼ë¡œ ì´ë™í• ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
        
        # ì¸ì‚¬
        elif any(word in user_lower for word in ["ì•ˆë…•", "hello", "hi"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë³‘ì› ì•ˆë‚´ ë¡œë´‡ ì˜ì›…ì´ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        
        # ê°ì‚¬
        elif any(word in user_lower for word in ["ê³ ë§ˆ", "ê°ì‚¬", "thank"]):
            return "ì²œë§Œì—ìš”! ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        
        # ê¸°ë³¸
        else:
            return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë³‘ì› ì‹œì„¤ ì•ˆë‚´, ìœ„ì¹˜ ì¡°íšŒ, ì˜ˆì•½ í™•ì¸, ì ‘ìˆ˜ ë“±ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”."
    
    def _simple_simulation(self, user_input: str) -> str:
        """ë‹¨ìˆœí•œ ì‹œë®¬ë ˆì´ì…˜"""
        user_lower = user_input.lower().strip()
        
        # ì¸ì‚¬ë§
        if any(word in user_lower for word in ["ì•ˆë…•", "hello", "hi"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë³‘ì› ì•ˆë‚´ ë¡œë´‡ ì˜ì›…ì´ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        
        # ê°ì‚¬
        elif any(word in user_lower for word in ["ê³ ë§ˆ", "ê°ì‚¬", "thank"]):
            return "ì²œë§Œì—ìš”! ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        
        # ì‹œì„¤ ìœ„ì¹˜ ì¡°íšŒ
        elif any(word in user_input for word in ["CT", "X-ray", "ì´ˆìŒíŒŒ", "ë‡Œì¢…ì–‘", "ìœ ë°©ì•”", "ëŒ€ì¥ì•”", "ìœ„ì•”", "íì•”"]):
            if "CT" in user_input:
                return "CTëŠ” ì™¼ìª½ ì¤‘ì•™ ì˜ìƒì˜í•™ê³¼ì— ìˆì–´ìš”."
            elif "X-ray" in user_input:
                return "X-rayëŠ” ì™¼ìª½ ìƒë‹¨ ì˜ìƒì˜í•™ê³¼ì— ìˆì–´ìš”."
            elif "ì´ˆìŒíŒŒ" in user_input:
                return "ì´ˆìŒíŒŒëŠ” ì™¼ìª½ í•˜ë‹¨ ì˜ìƒì˜í•™ê³¼ì— ìˆì–´ìš”."
            elif "ë‡Œì¢…ì–‘" in user_input:
                return "ë‡Œì¢…ì–‘ì€ ì˜¤ë¥¸ìª½ ìƒë‹¨ ì•”ì„¼í„°ì— ìˆì–´ìš”."
            elif "ìœ ë°©ì•”" in user_input:
                return "ìœ ë°©ì•”ì€ ì˜¤ë¥¸ìª½ ìƒë‹¨ ì•”ì„¼í„°ì— ìˆì–´ìš”."
            elif "ëŒ€ì¥ì•”" in user_input:
                return "ëŒ€ì¥ì•”ì€ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ì•”ì„¼í„°ì— ìˆì–´ìš”."
            elif "ìœ„ì•”" in user_input:
                return "ìœ„ì•”ì€ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ì•”ì„¼í„°ì— ìˆì–´ìš”."
            elif "íì•”" in user_input:
                return "íì•”ì€ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ì•”ì„¼í„°ì— ìˆì–´ìš”."
        
        # ë„¤ë¹„ê²Œì´ì…˜
        elif any(word in user_lower for word in ["ê°€ì¤˜", "ì•ˆë‚´", "ì´ë™", "ë°ë ¤ë‹¤"]):
            return "ì¢‹ì•„ìš”! ì €ë¥¼ ë”°ë¼ì˜¤ì„¸ìš”!"
        
        # ê¸°ë³¸ ì‘ë‹µ
        else:
            return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    
    def _advanced_llm_simulation(self, user_input: str, context_prompt: str) -> str:
        """ê¸°ì¡´ ë³µì¡í•œ ì‹œë®¬ë ˆì´ì…˜ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return self._simple_simulation(user_input)
    
    def _call_real_exaone(self, user_input: str, context_prompt: str, is_function_call: bool = False) -> str:
        """ê¸°ì¡´ ë³µì¡í•œ ëª¨ë¸ í˜¸ì¶œ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return self._call_real_exaone_simple(user_input)
    
    def _execute_function_raw(self, function_call: Dict[str, Any], user_input: str = "") -> str:
        """ê¸°ì¡´ ë³µì¡í•œ í•¨ìˆ˜ ì‹¤í–‰ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return "í•¨ìˆ˜ ì‹¤í–‰ì´ ë‹¨ìˆœí™”ë˜ì—ˆìŠµë‹ˆë‹¤."

    def _generate_natural_response(self, user_input: str, function_result: str) -> str:
        """ê¸°ì¡´ ë³µì¡í•œ ìì—°ì–´ ì‘ë‹µ ìƒì„± - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return self._simple_simulation(user_input)
    
    def _simple_fallback(self, user_input: str) -> str:
        """ê¸°ì¡´ ë³µì¡í•œ fallback - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        return self._simple_simulation(user_input)
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
    
    def _clean_reasoning_response(self, response: str) -> str:
        """Reasoning ëª¨ë“œ ì‘ë‹µì—ì„œ <think> ë¸”ë¡ì„ ì œê±°í•˜ê³  ì •ë¦¬ëœ ë‹µë³€ë§Œ ë°˜í™˜"""
        try:
            print(f"ğŸ” ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response)}")
            print(f"ğŸ” ì›ë³¸ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:300]}...")
            
            # <think> ë¸”ë¡ ì œê±°
            if "<think>" in response and "</think>" in response:
                think_start = response.find("<think>")
                think_end = response.find("</think>") + 8
                response = response[:think_start] + response[think_end:]
                print(f"ğŸ” <think> ë¸”ë¡ ì œê±° í›„ ê¸¸ì´: {len(response)}")
            else:
                print("ğŸ” <think> ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            unwanted_patterns = [
                "ë‹¹ì‹ ì€ ë³‘ì› ì•ˆë‚´ ë¡œë´‡ì…ë‹ˆë‹¤",
                "ì‚¬ìš©ì ì§ˆë¬¸:",
                "ì¤‘ìš”í•œ ê·œì¹™:",
                "ì´ì „ ëŒ€í™” ë§¥ë½:",
                "Available Tools",
                "ì‚¬ìš©ì ì§ˆë¬¸:"
            ]
            
            for pattern in unwanted_patterns:
                if pattern in response:
                    response = response.replace(pattern, "")
                    print(f"ğŸ” '{pattern}' ì œê±°ë¨")
            
            # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° ë° ì •ë¦¬
            response = response.strip()
            print(f"ğŸ” ì •ë¦¬ í›„ ê¸¸ì´: {len(response)}")
            
            # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° ì²˜ë¦¬
            if not response or len(response) < 10:
                print("âŒ ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ")
                return ""
            
            # ì‘ë‹µì´ ë„ˆë¬´ ê¸´ ê²½ìš° ì ì ˆíˆ ìë¥´ê¸° (ìµœëŒ€ 1000ì)
            if len(response) > 1000:
                response = response[:1000] + "..."
                print("ğŸ” ì‘ë‹µì´ 1000ìë¡œ ì˜ë¦¼")
            
            print(f"âœ… ìµœì¢… ì •ë¦¬ëœ ì‘ë‹µ: {response[:100]}...")
            return response
            
        except Exception as e:
            print(f"âŒ Reasoning ì‘ë‹µ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return response.strip() 

    def _call_real_exaone_reasoning(self, user_input: str) -> str:
        """Reasoning ëª¨ë“œìš© EXAONE í˜¸ì¶œ (<think> ë¸”ë¡ ì‚¬ìš©) - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë§¥ë½ êµ¬ì„±
            conversation_context = ""
            if len(self.conversation_history) > 1:
                # ìµœê·¼ 4ê°œ ëŒ€í™”ë§Œ í¬í•¨ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ)
                recent_history = self.conversation_history[-8:]  # 4ìŒì˜ ëŒ€í™”
                context_items = []
                for entry in recent_history:
                    context_items.append(f"{entry['role']}: {entry['content']}")
                conversation_context = "\n".join(context_items)
            
            # Reasoning ëª¨ë“œìš© ì§€ì‹œì‚¬í•­ - í•¨ìˆ˜ í˜¸ì¶œ ë°©ì‹ ì‚¬ìš©
            system_prompt = f"""ë‹¹ì‹ ì€ ë³‘ì› ì•ˆë‚´ ë¡œë´‡ì…ë‹ˆë‹¤. ì´ë¦„ì€ 'ì˜ì›…ì´'ì…ë‹ˆë‹¤. 
ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹¨ê³„ë³„ë¡œ ìƒê°í•œ í›„ ì ì ˆí•œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.

ì¤‘ìš”í•œ ê·œì¹™:
1. ìœ„ì¹˜ ì§ˆë¬¸('ì–´ë””ì•¼', 'ì–´ë””ìˆì–´', 'ì°¾ì•„')ì€ query_facility ì‚¬ìš©
2. ì´ë™ ìš”ì²­('ì•ˆë‚´í•´ì¤˜', 'ë°ë ¤ë‹¤ì¤˜', 'ë™í–‰í•´ì¤˜', 'ê°€ì', 'ê°€ì ¸ë‹¤ì¤˜')ì€ navigate ì‚¬ìš©  
3. ì˜ˆì•½ í™•ì¸ ìš”ì²­('ì˜ˆì•½ í™•ì¸', 'ì˜ˆì•½ ë‚´ì—­', 'ì˜ˆì•½ ì •ë³´', 'ì˜ˆì•½ë¼ ìˆëŠ”ì§€')ì€ check_reservation ì‚¬ìš©
4. ì ‘ìˆ˜ ìš”ì²­('ì ‘ìˆ˜', 'ì ‘ìˆ˜í•˜ë ¤ë©´', 'ì ‘ìˆ˜í•˜ê³  ì‹¶ì–´ìš”', 'ì ‘ìˆ˜ ì¢€ ë„ì™€ì£¼ì„¸ìš”')ì€ start_registration ì‚¬ìš©
5. ì¼ë°˜ ëŒ€í™”('ì•ˆë…•', 'ê³ ë§ˆì›Œ', 'ë­ì•¼')ëŠ” general_response ì‚¬ìš©
6. ë³µì¡í•œ ì„¤ëª…ì´ í•„ìš”í•œ ì§ˆë¬¸ë„ general_responseë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€
7. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ (ê¸¸ê³  í˜„í•™ì ì¸ ë‹µë³€ ê¸ˆì§€)

{f"ì´ì „ ëŒ€í™” ë§¥ë½:{conversation_context}" if conversation_context else ""}

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ì¤‘ìš”: ì‚¬ìš©ìê°€ "ë„ˆê°€ ì„¤ëª…í•œ", "ë‹¹ì‹ ì´ ë§í•œ" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´, 
ì´ì „ ëŒ€í™”ì—ì„œ ìì‹ ì´ ì„¤ëª…í•œ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            
            # tools ì •ì˜ (non-reasoning ëª¨ë“œì™€ ë™ì¼)
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "query_facility",
                        "description": "ë³‘ì› ë‚´ ì‹œì„¤ì˜ ìœ„ì¹˜ë¥¼ ì¡°íšŒí•  ë•Œ ì‚¬ìš©. 'ì–´ë””ì•¼', 'ìœ„ì¹˜', 'ì°¾ì•„' ë“±ì˜ ì§ˆë¬¸ì— ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["facility"],
                            "properties": {
                                "facility": {
                                    "type": "string",
                                    "description": "ì¡°íšŒí•  ì‹œì„¤ëª… (CT, X-ray, ì´ˆìŒíŒŒ, íì•”, ìœ„ì•”, ëŒ€ì¥ì•”, ìœ ë°©ì•”, ë‡Œì¢…ì–‘ ë“±)"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function", 
                    "function": {
                        "name": "navigate",
                        "description": "ì‚¬ìš©ìë¥¼ íŠ¹ì • ìœ„ì¹˜ë¡œ ì•ˆë‚´í•  ë•Œ ì‚¬ìš©. 'ì•ˆë‚´í•´ì¤˜', 'ë°ë ¤ë‹¤ì¤˜', 'ë™í–‰í•´ì¤˜', 'ê°€ì' ë“±ì˜ ìš”ì²­ì— ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["target"],
                            "properties": {
                                "target": {
                                    "type": "string",
                                    "description": "ì•ˆë‚´í•  ëª©ì ì§€"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "general_response",
                        "description": "ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ì¸ì‚¬, ì„¤ëª…ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©",
                        "parameters": {
                            "type": "object",
                            "required": ["message"],
                            "properties": {
                                "message": {
                                    "type": "string",
                                    "description": "ì‚¬ìš©ìì˜ ë©”ì‹œì§€"
                                }
                            }
                        }
                    }
                }
            ]
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "user", "content": system_prompt}]
            
            # í† í¬ë‚˜ì´ì € ì ìš© (í•¨ìˆ˜ í˜¸ì¶œ ë°©ì‹ ì‚¬ìš©)
            input_ids = self.tokenizer.apply_chat_template(
                messages,
                tokenize=True,
                add_generation_prompt=True,
                return_tensors="pt",
                tools=tools,  # í•¨ìˆ˜ í˜¸ì¶œ í™œì„±í™”
            )
            print("âœ… í•¨ìˆ˜ í˜¸ì¶œ íŒŒë¼ë¯¸í„° ì ìš©ë¨")
            
            print("ğŸ§  Reasoning ëª¨ë“œë¡œ ì‹¤ì‹œê°„ ë‹µë³€ ì¤‘:", end=" ", flush=True)
            
            # Reasoning ëª¨ë“œìš© ìŠ¤íŠ¸ë¦¬ë¨¸ (TextIteratorStreamer ê°•ì œ ì‚¬ìš©)
            from transformers import TextIteratorStreamer
            from threading import Thread
            
            reasoning_streamer = TextIteratorStreamer(
                self.tokenizer,
                skip_prompt=True,
                skip_special_tokens=True
            )
            
            # Reasoning ëª¨ë“œ ìƒì„± íŒŒë¼ë¯¸í„° (EXAONE 4.0 ê³µì‹ ê¶Œì¥ê°’)
            max_tokens = 1024 if self.fast_mode else 2048
            
            # Reasoning ëª¨ë“œ ìŠ¤ë ˆë“œ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë°
            reasoning_kwargs = {
                "input_ids": input_ids.to(self.model.device),
                "max_new_tokens": max_tokens,
                "do_sample": True,
                "temperature": 0.6,  # ê³µì‹ ê¶Œì¥ê°’ (Reasoning ëª¨ë“œ)
                "top_p": 0.95,  # ê³µì‹ ê¶Œì¥ê°’ ê³ ì •
                "repetition_penalty": 1.1,  # transformers ì§€ì› íŒŒë¼ë¯¸í„°
                "pad_token_id": self.tokenizer.pad_token_id,
                "eos_token_id": self.tokenizer.eos_token_id,
                "attention_mask": None,  # Attention mask ìë™ ìƒì„±
                "streamer": reasoning_streamer,  # TextIteratorStreamer ì‚¬ìš©
            }
            
            # Reasoning ëª¨ë“œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
            if hasattr(reasoning_streamer, '__iter__'):  # TextIteratorStreamerì¸ ê²½ìš°
                print("ğŸ” TextIteratorStreamer ì‚¬ìš©")
                reasoning_thread = Thread(target=self.model.generate, kwargs=reasoning_kwargs)
                reasoning_thread.start()
                
                # Reasoning ëª¨ë“œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ë° í•¨ìˆ˜ í˜¸ì¶œ ê°ì§€
                full_reasoning_text = ""
                token_count = 0
                for text in reasoning_streamer:
                    print(text, end="", flush=True)
                    full_reasoning_text += text
                    token_count += 1
                    if token_count % 10 == 0:  # 10ê°œ í† í°ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                        print(f" [í† í° {token_count}]", end="", flush=True)
                
                reasoning_thread.join()  # ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
                print(f"\nğŸ” ì´ ìƒì„±ëœ í† í° ìˆ˜: {token_count}")
                
                # Reasoning ëª¨ë“œ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ì‘ë‹µ ì²˜ë¦¬
                print(f"\nğŸ” ì „ì²´ ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_reasoning_text)}")
                print(f"ğŸ” ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {full_reasoning_text[:200]}...")
                
                if "<tool_call>" in full_reasoning_text:
                    print("\nğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ í˜•ì‹ ê°ì§€ë¨")
                    function_result = self._parse_and_execute_tool_call_improved(full_reasoning_text, user_input)
                    print(f"ğŸ¤– ë‹µë³€: {function_result}")
                    return function_result
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                    if full_reasoning_text.strip() and "Available Tools" not in full_reasoning_text:
                        return full_reasoning_text.strip()
                    else:
                        print("\nâŒ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                        fallback_result = self._fallback_response(user_input)
                        print(f"ğŸ¤– ë‹µë³€: {fallback_result}")
                        return fallback_result
            # TextIteratorStreamerë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ else ë¸”ë¡ ì œê±°
            
        except Exception as e:
            print(f"\nâŒ Reasoning ëª¨ë“œ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_response(user_input)

# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸ (ë¹ ë¥¸ ëª¨ë“œ í™œì„±í™”, ë””ë²„ê·¸ ëª¨ë“œ ë¹„í™œì„±í™”)
    robot = RobotSystem(use_real_model=False, use_reasoning=False, fast_mode=True, debug_mode=False)
    
    print("ğŸ¤– ë³‘ì› ì•ˆë‚´ ë¡œë´‡ ì˜ì›…ì´ í…ŒìŠ¤íŠ¸")
    print("ğŸ“ ëª¨ë“œ: ìë™ ì „í™˜ (ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€)")
    print("âš¡ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ í™œì„±í™”")
    print("ğŸ’¡ EXAONE 4.0 ê³µì‹ ê¶Œì¥ê°’ ì ìš© ì¤‘")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("ìˆ˜ë™ ëª¨ë“œ ì „í™˜:")
    print("  - 'reasoning' â†’ Reasoning ëª¨ë“œ")
    print("  - 'non-reasoning' â†’ Non-reasoning ëª¨ë“œ")
    print("  - 'fast' â†’ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ ì¼œê¸°")
    print("  - 'normal' â†’ ì¼ë°˜ ì‘ë‹µ ëª¨ë“œ")
    print("ì˜ˆì‹œ:")
    print("  - 'CT ì–´ë””ì•¼?' â†’ Non-reasoning ëª¨ë“œ")
    print("  - 'ì™œ CTì™€ X-rayê°€ ë‹¤ë¥¸ê°€ìš”?' â†’ Reasoning ëª¨ë“œ")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ")
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            elif user_input.lower() == 'reasoning':
                # Reasoning ëª¨ë“œë¡œ ê°•ì œ ì „í™˜
                robot.use_reasoning = True
                print("ğŸ§  ìˆ˜ë™ ì „í™˜: Reasoning ëª¨ë“œ")
                continue
            elif user_input.lower() == 'non-reasoning':
                # Non-reasoning ëª¨ë“œë¡œ ê°•ì œ ì „í™˜
                robot.use_reasoning = False
                print("ğŸ’¬ ìˆ˜ë™ ì „í™˜: Non-reasoning ëª¨ë“œ")
                continue
            elif user_input.lower() == 'fast':
                # ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ í™œì„±í™”
                robot.fast_mode = True
                print("âš¡ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ í™œì„±í™”!")
                continue
            elif user_input.lower() == 'normal':
                # ì¼ë°˜ ì‘ë‹µ ëª¨ë“œë¡œ ì „í™˜
                robot.fast_mode = False
                print("ğŸŒ ì¼ë°˜ ì‘ë‹µ ëª¨ë“œë¡œ ì „í™˜")
                continue
            
            response = robot.process_user_input(user_input)
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì´ ì´ë¯¸ ì¶œë ¥ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ ì¶œë ¥
            if response and response.strip():
                print(f"ğŸ¤– ì˜ì›…ì´: {response}")
            
            print()  # ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ„í•œ ê°œí–‰
            sys.stdout.flush()  # ì¶œë ¥ ë²„í¼ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break 