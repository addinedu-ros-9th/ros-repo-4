package com.example.youngwoong

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Color
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.speech.tts.UtteranceProgressListener
import android.util.Log
import android.view.View
import android.view.animation.AlphaAnimation
import android.widget.ImageView
import android.widget.TextView
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.lifecycle.lifecycleScope
import com.airbnb.lottie.LottieAnimationView
import kotlinx.coroutines.*
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject
import java.util.concurrent.TimeUnit
import java.util.*

class VoiceGuideActivity : AppCompatActivity() {

    private var isListening = false
    private lateinit var voiceAnimation: LottieAnimationView
    private lateinit var dimView: View
    private lateinit var textPrompt: TextView
    private lateinit var textUserMessage: TextView
    private lateinit var textBotMessage: TextView
    private var blinkAnimation: AlphaAnimation? = null

    private lateinit var speechRecognizer: SpeechRecognizer
    private lateinit var speechIntent: Intent
    private lateinit var textToSpeech: TextToSpeech
    
    // LLM ì„œë²„ í†µì‹ ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
    private val client = OkHttpClient.Builder()
        .connectTimeout(30, TimeUnit.SECONDS)
        .readTimeout(60, TimeUnit.SECONDS)
        .writeTimeout(60, TimeUnit.SECONDS)
        .build()
    
    private val jsonMediaType = "application/json; charset=utf-8".toMediaType()
    
    companion object {
        private const val TAG = "VoiceGuideActivity"
        private const val BASE_URL = "http://192.168.0.31:5000" // Flask ì„œë²„ URL
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_voice_guide)

        checkPermissions()
        setupSTT()
        setupTTS()

        voiceAnimation = findViewById(R.id.voice_animation)
        dimView = findViewById(R.id.dim_view)
        textPrompt = findViewById(R.id.text_prompt)
        textUserMessage = findViewById(R.id.text_user_message)
        textBotMessage = findViewById(R.id.text_bot_message)

        findViewById<ImageView>(R.id.btn_back).setOnClickListener {
            applyAlphaEffect(it)
            returnToMainMenu()
        }

        findViewById<ImageView>(R.id.btn_voice).setOnClickListener {
            applyAlphaEffect(it)
            toggleListening(it as ImageView)
        }
    }

    private fun checkPermissions() {
        val permissions = listOf(Manifest.permission.RECORD_AUDIO)
        val notGranted = permissions.filter {
            ContextCompat.checkSelfPermission(this, it) != PackageManager.PERMISSION_GRANTED
        }

        if (notGranted.isNotEmpty()) {
            ActivityCompat.requestPermissions(this, notGranted.toTypedArray(), 1000)
        }
    }

    override fun onRequestPermissionsResult(
        requestCode: Int, permissions: Array<out String>, grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == 1000 && grantResults.any { it != PackageManager.PERMISSION_GRANTED }) {
            Toast.makeText(this, "ğŸ™ï¸ ìŒì„± ì¸ì‹ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
            finish()
        }
    }

    private fun applyAlphaEffect(view: View) {
        view.alpha = 0.6f
        view.postDelayed({ view.alpha = 1.0f }, 100)
    }

    private fun returnToMainMenu() {
        val intent = Intent(this, MainMenuActivity::class.java).apply {
            addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP or Intent.FLAG_ACTIVITY_SINGLE_TOP)
        }
        startActivity(intent)
        overridePendingTransition(android.R.anim.fade_in, android.R.anim.fade_out)
        finish()
    }

    private fun toggleListening(button: ImageView) {
        isListening = !isListening

        if (isListening) {
            dimView.alpha = 0f
            dimView.visibility = View.VISIBLE
            dimView.animate().alpha(0.15f).setDuration(300).start()

            voiceAnimation.apply {
                alpha = 0f
                visibility = View.VISIBLE
                animate().alpha(1f).setDuration(300).withStartAction {
                    playAnimation()
                }.start()
            }

            textPrompt.apply {
                visibility = View.VISIBLE
                text = "ë“£ê³  ìˆì–´ìš”..."
                setTextColor(Color.parseColor("#FFA000"))
                startBlinking(this)
            }

            speechRecognizer.startListening(speechIntent)
            button.setImageResource(R.drawable.btn_voice_stop)

        } else {
            dimView.animate().alpha(0f).setDuration(300).withEndAction {
                dimView.visibility = View.GONE
            }.start()

            voiceAnimation.animate().alpha(0f).setDuration(300).withEndAction {
                voiceAnimation.pauseAnimation()
                voiceAnimation.visibility = View.GONE
            }.start()

            textPrompt.apply {
                text = "í„°ì¹˜ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤"
                setTextColor(Color.parseColor("#000000"))
                stopBlinking(this)
            }

            speechRecognizer.stopListening()
            speechRecognizer.cancel()
            button.setImageResource(R.drawable.btn_voice_start)
        }
    }

    private fun startBlinking(view: View) {
        blinkAnimation = AlphaAnimation(1.0f, 0.0f).apply {
            duration = 600
            repeatMode = AlphaAnimation.REVERSE
            repeatCount = AlphaAnimation.INFINITE
        }
        view.startAnimation(blinkAnimation)
    }

    private fun stopBlinking(view: View) {
        blinkAnimation?.cancel()
        view.clearAnimation()
    }

    private fun setupSTT() {
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)

        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {}
            override fun onBeginningOfSpeech() {}
            override fun onRmsChanged(rmsdB: Float) {}
            override fun onBufferReceived(buffer: ByteArray?) {}
            override fun onEndOfSpeech() {}

            override fun onError(error: Int) {
                val errorMessage = when (error) {
                    SpeechRecognizer.ERROR_AUDIO -> "ì˜¤ë””ì˜¤ ì˜¤ë¥˜"
                    SpeechRecognizer.ERROR_CLIENT -> "í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜"
                    SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "ê¶Œí•œ ë¶€ì¡±"
                    SpeechRecognizer.ERROR_NETWORK -> "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜"
                    SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ë„¤íŠ¸ì›Œí¬ ì‹œê°„ ì´ˆê³¼"
                    SpeechRecognizer.ERROR_NO_MATCH -> "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
                    SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "ì¸ì‹ê¸° ì‚¬ìš© ì¤‘"
                    SpeechRecognizer.ERROR_SERVER -> "ì„œë²„ ì˜¤ë¥˜"
                    SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "ìŒì„± ì…ë ¥ ì‹œê°„ ì´ˆê³¼"
                    else -> "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                }
                
                Log.e("STT", "âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: $error ($errorMessage)")

                if (isListening) {
                    // ê°„ë‹¨í•œ ì¬ì‹œë„ ë¡œì§
                    speechRecognizer.cancel()
                    speechRecognizer.startListening(speechIntent)
                } else {
                    runOnUiThread {
                        textPrompt.text = "í„°ì¹˜ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤"
                    }
                }
            }

            override fun onResults(results: Bundle?) {
                val result = results
                    ?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    ?.getOrNull(0)

                result?.let { userMessage ->
                    runOnUiThread {
                        textUserMessage.text = userMessage
                        textPrompt.text = "ğŸ¤– ë¡œë´‡ì´ ì‘ë‹µí•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                        textBotMessage.text = ""
                    }
                    
                    // LLM ì„œë²„ë¡œ ë©”ì‹œì§€ ì „ì†¡
                    sendMessageToLLM(userMessage)
                }

                if (isListening) {
                    speechRecognizer.startListening(speechIntent)
                }
            }

            override fun onPartialResults(partialResults: Bundle?) {}
            override fun onEvent(eventType: Int, params: Bundle?) {}
        })

        speechIntent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ko-KR")
            putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 1) // ìµœëŒ€ ê²°ê³¼ ìˆ˜ë§Œ ì¶”ê°€
        }
    }
    
    private fun setupTTS() {
        textToSpeech = TextToSpeech(this) { status ->
            if (status == TextToSpeech.SUCCESS) {
                Log.d(TAG, "TTS ì´ˆê¸°í™” ì„±ê³µ")
                
                // ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª©ë¡ í™•ì¸
                val availableLocales = textToSpeech.availableLanguages
                Log.d(TAG, "ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´: $availableLocales")
                
                // í•œêµ­ì–´ ì„¤ì • ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
                var languageSet = false
                
                // 1. Locale.KOREA ì‹œë„ (Java ì˜ˆì œì™€ ë™ì¼)
                val koreaResult = textToSpeech.setLanguage(Locale.KOREA)
                if (koreaResult != TextToSpeech.LANG_MISSING_DATA && koreaResult != TextToSpeech.LANG_NOT_SUPPORTED) {
                    Log.d(TAG, "í•œêµ­ì–´ ì„¤ì • ì„±ê³µ (Locale.KOREA)")
                    languageSet = true
                } else {
                    Log.d(TAG, "Locale.KOREA ì„¤ì • ì‹¤íŒ¨: $koreaResult")
                    
                    // 2. Locale.KOREAN ì‹œë„
                    val koreanResult = textToSpeech.setLanguage(Locale.KOREAN)
                    if (koreanResult != TextToSpeech.LANG_MISSING_DATA && koreanResult != TextToSpeech.LANG_NOT_SUPPORTED) {
                        Log.d(TAG, "í•œêµ­ì–´ ì„¤ì • ì„±ê³µ (Locale.KOREAN)")
                        languageSet = true
                    } else {
                        Log.d(TAG, "Locale.KOREAN ì„¤ì • ì‹¤íŒ¨: $koreanResult")
                        
                        // 3. Locale("ko", "KR") ì‹œë„
                        val koKRResult = textToSpeech.setLanguage(Locale("ko", "KR"))
                        if (koKRResult != TextToSpeech.LANG_MISSING_DATA && koKRResult != TextToSpeech.LANG_NOT_SUPPORTED) {
                            Log.d(TAG, "í•œêµ­ì–´ ì„¤ì • ì„±ê³µ (ko-KR)")
                            languageSet = true
                        } else {
                            Log.d(TAG, "ko-KR ì„¤ì • ì‹¤íŒ¨: $koKRResult")
                            
                            // 4. ê¸°ë³¸ ì–¸ì–´ ì‚¬ìš©
                            val defaultResult = textToSpeech.setLanguage(Locale.getDefault())
                            if (defaultResult != TextToSpeech.LANG_MISSING_DATA && defaultResult != TextToSpeech.LANG_NOT_SUPPORTED) {
                                Log.d(TAG, "ê¸°ë³¸ ì–¸ì–´ ì„¤ì • ì„±ê³µ: ${Locale.getDefault()}")
                                languageSet = true
                            }
                        }
                    }
                }
                
                if (languageSet) {
                    // TTS ì†ë„ì™€ í”¼ì¹˜ ì„¤ì •
                    textToSpeech.setSpeechRate(0.9f) // ì•½ê°„ ëŠë¦¬ê²Œ
                    textToSpeech.setPitch(1.0f) // ê¸°ë³¸ í”¼ì¹˜
                    Log.d(TAG, "TTS ì„¤ì • ì™„ë£Œ - ì†ë„: 0.9, í”¼ì¹˜: 1.0")
                } else {
                    Log.e(TAG, "ëª¨ë“  ì–¸ì–´ ì„¤ì • ì‹œë„ ì‹¤íŒ¨")
                    Toast.makeText(this, "ìŒì„± í•©ì„± ì–¸ì–´ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
                }
            } else {
                Log.e(TAG, "TTS ì´ˆê¸°í™” ì‹¤íŒ¨: $status")
                Toast.makeText(this, "ìŒì„± í•©ì„± ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
            }
        }
        
        // TTS ì§„í–‰ ìƒíƒœ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
        textToSpeech.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
            override fun onStart(utteranceId: String?) {
                Log.d(TAG, "TTS ì‹œì‘: $utteranceId")
            }
            
            override fun onDone(utteranceId: String?) {
                Log.d(TAG, "TTS ì™„ë£Œ: $utteranceId")
            }
            
            override fun onError(utteranceId: String?) {
                Log.e(TAG, "TTS ì˜¤ë¥˜: $utteranceId")
            }
        })
    }
    
    private fun sendMessageToLLM(message: String) {
        lifecycleScope.launch {
            try {
                Log.d(TAG, "LLM ì„œë²„ë¡œ ë©”ì‹œì§€ ì „ì†¡: $message")
                
                val response = sendMessageToServer(message)
                
                runOnUiThread {
                    textBotMessage.text = response
                    textPrompt.text = "í„°ì¹˜ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤"
                    // TTSë¡œ ì‘ë‹µ ìŒì„± ì¶œë ¥
                    speakResponse(response)
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "LLM ì„œë²„ í†µì‹  ì˜¤ë¥˜: ${e.message}")
                runOnUiThread {
                    textBotMessage.text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë²„ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
                    textPrompt.text = "í„°ì¹˜ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤"
                    speakResponse("ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë²„ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
                }
            }
        }
    }
    
    private suspend fun sendMessageToServer(message: String): String = withContext(Dispatchers.IO) {
        try {
            val jsonBody = JSONObject().apply {
                put("message", message)
            }
            
            val requestBody = jsonBody.toString().toRequestBody(jsonMediaType)
            val request = Request.Builder()
                .url("$BASE_URL/api/chat")
                .post(requestBody)
                .build()
            
            val response = client.newCall(request).execute()
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                Log.d(TAG, "ì„œë²„ ì‘ë‹µ ì›ë³¸: $responseBody")
                
                val jsonResponse = JSONObject(responseBody ?: "{}")
                Log.d(TAG, "JSON ì‘ë‹µ: $jsonResponse")
                
                val reply = jsonResponse.optString("response", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                Log.d(TAG, "íŒŒì‹±ëœ ì‘ë‹µ: $reply")
                Log.d(TAG, "LLM ì‘ë‹µ ìˆ˜ì‹ : ${reply.length}ì")
                return@withContext reply
            } else {
                Log.e(TAG, "LLM ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨: ${response.code}")
                return@withContext "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        } catch (e: Exception) {
            Log.e(TAG, "LLM ì„œë²„ í†µì‹  ì˜¤ë¥˜: ${e.message}")
            return@withContext "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    }
    
    private fun speakResponse(text: String) {
        try {
            if (::textToSpeech.isInitialized) {
                Log.d(TAG, "TTSë¡œ ìŒì„± ì¶œë ¥: $text")
                val result = textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, "response_utterance")
                if (result == TextToSpeech.ERROR) {
                    Log.e(TAG, "TTS ìŒì„± ì¶œë ¥ ì‹¤íŒ¨")
                } else {
                    Log.d(TAG, "TTS ìŒì„± ì¶œë ¥ ì„±ê³µ")
                }
            } else {
                Log.e(TAG, "TTSê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            }
        } catch (e: Exception) {
            Log.e(TAG, "TTS ì˜¤ë¥˜: ${e.message}")
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        speechRecognizer.destroy()
        if (::textToSpeech.isInitialized) {
            textToSpeech.stop()
            textToSpeech.shutdown()
        }
    }
}
