#!/usr/bin/env python3
"""
YOLOë¡œ ì‚¬ëŒ ê°ì§€í•˜ê³  ì„¸ê·¸ë©˜í…Œì´ì…˜ìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
"""

import cv2
import numpy as np
import os
import sys
import json
from datetime import datetime

# YOLO ëª¨ë¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('/home/ckim/ros-repo-4/deeplearning/src')
from shared_models import get_shared_seg_model, SEG_MODEL_LOCK

class SimplePersonColorAnalyzer:
    def __init__(self):
        self.output_dir = "simple_person_analysis"
        self.seg_model = None
        
    def load_model(self):
        """YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ"""
        if self.seg_model is None:
            print("Loading YOLO segmentation model...")
            self.seg_model = get_shared_seg_model()
            print("âœ… YOLO model loaded")
        return self.seg_model
    
    def extract_color_histogram(self, img, mask, bins=16):
        """HSV ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ"""
        # HSVë¡œ ë³€í™˜
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # ë§ˆìŠ¤í¬ ì ìš©
        masked_hsv = cv2.bitwise_and(hsv, hsv, mask=mask)
        
        # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
        h_hist = cv2.calcHist([masked_hsv], [0], mask, [bins], [0, 180])
        s_hist = cv2.calcHist([masked_hsv], [1], mask, [bins], [0, 256])
        v_hist = cv2.calcHist([masked_hsv], [2], mask, [bins], [0, 256])
        
        # ì •ê·œí™”
        h_hist = cv2.normalize(h_hist, h_hist, 0, 1, cv2.NORM_MINMAX)
        s_hist = cv2.normalize(s_hist, s_hist, 0, 1, cv2.NORM_MINMAX)
        v_hist = cv2.normalize(v_hist, v_hist, 0, 1, cv2.NORM_MINMAX)
        
        # ê²°í•©ëœ íˆìŠ¤í† ê·¸ë¨
        combined = np.concatenate([h_hist.flatten(), s_hist.flatten(), v_hist.flatten()])
        
        return {
            'h': h_hist.flatten(),
            's': s_hist.flatten(),
            'v': v_hist.flatten(),
            'combined': combined
        }
    
    def calculate_similarity(self, hist1, hist2):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = np.dot(hist1, hist2)
        norm1 = np.linalg.norm(hist1)
        norm2 = np.linalg.norm(hist2)
        return dot_product / (norm1 * norm2) if norm1 * norm2 > 0 else 0
    
    def analyze_image(self, image_path):
        """ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒ ê°ì§€í•˜ê³  ìƒ‰ìƒ ë¶„ì„"""
        
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        print(f"Loading image: {image_path}")
        image = cv2.imread(image_path)
        
        if image is None:
            print(f"Cannot load image: {image_path}")
            return None
        
        print(f"Image size: {image.shape}")
        
        # YOLOë¡œ ì‚¬ëŒ ê°ì§€ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ (ë†’ì€ confidence)
        model = self.load_model()
        
        with SEG_MODEL_LOCK:
            results = model(image, conf=0.5, verbose=False)  # confidence threshold ë†’ì„
        
        if not results or len(results) == 0 or results[0].masks is None:
            print("âŒ No people detected")
            return None
        
        masks = results[0].masks
        boxes = results[0].boxes
        confidences = results[0].boxes.conf
        
        print(f"âœ… Initially detected {len(masks)} people")
        
        # ìë™ í•„í„°ë§: ì‹¤ì œ ì‚¬ëŒë§Œ ì„ íƒ
        filtered_persons = self._filter_real_people(masks, boxes, confidences, image.shape)
        
        if not filtered_persons:
            print("âŒ No valid people after filtering")
            return None
        
        print(f"âœ… Filtered to {len(filtered_persons)} real people")
        
        # ê° ì‚¬ëŒë³„ ìƒ‰ìƒ ë¶„ì„
        person_data = {}
        
        for i, (mask, box, conf) in enumerate(filtered_persons):
            # ë§ˆìŠ¤í¬ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            mask_resized = cv2.resize(mask.cpu().numpy(), (image.shape[1], image.shape[0]))
            mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
            
            # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
            histograms = self.extract_color_histogram(image, mask_binary)
            
            person_id = f"Person_{i+1}"
            person_data[person_id] = {
                'id': person_id,
                'name': person_id,
                'bbox': box.cpu().numpy().astype(int).tolist(),
                'confidence': float(conf),
                'histograms': histograms,
                'mask': mask_binary
            }
            
            print(f"âœ… {person_id} analysis completed (conf: {conf:.3f})")
        
        if person_data:
            # ì‹œê°í™” ìƒì„±
            self._create_visualization(person_data, image)
            
            # ìœ ì‚¬ë„ ë¶„ì„
            self._analyze_similarities(person_data)
            
            print(f"âœ… Analysis completed! Results saved to '{self.output_dir}' folder.")
            return person_data
        else:
            print("âŒ No person data to analyze.")
            return None
    
    def _filter_real_people(self, masks, boxes, confidences, image_shape):
        """ì‹¤ì œ ì‚¬ëŒë§Œ í•„í„°ë§"""
        height, width = image_shape[:2]
        filtered = []
        
        for i, (mask, box, conf) in enumerate(zip(masks.data, boxes.xyxy, confidences)):
            x1, y1, x2, y2 = box.cpu().numpy()
            
            # 1. Confidence threshold (ì´ë¯¸ 0.5ë¡œ ì„¤ì •ë¨)
            if conf < 0.5:
                continue
            
            # 2. ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° í•„í„°ë§
            bbox_width = x2 - x1
            bbox_height = y2 - y1
            bbox_area = bbox_width * bbox_height
            
            # ë„ˆë¬´ ì‘ê±°ë‚˜ í° ë°”ìš´ë”©ë°•ìŠ¤ ì œê±°
            min_area = (width * height) * 0.01  # ì´ë¯¸ì§€ì˜ 1% ì´ìƒ
            max_area = (width * height) * 0.8   # ì´ë¯¸ì§€ì˜ 80% ì´í•˜
            
            if bbox_area < min_area or bbox_area > max_area:
                continue
            
            # 3. ì¢…íš¡ë¹„ í•„í„°ë§ (ì‚¬ëŒì€ ì„¸ë¡œë¡œ ê¸´ í˜•íƒœ)
            aspect_ratio = bbox_height / bbox_width
            if aspect_ratio < 1.2:  # ë†’ì´ê°€ ë„ˆë¹„ë³´ë‹¤ 1.2ë°° ì´ìƒ
                continue
            
            # 4. ì´ë¯¸ì§€ ê²½ê³„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
            if x1 < 0 or y1 < 0 or x2 > width or y2 > height:
                continue
            
            # 5. ì¤‘ë³µ ì œê±° (IoU ê¸°ë°˜)
            is_duplicate = False
            for existing_mask, existing_box, _ in filtered:
                existing_x1, existing_y1, existing_x2, existing_y2 = existing_box.cpu().numpy()
                
                # IoU ê³„ì‚°
                intersection_x1 = max(x1, existing_x1)
                intersection_y1 = max(y1, existing_y1)
                intersection_x2 = min(x2, existing_x2)
                intersection_y2 = min(y2, existing_y2)
                
                if intersection_x2 > intersection_x1 and intersection_y2 > intersection_y1:
                    intersection_area = (intersection_x2 - intersection_x1) * (intersection_y2 - intersection_y1)
                    union_area = bbox_area + (existing_x2 - existing_x1) * (existing_y2 - existing_y1) - intersection_area
                    iou = intersection_area / union_area if union_area > 0 else 0
                    
                    if iou > 0.3:  # IoUê°€ 0.3 ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                filtered.append((mask, box, conf))
                print(f"  - Kept detection {i+1}: bbox={[int(x1), int(y1), int(x2), int(y2)]}, "
                      f"area={bbox_area:.0f}, aspect_ratio={aspect_ratio:.2f}, conf={conf:.3f}")
        
        # 6. ìµœëŒ€ 3ëª…ê¹Œì§€ë§Œ ì„ íƒ (confidence ìˆœìœ¼ë¡œ ì •ë ¬)
        filtered.sort(key=lambda x: x[2], reverse=True)
        filtered = filtered[:3]
        
        return filtered
    
    def _create_visualization(self, person_data, original_image):
        """ë°œí‘œìš© ì‹œê°í™” ìƒì„±"""
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”©ë°•ìŠ¤ í‘œì‹œ
        vis_image = original_image.copy()
        # ì‹¤ì œ ì˜· ìƒ‰ìƒì— ë§ê²Œ ì¡°ì •: ì´ˆë¡ìƒ‰, í•‘í¬ìƒ‰, íŒŒë€ìƒ‰
        colors = [(0, 255, 0), (255, 192, 203), (0, 0, 255)]  # ì´ˆë¡, í•‘í¬, íŒŒë€ìƒ‰
        
        for i, (person_id, person) in enumerate(person_data.items()):
            x1, y1, x2, y2 = person['bbox']
            color = colors[i % len(colors)]
            
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(vis_image, person['name'], (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        cv2.imwrite(f'{self.output_dir}/annotated_image.jpg', vis_image)
        
        # 2. ë°œí‘œìš© í•µì‹¬ ê·¸ë˜í”„: ìƒ‰ìƒ ë¶„í¬ + ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        fig = plt.figure(figsize=(16, 8))
        
        # ì™¼ìª½: ìƒ‰ìƒ ë¶„í¬ ë¹„êµ
        ax1 = plt.subplot(1, 2, 1)
        
        for i, (person_id, person) in enumerate(person_data.items()):
            hist = person['histograms']['h']  # Hue ì±„ë„
            color = colors[i % len(colors)]
            ax1.plot(hist, label=person['name'], color=tuple(c/255 for c in color), 
                    linewidth=3, marker='o', markersize=4)
        
        ax1.set_title('Color Distribution Differences (Hue Channel)', fontsize=16, fontweight='bold')
        ax1.set_xlabel('Color Bins', fontsize=12)
        ax1.set_ylabel('Normalized Frequency', fontsize=12)
        ax1.legend(fontsize=12)
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 1)
        
        # ì˜¤ë¥¸ìª½: ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        ax2 = plt.subplot(1, 2, 2)
        
        person_ids = list(person_data.keys())
        similarity_matrix = np.zeros((len(person_ids), len(person_ids)))
        
        for i, id1 in enumerate(person_ids):
            for j, id2 in enumerate(person_ids):
                if i == j:
                    similarity_matrix[i, j] = 1.0
                else:
                    hist1 = person_data[id1]['histograms']['combined']
                    hist2 = person_data[id2]['histograms']['combined']
                    similarity_matrix[i, j] = self.calculate_similarity(hist1, hist2)
        
        # íˆíŠ¸ë§µ ìƒì„±
        im = sns.heatmap(similarity_matrix, 
                        xticklabels=[person_data[pid]['name'] for pid in person_ids],
                        yticklabels=[person_data[pid]['name'] for pid in person_ids],
                        annot=True, cmap='RdYlBu_r', vmin=0, vmax=1, fmt='.3f',
                        cbar_kws={'label': 'Similarity Score'}, ax=ax2)
        
        ax2.set_title('Person Re-identification (Color Similarity Matrix)', fontsize=16, fontweight='bold')
        
        # ì „ì²´ ì œëª© (í•œ ì¤„ë¡œ ì¤„ì„)
        fig.suptitle('Person Re-identification using Color Distribution Analysis', 
                    fontsize=18, fontweight='bold', y=0.98)
        
        # ì„¤ëª… í…ìŠ¤íŠ¸ ì¶”ê°€
        fig.text(0.5, 0.02, 
                'Left: Different color distributions enable person distinction\nRight: Low similarity scores confirm different persons', 
                ha='center', fontsize=12, style='italic')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.9, bottom=0.15)
        plt.savefig(f'{self.output_dir}/presentation_chart.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Presentation chart saved: {self.output_dir}/presentation_chart.png")
    
    def _analyze_similarities(self, person_data):
        """ìœ ì‚¬ë„ ë¶„ì„"""
        person_ids = list(person_data.keys())
        
        print("\n=== Color Similarity Analysis ===")
        
        for i, id1 in enumerate(person_ids):
            for j, id2 in enumerate(person_ids):
                if i < j:  # ì¤‘ë³µ ì œê±°
                    hist1 = person_data[id1]['histograms']['combined']
                    hist2 = person_data[id2]['histograms']['combined']
                    
                    similarity = self.calculate_similarity(hist1, hist2)
                    
                    print(f"\n{person_data[id1]['name']} vs {person_data[id2]['name']}:")
                    print(f"  - Similarity: {similarity:.4f}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ–¼ï¸ Simple Person Color Analysis")
    
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
        
        if not os.path.exists(image_path):
            print(f"Image file does not exist: {image_path}")
            return
        
        analyzer = SimplePersonColorAnalyzer()
        results = analyzer.analyze_image(image_path)
        
        if results:
            print(f"âœ… Analysis completed! Analyzed {len(results)} persons.")
        else:
            print("âŒ Analysis failed.")
    else:
        print("Usage: python3 simple_person_color_analysis.py <image_path>")
        print("Example: python3 simple_person_color_analysis.py /path/to/image.jpg")

if __name__ == "__main__":
    main() 