"""
Sliding Window ë°©ì‹ìœ¼ë¡œ ì œìŠ¤ì²˜ ë°ì´í„° ìƒì„±
- ì›ë³¸ ì˜ìƒì—ì„œ ê´€ì ˆì  ì¶”ì¶œ (í”„ë ˆì„ ìˆ˜ ê·¸ëŒ€ë¡œ ìœ ì§€)
- ì§§ì€ ì‹œí€€ìŠ¤ (30í”„ë ˆì„)ë¡œ sliding window ì ìš©
- ë” ë§ì€ ìƒ˜í”Œ ìƒì„±
"""

import cv2
import numpy as np
import os
import glob
from ultralytics import YOLO
from pathlib import Path

class SlidingWindowPoseExtractor:
    """Sliding Window ë°©ì‹ì˜ ê´€ì ˆì  ì¶”ì¶œê¸°"""
    
    def __init__(self, model_path='yolov8n-pose.pt', target_joints='upper_body'):
        # GPU ì‚¬ìš© ì„¤ì •
        import torch
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {self.device}")
        
        self.model = YOLO(model_path)
        # YOLO ëª¨ë¸ì„ GPUë¡œ ì´ë™
        if torch.cuda.is_available():
            self.model.to(self.device)
        
        self.target_joints = target_joints
        
        # ê´€ì ˆì  ì¸ë±ìŠ¤ ì •ì˜
        self.joint_indices = {
            'arms_only': [5, 6, 7, 8, 9, 10],  # ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©
            'upper_body': [0, 5, 6, 7, 8, 9, 10, 11, 12],  # ì½”, ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©, ì—‰ë©ì´
            'full_body': list(range(17))  # ì „ì‹ 
        }
        
        # ê´€ì ˆì  ì—°ê²° ì •ì˜
        self.edges = {
            'arms_only': [
                (0, 1), (0, 2), (1, 3), (2, 4), (3, 5)
            ],
            'upper_body': [
                (0, 1), (0, 2), (1, 2), (1, 3), (2, 4),
                (3, 5), (4, 6), (1, 7), (2, 8), (7, 8)
            ],
            'full_body': [
                (0, 1), (0, 2), (1, 3), (2, 4), (5, 6), (5, 7), (6, 8), 
                (7, 9), (8, 10), (5, 11), (6, 12), (11, 12),
                (11, 13), (12, 14), (13, 15), (14, 16)
            ]
        }
        
        self.selected_indices = self.joint_indices[target_joints]
        self.num_joints = len(self.selected_indices)
        
        print(f"âœ… Sliding Window Pose ì¶”ì¶œê¸° ì´ˆê¸°í™”")
        print(f"   - ê´€ì ˆì  ë²”ìœ„: {target_joints} ({self.num_joints}ê°œ)")
    
    def extract_keypoints_from_video(self, video_path):
        """ë¹„ë””ì˜¤ì—ì„œ ê´€ì ˆì  ì¶”ì¶œ (ì›ë³¸ í”„ë ˆì„ ìˆ˜ ìœ ì§€)"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
            return None
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        keypoints_sequence = []
        frame_idx = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # YOLO Pose ì¶”ë¡ 
            results = self.model(frame, verbose=False)
            
            if results[0].keypoints is not None and len(results[0].keypoints.data) > 0:
                # ì²« ë²ˆì§¸ ì‚¬ëŒì˜ ê´€ì ˆì ë§Œ ì‚¬ìš©
                all_keypoints = results[0].keypoints.data[0].cpu().numpy()  # (17, 3)
                
                # ì„ íƒëœ ê´€ì ˆì ë§Œ ì¶”ì¶œ
                selected_keypoints = all_keypoints[self.selected_indices]  # (V, 3)
                
                # ì‹ ë¢°ë„ ì²´í¬
                if np.all(selected_keypoints[:, 2] > 0.3):
                    keypoints_sequence.append(selected_keypoints)
                else:
                    # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ì´ì „ í”„ë ˆì„ ë³µì‚¬
                    if len(keypoints_sequence) > 0:
                        keypoints_sequence.append(keypoints_sequence[-1].copy())
                    else:
                        # ì²« í”„ë ˆì„ì¸ ê²½ìš° ì¼ë‹¨ ì €ì¥
                        keypoints_sequence.append(selected_keypoints)
            else:
                # ê´€ì ˆì ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì´ì „ í”„ë ˆì„ ë³µì‚¬
                if len(keypoints_sequence) > 0:
                    keypoints_sequence.append(keypoints_sequence[-1].copy())
                else:
                    # ì²« í”„ë ˆì„ì¸ ê²½ìš° ì˜ë²¡í„° ì €ì¥
                    keypoints_sequence.append(np.zeros((self.num_joints, 3)))
            
            frame_idx += 1
        
        cap.release()
        
        if len(keypoints_sequence) == 0:
            print(f"âŒ ê´€ì ˆì  ì¶”ì¶œ ì‹¤íŒ¨: {video_path}")
            return None
        
        keypoints_array = np.array(keypoints_sequence)  # (T, V, 3)
        print(f"âœ… ê´€ì ˆì  ì¶”ì¶œ: {os.path.basename(video_path)}")
        print(f"   - ì‹¤ì œ í”„ë ˆì„: {keypoints_array.shape[0]} (ì˜ˆìƒ: {total_frames})")
        print(f"   - FPS: {fps:.1f}")
        
        return keypoints_array
    
    def normalize_keypoints(self, keypoints):
        """ê´€ì ˆì  ì •ê·œí™”"""
        if keypoints is None:
            return None
        
        normalized_keypoints = keypoints.copy()
        
        for t in range(keypoints.shape[0]):
            frame_keypoints = keypoints[t]  # (V, 3)
            
            # ìœ íš¨í•œ ê´€ì ˆì ë§Œ ì‚¬ìš©
            valid_joints = frame_keypoints[:, 2] > 0
            
            if np.any(valid_joints):
                valid_points = frame_keypoints[valid_joints]
                
                # ì¤‘ì‹¬ì  ê³„ì‚°
                center_x = np.mean(valid_points[:, 0])
                center_y = np.mean(valid_points[:, 1])
                
                # ìŠ¤ì¼€ì¼ ê³„ì‚°
                scale = np.std(valid_points[:, :2])
                if scale == 0:
                    scale = 1.0
                
                # ì •ê·œí™” ì ìš©
                normalized_keypoints[t, :, 0] = (frame_keypoints[:, 0] - center_x) / scale
                normalized_keypoints[t, :, 1] = (frame_keypoints[:, 1] - center_y) / scale
        
        return normalized_keypoints
    
    def create_sliding_windows(self, keypoints, window_size=30, stride=1):
        """
        Sliding windowë¡œ ë°ì´í„° ë¶„í• 
        
        Args:
            keypoints: (T, V, 3) í˜•íƒœì˜ ê´€ì ˆì  ë°ì´í„°
            window_size: ìœˆë„ìš° í¬ê¸° (í”„ë ˆì„ ìˆ˜)
            stride: ìŠ¬ë¼ì´ë”© ê°„ê²©
            
        Returns:
            windows: ìœˆë„ìš°ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if keypoints is None:
            return []
        
        T, V, C = keypoints.shape
        windows = []
        
        # Sliding window ìƒì„±
        for start in range(0, T - window_size + 1, stride):
            end = start + window_size
            window = keypoints[start:end]  # (window_size, V, 3)
            windows.append(window)
        
        print(f"   - ì›ë³¸ í”„ë ˆì„: {T}")
        print(f"   - ìœˆë„ìš° í¬ê¸°: {window_size}")
        print(f"   - ìƒì„±ëœ ìœˆë„ìš°: {len(windows)}ê°œ")
        
        return windows
    
    def convert_to_shift_gcn_format(self, window):
        """
        ìœˆë„ìš°ë¥¼ Shift-GCN í˜•íƒœë¡œ ë³€í™˜
        
        Args:
            window: (T, V, 3) í˜•íƒœì˜ ìœˆë„ìš° ë°ì´í„°
            
        Returns:
            shift_gcn_data: (3, T, V, 1) í˜•íƒœì˜ ë°ì´í„°
        """
        T, V, C = window.shape
        M = 1  # ì‚¬ëŒ ìˆ˜
        
        # (T, V, C) -> (C, T, V, M) ë³€í™˜
        shift_gcn_data = np.zeros((C, T, V, M))
        shift_gcn_data[:, :, :, 0] = window.transpose(2, 0, 1)  # (C, T, V)
        
        return shift_gcn_data
    
    def create_adjacency_matrix(self):
        """Shift-GCNìš© adjacency matrix ìƒì„±"""
        A = np.zeros((self.num_joints, self.num_joints))
        
        # self-connection
        for i in range(self.num_joints):
            A[i, i] = 1
        
        # joint connections
        edges = self.edges[self.target_joints]
        for i, j in edges:
            A[i, j] = 1
            A[j, i] = 1
        
        return A

def process_videos_sliding_window(video_dir, output_dir, target_joints='upper_body', 
                                window_size=30, stride=1):
    """
    Sliding window ë°©ì‹ìœ¼ë¡œ ì œìŠ¤ì²˜ ë¹„ë””ì˜¤ ì²˜ë¦¬
    
    Args:
        video_dir: ë¹„ë””ì˜¤ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        target_joints: ì¶”ì¶œí•  ê´€ì ˆì  ë²”ìœ„
        window_size: ìœˆë„ìš° í¬ê¸° (í”„ë ˆì„ ìˆ˜)
        stride: ìŠ¬ë¼ì´ë”© ê°„ê²©
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = SlidingWindowPoseExtractor(target_joints=target_joints)
    
    # ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
    video_extensions = ['*.mp4', '*.avi', '*.mov']
    video_files = []
    for ext in video_extensions:
        video_files.extend(glob.glob(os.path.join(video_dir, '**', ext), recursive=True))
    
    print(f"ğŸ“¹ ì°¾ì€ ë¹„ë””ì˜¤ íŒŒì¼: {len(video_files)}ê°œ")
    
    if len(video_files) == 0:
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_dir}")
        return
    
    # ì•¡ì…˜ë³„ ë°ì´í„° ìˆ˜ì§‘
    action_data = {}
    
    for video_path in video_files:
        print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {os.path.basename(video_path)}")
        
        # ì•¡ì…˜ëª… ì¶”ì¶œ
        path_parts = Path(video_path).parts
        action_name = None
        
        for part in reversed(path_parts):
            if part.lower() in ['come', 'normal']:
                action_name = part.lower()
                break
        
        if action_name is None:
            filename = os.path.basename(video_path).lower()
            if 'come' in filename:
                action_name = 'come'
            elif 'normal' in filename:
                action_name = 'normal'
        
        if action_name is None:
            print(f"âš ï¸ ì•¡ì…˜ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            continue
        
        # ê´€ì ˆì  ì¶”ì¶œ (ì›ë³¸ í”„ë ˆì„ ìˆ˜ ìœ ì§€)
        keypoints = extractor.extract_keypoints_from_video(video_path)
        
        if keypoints is not None:
            # ì •ê·œí™”
            normalized_keypoints = extractor.normalize_keypoints(keypoints)
            
            # Sliding window ìƒì„±
            windows = extractor.create_sliding_windows(
                normalized_keypoints, 
                window_size=window_size, 
                stride=stride
            )
            
            if action_name not in action_data:
                action_data[action_name] = []
            
            # ê° ìœˆë„ìš°ë¥¼ Shift-GCN í˜•íƒœë¡œ ë³€í™˜
            for window in windows:
                shift_gcn_data = extractor.convert_to_shift_gcn_format(window)
                action_data[action_name].append({
                    'data': shift_gcn_data,
                    'video_path': video_path
                })
    
    # ë°ì´í„° ì €ì¥
    print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    
    total_samples = 0
    for action_name, samples in action_data.items():
        print(f"ğŸ“Š {action_name}: {len(samples)}ê°œ ìœˆë„ìš°")
        total_samples += len(samples)
        
        # ì•¡ì…˜ë³„ ë°ì´í„° í•©ì¹˜ê¸°
        all_data = []
        labels = []
        
        for sample in samples:
            all_data.append(sample['data'])
            labels.append(action_name)
        
        if len(all_data) > 0:
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            data_array = np.array(all_data)  # (N, C, T, V, M)
            
            # ì €ì¥
            data_file = os.path.join(output_dir, f'{action_name}_pose_data.npy')
            labels_file = os.path.join(output_dir, f'{action_name}_labels.npy')
            
            np.save(data_file, data_array)
            np.save(labels_file, labels)
            
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {data_file}")
            print(f"   - Shape: {data_array.shape}")
    
    # ì¸ì ‘ í–‰ë ¬ ì €ì¥
    adjacency_matrix = extractor.create_adjacency_matrix()
    adj_file = os.path.join(output_dir, 'adjacency_matrix.npy')
    np.save(adj_file, adjacency_matrix)
    print(f"âœ… ì¸ì ‘ í–‰ë ¬ ì €ì¥: {adj_file}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'target_joints': target_joints,
        'num_joints': extractor.num_joints,
        'joint_indices': extractor.selected_indices,
        'window_size': window_size,
        'stride': stride,
        'actions': list(action_data.keys()),
        'total_samples': total_samples
    }
    
    metadata_file = os.path.join(output_dir, 'metadata.npy')
    np.save(metadata_file, metadata)
    print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_file}")
    
    print(f"\nğŸ‰ Sliding Window ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    print(f"   - ì´ ìƒ˜í”Œ: {total_samples}ê°œ (ê¸°ì¡´ 100ê°œ -> {total_samples}ê°œ)")
    print(f"   - ìœˆë„ìš° í¬ê¸°: {window_size} í”„ë ˆì„ (ê¸°ì¡´ 90 í”„ë ˆì„)")
    print(f"   - ë°ì´í„° ì¦ê°•: {total_samples/100:.1f}ë°° ì¦ê°€")

if __name__ == "__main__":
    video_dir = "./pose_dataset"
    output_dir = "./shift_gcn_data_sliding"
    
    print("ğŸš€ Sliding Window ë°©ì‹ ë°ì´í„° ìƒì„± ì‹œì‘")
    print("=" * 60)
    print("ğŸ“‹ ì„¤ì •:")
    print("   - ìœˆë„ìš° í¬ê¸°: 30 í”„ë ˆì„ (1ì´ˆ)")
    print("   - ìŠ¬ë¼ì´ë”© ê°„ê²©: 1 í”„ë ˆì„")
    print("   - ì˜ˆìƒ ì¦ê°€: ê° 3ì´ˆ ì˜ìƒ â†’ ì•½ 36ê°œ ìœˆë„ìš°")
    print("   - ì´ ì˜ˆìƒ ìƒ˜í”Œ: 100ê°œ ì˜ìƒ â†’ ì•½ 3600ê°œ ìœˆë„ìš°")
    
    process_videos_sliding_window(
        video_dir=video_dir,
        output_dir=output_dir,
        target_joints='upper_body',
        window_size=30,  # 30 í”„ë ˆì„ (ì•½ 1ì´ˆ)
        stride=1         # 1 í”„ë ˆì„ì”© ìŠ¬ë¼ì´ë”©
    ) 