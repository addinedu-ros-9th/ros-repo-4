import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os
import glob
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class HandGestureDataset(Dataset):
    """ì† ì œìŠ¤ì²˜ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì§„ì§œ Shift-GCNìš©)"""
    def __init__(self, data_paths, labels):
        self.data_paths = data_paths
        self.labels = labels
        self.samples = []
        
        # ê° íŒŒì¼ì—ì„œ ì‹œí€€ìŠ¤ë“¤ì„ ê°œë³„ ìƒ˜í”Œë¡œ ë¶„ë¦¬
        for file_path, label in zip(data_paths, labels):
            data = np.load(file_path)
            # data shape: (num_sequences, 60, 100)
            for i in range(data.shape[0]):
                self.samples.append((data[i], label))  # (sequence, label)
        
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        # ê°œë³„ ì‹œí€€ìŠ¤ì™€ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
        sequence, label = self.samples[idx]
        
        # ë°ì´í„° í˜•íƒœ: (60, 100) - 60í”„ë ˆì„, 100íŠ¹ì§• (99 + 1ë¼ë²¨)
        frames = sequence.shape[0]  # 60
        features = sequence.shape[1] - 1  # 99 (ë¼ë²¨ ì œì™¸)
        
        # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ ë¶„ë¦¬
        x = sequence[:, :-1].astype(np.float32)  # íŠ¹ì§• ë°ì´í„° (60, 99)
        y = int(sequence[0, -1])  # ë¼ë²¨ (ì²« ë²ˆì§¸ í”„ë ˆì„ì˜ ë¼ë²¨ ì‚¬ìš©)
        
        # ëœë“œë§ˆí¬ ì¢Œí‘œë§Œ ì¶”ì¶œ (x, y, z)
        # 21ê°œ ê´€ì ˆ Ã— 4 (x, y, z, visibility) = 84
        landmarks = x[:, :84]  # (60, 84)
        
        # (60, 84) -> (60, 21, 4) -> (60, 21, 3) - visibility ì œê±°
        landmarks = landmarks.reshape(60, 21, 4)  # (60, 21, 4)
        landmarks = landmarks[:, :, :3]  # (60, 21, 3) - x, y, zë§Œ ì‚¬ìš©
        
        # ë””ë²„ê·¸ ì¶œë ¥ (ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ)
        if idx == 0:
            print(f"ğŸ” ë°ì´í„°ì…‹ ë””ë²„ê·¸:")
            print(f"  ì›ë³¸ sequence shape: {sequence.shape}")
            print(f"  íŠ¹ì§• ë°ì´í„° x shape: {x.shape}")
            print(f"  ëœë“œë§ˆí¬ shape: {landmarks.shape}")
            print(f"  ë¼ë²¨: {y}")
        
        return torch.FloatTensor(landmarks), torch.LongTensor([y])

class ShiftGCNLayer(nn.Module):
    """Shift-GCN ë ˆì´ì–´"""
    def __init__(self, in_channels, out_channels, adjacency_matrix, num_adj=8):
        super(ShiftGCNLayer, self).__init__()
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_adj = num_adj
        
        # ì¸ì ‘ í–‰ë ¬ ë¶„í• 
        A_list = self._split_adjacency_matrix(adjacency_matrix)
        # ë¦¬ìŠ¤íŠ¸ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        self.register_buffer('A_list', torch.stack(A_list))
        
        # ê° ë¶„í• ì— ëŒ€í•œ ì»¨ë³¼ë£¨ì…˜
        self.conv_list = nn.ModuleList([
            nn.Conv2d(in_channels, out_channels // num_adj, 
                     kernel_size=1, bias=False)
            for _ in range(num_adj)
        ])
        
        # ì”ì°¨ ì—°ê²°
        if in_channels != out_channels:
            self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1)
        else:
            self.residual = nn.Identity()
        
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()
        
    def _split_adjacency_matrix(self, A):
        """ì¸ì ‘ í–‰ë ¬ì„ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• """
        A_list = []
        
        # ê¸°ë³¸ ì¸ì ‘ í–‰ë ¬
        A_list.append(A)
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ì¸ì ‘ í–‰ë ¬ë“¤ (1-hop, 2-hop, ...)
        A_power = A.clone()
        for _ in range(self.num_adj - 1):
            A_power = torch.mm(A_power, A)
            A_list.append(A_power)
        
        return A_list
    
    def forward(self, x):
        # x shape: (batch_size, in_channels, num_frames, num_joints)
        batch_size, in_channels, num_frames, num_joints = x.size()
        
        # Shift-GCN ì—°ì‚°
        out_list = []
        for i in range(self.num_adj):
            A = self.A_list[i]  # (num_joints, num_joints)
            conv = self.conv_list[i]
            
            # ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ - einsum ì‚¬ìš©
            # x: (batch_size, in_channels, num_frames, num_joints)
            # A: (num_joints, num_joints)
            # einsum('bcfj,jk->bcfk', x, A): (batch_size, in_channels, num_frames, num_joints)
            graph_conv = torch.einsum('bcfj,jk->bcfk', x, A)
            conv_out = conv(graph_conv)
            out_list.append(conv_out)
        
        # ê²°ê³¼ ê²°í•©
        out = torch.cat(out_list, dim=1)  # (batch_size, out_channels, num_frames, num_joints)
        
        # ì”ì°¨ ì—°ê²°
        residual = self.residual(x)
        out = out + residual
        
        # BatchNormê³¼ ReLU
        out = self.bn(out)
        out = self.relu(out)
        
        return out

class RealShiftGCN(nn.Module):
    """ì§„ì§œ Shift-GCN ëª¨ë¸ êµ¬í˜„"""
    def __init__(self, num_classes=3, num_frames=60, num_joints=21, num_features=3):
        super(RealShiftGCN, self).__init__()
        
        self.num_classes = num_classes
        self.num_frames = num_frames
        self.num_joints = num_joints
        self.num_features = num_features  # x, y, z
        
        # ì† ê´€ì ˆ ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜ (MediaPipe Hands ê¸°ì¤€)
        # 21ê°œ ê´€ì ˆì˜ ì—°ê²° ê´€ê³„
        self.hand_connections = [
            # ì—„ì§€
            (0, 1), (1, 2), (2, 3), (3, 4),
            # ê²€ì§€
            (0, 5), (5, 6), (6, 7), (7, 8),
            # ì¤‘ì§€
            (0, 9), (9, 10), (10, 11), (11, 12),
            # ì•½ì§€
            (0, 13), (13, 14), (14, 15), (15, 16),
            # ìƒˆë¼
            (0, 17), (17, 18), (18, 19), (19, 20),
            # ì†ë°”ë‹¥ ì—°ê²°
            (5, 9), (9, 13), (13, 17)
        ]
        
        # ì¸ì ‘ í–‰ë ¬ ìƒì„±
        self.register_buffer('A', self._build_adjacency_matrix())
        
        # Shift-GCN ë ˆì´ì–´ë“¤
        self.gcn_layers = nn.ModuleList([
            ShiftGCNLayer(3, 64, self.A),    # 3 -> 64
            ShiftGCNLayer(64, 128, self.A),  # 64 -> 128
            ShiftGCNLayer(128, 256, self.A), # 128 -> 256
        ])
        
        # Temporal CNN
        self.temporal_conv = nn.Sequential(
            nn.Conv1d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm1d(512)
        )
        
        # Global Average Pooling
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        
        # Classifier
        self.classifier = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )
        
    def _build_adjacency_matrix(self):
        """ì¸ì ‘ í–‰ë ¬ ìƒì„±"""
        A = torch.zeros(self.num_joints, self.num_joints)
        for i, j in self.hand_connections:
            A[i, j] = 1
            A[j, i] = 1  # ë¬´ë°©í–¥ ê·¸ë˜í”„
        # ìê¸° ìì‹ ê³¼ì˜ ì—°ê²°
        A += torch.eye(self.num_joints)
        return A
    
    def forward(self, x):
        # x shape: (batch_size, num_frames, num_joints, num_features)
        batch_size, num_frames, num_joints, num_features = x.size()
        
        # ë””ë²„ê·¸ ì¶œë ¥ (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
        if batch_size > 0:
            print(f"ğŸ” ëª¨ë¸ ì…ë ¥ ë””ë²„ê·¸:")
            print(f"  ì…ë ¥ x shape: {x.shape}")
            print(f"  batch_size: {batch_size}, num_frames: {num_frames}, num_joints: {num_joints}, num_features: {num_features}")
        
        # (batch_size, num_frames, num_joints, num_features) -> (batch_size, num_features, num_frames, num_joints)
        x = x.permute(0, 3, 1, 2)  # (batch_size, 3, num_frames, num_joints)
        
        # GCN ë ˆì´ì–´ë“¤ í†µê³¼
        gcn_out = x
        for gcn_layer in self.gcn_layers:
            gcn_out = gcn_layer(gcn_out)
        
        # Temporal modeling
        # (batch_size, 256, num_frames, num_joints) -> (batch_size, 256, num_frames)
        gcn_out = gcn_out.mean(dim=3)  # ê´€ì ˆ ì°¨ì› í‰ê· 
        
        # Temporal CNN
        temporal_out = self.temporal_conv(gcn_out)
        
        # Global pooling
        pooled = self.global_pool(temporal_out)  # (batch_size, 512, 1)
        pooled = pooled.squeeze(-1)  # (batch_size, 512)
        
        # Classification
        output = self.classifier(pooled)
        
        return output

def load_dataset(data_dir):
    """ë°ì´í„°ì…‹ ë¡œë“œ"""
    print("ğŸ“ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° íŒŒì¼ë“¤ ì°¾ê¸°
    seq_files = glob.glob(os.path.join(data_dir, 'seq_*.npy'))
    
    if not seq_files:
        print("âš ï¸ ì‹œí€€ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # ì›ì‹œ ë°ì´í„° íŒŒì¼ë“¤ ì°¾ê¸°
        raw_files = glob.glob(os.path.join(data_dir, 'raw_*.npy'))
        if not raw_files:
            raise FileNotFoundError("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        data_files = raw_files
    else:
        data_files = seq_files
    
    print(f"ğŸ“Š ë°œê²¬ëœ ë°ì´í„° íŒŒì¼: {len(data_files)}ê°œ")
    
    # íŒŒì¼ë³„ë¡œ ë¼ë²¨ ì¶”ì¶œ
    data_paths = []
    labels = []
    
    for file_path in data_files:
        filename = os.path.basename(file_path)
        
        # ë¼ë²¨ ì¶”ì¶œ (come=0, away=1, stop=2)
        if 'come' in filename:
            label = 0
        elif 'away' in filename:
            label = 1
        elif 'stop' in filename:
            label = 2
        else:
            continue
            
        data_paths.append(file_path)
        labels.append(label)
    
    print(f"ğŸ“ˆ í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜:")
    for i, action in enumerate(['come', 'away', 'stop']):
        count = labels.count(i)
        print(f"  {action}: {count}ê°œ")
    
    return data_paths, labels

def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=0.001):
    """ëª¨ë¸ í•™ìŠµ"""
    print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)
    
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    
    best_val_acc = 0.0
    
    for epoch in range(num_epochs):
        # í•™ìŠµ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_x, batch_y in train_loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.squeeze().to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += batch_y.size(0)
            train_correct += (predicted == batch_y).sum().item()
        
        # ê²€ì¦
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                batch_x = batch_x.to(device)
                batch_y = batch_y.squeeze().to(device)
                
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += batch_y.size(0)
                val_correct += (predicted == batch_y).sum().item()
        
        # í†µê³„ ê³„ì‚°
        train_loss = train_loss / len(train_loader)
        val_loss = val_loss / len(val_loader)
        train_acc = 100 * train_correct / train_total
        val_acc = 100 * val_correct / val_total
        
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        
        # í•™ìŠµë¥  ì¡°ì •
        scheduler.step()
        
        # ê²°ê³¼ ì¶œë ¥
        print(f'Epoch [{epoch+1}/{num_epochs}] - '
              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - '
              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), 'best_real_shift_gcn_model.pth')
            print(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (ê²€ì¦ ì •í™•ë„: {val_acc:.2f}%)")
    
    return train_losses, val_losses, train_accuracies, val_accuracies

def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ í”Œë¡¯"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì†ì‹¤ ê·¸ë˜í”„
    ax1.plot(train_losses, label='Train Loss')
    ax1.plot(val_losses, label='Validation Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True)
    
    # ì •í™•ë„ ê·¸ë˜í”„
    ax2.plot(train_accuracies, label='Train Accuracy')
    ax2.plot(val_accuracies, label='Validation Accuracy')
    ax2.set_title('Training and Validation Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('real_shift_gcn_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

def evaluate_model(model, test_loader):
    """ëª¨ë¸ í‰ê°€"""
    print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
    
    model.eval()
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.squeeze().to(device)
            
            outputs = model(batch_x)
            _, predicted = torch.max(outputs.data, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(batch_y.cpu().numpy())
    
    # ì •í™•ë„ ê³„ì‚°
    accuracy = accuracy_score(all_labels, all_predictions)
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # ë¶„ë¥˜ ë¦¬í¬íŠ¸
    print("\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(all_labels, all_predictions, 
                              target_names=['come', 'away', 'stop']))
    
    return accuracy

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ì§„ì§œ Shift-GCN ëª¨ë¸ í•™ìŠµ")
    print("ğŸ’¡ ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ + Shift ì—°ì‚° + ê´€ì ˆ ê´€ê³„ í•™ìŠµ")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    data_paths, labels = load_dataset('dataset')
    
    print(f"ğŸ“Š ì›ë³¸ ë°ì´í„°:")
    for i, action in enumerate(['come', 'away', 'stop']):
        count = labels.count(i)
        print(f"  {action}: {count}ê°œ")
    
    # ë°ì´í„°ì…‹ ìƒì„± (ì‹œí€€ìŠ¤ë“¤ì´ ê°œë³„ ìƒ˜í”Œë¡œ ë¶„ë¦¬ë¨)
    train_dataset = HandGestureDataset(data_paths, labels)
    
    # ì „ì²´ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    total_samples = len(train_dataset)
    print(f"ğŸ“Š ì´ ì‹œí€€ìŠ¤ ìƒ˜í”Œ: {total_samples}ê°œ")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    class_counts = [0, 0, 0]
    for _, label in train_dataset.samples:
        class_counts[label] += 1
    
    print(f"ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì‹œí€€ìŠ¤ ìˆ˜:")
    for i, action in enumerate(['come', 'away', 'stop']):
        print(f"  {action}: {class_counts[i]}ê°œ")
    
    # ë°ì´í„° ë¶„í•  (stratify ì‚¬ìš© ê°€ëŠ¥)
    all_samples = list(range(total_samples))
    all_labels = [label for _, label in train_dataset.samples]
    
    X_train, X_temp, y_train, y_temp = train_test_split(
        all_samples, all_labels, test_size=0.3, random_state=42, stratify=all_labels
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
    print(f"  í•™ìŠµ: {len(X_train)}ê°œ")
    print(f"  ê²€ì¦: {len(X_val)}ê°œ")
    print(f"  í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
    
    # ì„œë¸Œì…‹ ë°ì´í„°ì…‹ ìƒì„±
    class SubsetDataset(Dataset):
        def __init__(self, full_dataset, indices):
            self.full_dataset = full_dataset
            self.indices = indices
            
        def __len__(self):
            return len(self.indices)
            
        def __getitem__(self, idx):
            return self.full_dataset[self.indices[idx]]
    
    train_subset = SubsetDataset(train_dataset, X_train)
    val_subset = SubsetDataset(train_dataset, X_val)
    test_subset = SubsetDataset(train_dataset, X_test)
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    batch_size = 16  # GCNì€ ë” ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©
    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)
    
    # ëª¨ë¸ ìƒì„± (ì§„ì§œ Shift-GCN)
    model = RealShiftGCN(num_classes=3, num_frames=60, num_joints=21, num_features=3)
    model = model.to(device)
    
    print(f"ğŸ“ˆ ëª¨ë¸ êµ¬ì¡° (ì§„ì§œ Shift-GCN):")
    print(f"  - ì…ë ¥: 60í”„ë ˆì„ Ã— 21ê´€ì ˆ Ã— 3ì¢Œí‘œ")
    print(f"  - ê·¸ë˜í”„ êµ¬ì¡°: 21ê°œ ê´€ì ˆ ì—°ê²° ê´€ê³„")
    print(f"  - Shift ì—°ì‚°: 8ê°œ ì¸ì ‘ í–‰ë ¬ ë¶„í• ")
    print(f"  - ì¶œë ¥: 3ê°œ í´ë˜ìŠ¤ (come, away, stop)")
    print(f"  - íŠ¹ì§•:")
    print(f"    â€¢ Graph Convolution: ê´€ì ˆ ê°„ ê´€ê³„ í•™ìŠµ")
    print(f"    â€¢ Shift ì—°ì‚°: ì‹œê°„ì  íŒ¨í„´ í•™ìŠµ")
    print(f"    â€¢ ìë™ íŠ¹ì§• í•™ìŠµ: ìˆ˜ë™ íŠ¹ì„± ì—†ìŒ")
    print(model)
    
    # ëª¨ë¸ í•™ìŠµ
    train_losses, val_losses, train_accuracies, val_accuracies = train_model(
        model, train_loader, val_loader, num_epochs=50, learning_rate=0.001
    )
    
    # í•™ìŠµ íˆìŠ¤í† ë¦¬ í”Œë¡¯
    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
    if os.path.exists('best_real_shift_gcn_model.pth'):
        model.load_state_dict(torch.load('best_real_shift_gcn_model.pth'))
        
        # ëª¨ë¸ í‰ê°€
        test_accuracy = evaluate_model(model, test_loader)
        
        print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
        print(f"  - best_real_shift_gcn_model.pth (ì§„ì§œ Shift-GCN ëª¨ë¸)")
        print(f"  - real_shift_gcn_training_history.png (í•™ìŠµ íˆìŠ¤í† ë¦¬ ê·¸ë˜í”„)")
        print(f"ğŸ’¡ ì§„ì§œ Shift-GCN íŠ¹ì§•:")
        print(f"  - ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜: ê´€ì ˆ ê°„ ê³µê°„ì  ê´€ê³„ í•™ìŠµ")
        print(f"  - Shift ì—°ì‚°: ì‹œê°„ì  ë³€í™” íŒ¨í„´ í•™ìŠµ")
        print(f"  - ìë™ íŠ¹ì§• ë°œê²¬: ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ íŒ¨í„´ í•™ìŠµ")
    else:
        print("âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 