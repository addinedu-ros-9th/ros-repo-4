"""
YOLO Pose ê¸°ë°˜ ì œìŠ¤ì²˜ ë°ì´í„°ì…‹ ìƒì„± ë„êµ¬

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ì˜ìƒ ì €ì¥ ì†ë„ ë¬¸ì œ í•´ê²°:
   - ì •í™•í•œ í”„ë ˆì„ë ˆì´íŠ¸ ì œì–´ë¥¼ ìœ„í•œ FrameRateController í´ë˜ìŠ¤ ì¶”ê°€
   - H.264, XVID, MJPG ì½”ë± ìë™ ì„ íƒìœ¼ë¡œ ì•ˆì •ì ì¸ VideoWriter ìƒì„±
   - í”„ë ˆì„ ê°„ê²© ì •í™•ë„ ëª¨ë‹ˆí„°ë§ ë° í†µê³„ ì œê³µ

2. ì¹´ìš´íŠ¸ë‹¤ìš´ ë ‰ ë¬¸ì œ í•´ê²°:
   - cv2.waitKey(1000) ëŒ€ì‹  time.sleep(0.05)ì™€ ë¶€ë“œëŸ¬ìš´ ì—…ë°ì´íŠ¸ ë°©ì‹ ì‚¬ìš©
   - 50ms ê°„ê²©ìœ¼ë¡œ í™”ë©´ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¶€ë“œëŸ¬ìš´ ì¹´ìš´íŠ¸ë‹¤ìš´ êµ¬í˜„
   - ì‹¤ì‹œê°„ ë‚¨ì€ ì‹œê°„ í‘œì‹œ

3. ë™ì  í•´ìƒë„ ì§€ì›:
   - ì¹´ë©”ë¼ ìµœëŒ€ í•´ìƒë„ ìë™ ê°ì§€
   - í•´ìƒë„ í”„ë¦¬ì…‹ ì œê³µ (low/medium/high/full)
   - ì‹¤ì œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë§ëŠ” í’€ í•´ìƒë„ ëŒ€ì‘
   - í•´ìƒë„ë³„ ì˜ˆìƒ íŒŒì¼ í¬ê¸° ê³„ì‚°

4. ì¶”ê°€ ê¸°ëŠ¥:
   - ì‹¤ì‹œê°„ FPS ëª¨ë‹ˆí„°ë§
   - í”„ë ˆì„ ì •í™•ë„ ë° ê°„ê²© ì •í™•ë„ ë¶„ì„
   - ëŒ€ì•ˆì ì¸ ë…¹í™” ë°©ë²• ì œê³µ (record_action_alternative)

í•´ìƒë„ ì„¤ì •:
- RESOLUTION_MODE ë³€ìˆ˜ë¡œ í•´ìƒë„ ì„ íƒ
- 'low': 640x480 (ë¹ ë¥¸ ì²˜ë¦¬, ì‘ì€ íŒŒì¼)
- 'medium': 1280x720 (HD, ê· í˜•)
- 'high': 1920x1080 (Full HD, ê³ í’ˆì§ˆ)
- 'full': ì¹´ë©”ë¼ ìµœëŒ€ í•´ìƒë„ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ìš©)

ì‚¬ìš©ë²•:
- ê¸°ë³¸ ë…¹í™”: record_action() í•¨ìˆ˜ ì‚¬ìš©
- ëŒ€ì•ˆ ë…¹í™”: record_action_alternative() í•¨ìˆ˜ ì‚¬ìš©
- ë©”ì¸ í•¨ìˆ˜ì—ì„œ ì›í•˜ëŠ” ë°©ë²• ì„ íƒ ê°€ëŠ¥
"""

import cv2
import numpy as np
import time
import os
import threading

# ì œìŠ¤ì²˜ ì •ì˜
actions = ['come', 'normal']
secs_for_action = 3  # 3ì´ˆì”© ì´¬ì˜
num_samples = 50  # ê° ì•¡ì…˜ë‹¹ 50ê°œ ìƒ˜í”Œ

# í•´ìƒë„ ì„¤ì • ì˜µì…˜
RESOLUTION_PRESETS = {
    'low': (640, 480),      # ì €í•´ìƒë„ (ë¹ ë¥¸ ì²˜ë¦¬)
    'medium': (1280, 720),  # HD í•´ìƒë„
    'high': (1920, 1080),   # Full HD í•´ìƒë„
    'full': None            # ì¹´ë©”ë¼ ìµœëŒ€ í•´ìƒë„ ì‚¬ìš©
}

# ì‚¬ìš©í•  í•´ìƒë„ ì„ íƒ (ë³€ê²½ ê°€ëŠ¥)
RESOLUTION_MODE = 'full'  # 'low', 'medium', 'high', 'full' ì¤‘ ì„ íƒ

# ì¹´ë©”ë¼ ì„¤ì •
cap = cv2.VideoCapture('/dev/video0')

def setup_camera_resolution(cap, mode='full'):
    """ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •"""
    if mode in RESOLUTION_PRESETS:
        if RESOLUTION_PRESETS[mode] is None:  # full ëª¨ë“œ
            # ì¹´ë©”ë¼ê°€ ì§€ì›í•˜ëŠ” ìµœëŒ€ í•´ìƒë„ í™•ì¸
            max_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            max_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # ì¼ë°˜ì ì¸ ìµœëŒ€ í•´ìƒë„ë“¤ì„ ì‹œë„
            test_resolutions = [
                (3840, 2160),  # 4K
                (2560, 1440),  # 2K
                (1920, 1080),  # Full HD
                (1280, 720),   # HD
                (640, 480)     # VGA (fallback)
            ]
            
            width, height = 640, 480  # ê¸°ë³¸ê°’
            
            for test_w, test_h in test_resolutions:
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, test_w)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, test_h)
                
                actual_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                
                if actual_w == test_w and actual_h == test_h:
                    width, height = actual_w, actual_h
                    print(f"âœ… ìµœëŒ€ í•´ìƒë„ ì„¤ì • ì„±ê³µ: {width}x{height}")
                    break
            
            if width == 640 and height == 480:
                print("âš ï¸ ìµœëŒ€ í•´ìƒë„ ê°ì§€ ì‹¤íŒ¨, 640x480 ì‚¬ìš©")
                
        else:
            width, height = RESOLUTION_PRESETS[mode]
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            print(f"âœ… í•´ìƒë„ ì„¤ì •: {width}x{height} ({mode} ëª¨ë“œ)")
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í•´ìƒë„ ëª¨ë“œ: {mode}")
        width, height = 640, 480
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
    
    # ì‹¤ì œ ì„¤ì •ëœ í•´ìƒë„ í™•ì¸
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ“¹ ì‹¤ì œ ì¹´ë©”ë¼ í•´ìƒë„: {actual_width}x{actual_height}")
    
    return actual_width, actual_height

# ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •
camera_width, camera_height = setup_camera_resolution(cap, RESOLUTION_MODE)

# ì‹¤ì œ ì¹´ë©”ë¼ í”„ë ˆì„ë ˆì´íŠ¸ í™•ì¸
actual_fps = cap.get(cv2.CAP_PROP_FPS)
if actual_fps <= 0:
    actual_fps = 30.0  # ê¸°ë³¸ê°’
print(f"ğŸ“¹ ì¹´ë©”ë¼ í”„ë ˆì„ë ˆì´íŠ¸: {actual_fps} FPS")

# ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„± (ì•¡ì…˜ë³„ ë¶„ë¦¬)
created_time = int(time.time())
dataset_dir = './deeplearning/gesture_recognition/pose_dataset'
os.makedirs(dataset_dir, exist_ok=True)

# ì•¡ì…˜ë³„ í´ë” ìƒì„±
for action in actions:
    action_dir = os.path.join(dataset_dir, action)
    os.makedirs(action_dir, exist_ok=True)
    print(f"ğŸ“ í´ë” ìƒì„±: {action_dir}")

class FrameRateController:
    """ì •í™•í•œ í”„ë ˆì„ë ˆì´íŠ¸ ì œì–´ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, target_fps):
        self.target_fps = target_fps
        self.frame_interval = 1.0 / target_fps
        self.last_frame_time = 0
        self.frame_count = 0
    
    def wait_for_next_frame(self):
        """ë‹¤ìŒ í”„ë ˆì„ê¹Œì§€ ëŒ€ê¸°"""
        current_time = time.time()
        
        if self.last_frame_time == 0:
            self.last_frame_time = current_time
            return True
        
        elapsed = current_time - self.last_frame_time
        if elapsed >= self.frame_interval:
            self.last_frame_time = current_time
            self.frame_count += 1
            return True
        
        # ì •í™•í•œ íƒ€ì´ë°ì„ ìœ„í•´ ì§§ê²Œ ëŒ€ê¸°
        time.sleep(max(0, self.frame_interval - elapsed - 0.001))
        return False
    
    def get_stats(self):
        """í˜„ì¬ í†µê³„ ë°˜í™˜"""
        if self.frame_count > 0:
            current_time = time.time()
            elapsed = current_time - self.last_frame_time + (self.frame_count * self.frame_interval)
            actual_fps = self.frame_count / elapsed
            return {
                'frame_count': self.frame_count,
                'elapsed_time': elapsed,
                'actual_fps': actual_fps,
                'target_fps': self.target_fps
            }
        return None

def create_video_writer(filename, fps, width=None, height=None):
    """ì•ˆì •ì ì¸ VideoWriter ìƒì„± - ë™ì  í•´ìƒë„ ì§€ì›"""
    # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¹´ë©”ë¼ í•´ìƒë„ ì‚¬ìš©
    if width is None or height is None:
        width, height = camera_width, camera_height
    
    print(f"ğŸ¬ VideoWriter ìƒì„± ì¤‘... ({width}x{height}, {fps:.1f} FPS)")
    
    # ì½”ë± ìš°ì„ ìˆœìœ„: H264 > XVID > MJPG
    codecs = [
        ('H264', '.mp4'),
        ('XVID', '.avi'),
        ('MJPG', '.avi')
    ]
    
    for codec, ext in codecs:
        try:
            fourcc = cv2.VideoWriter_fourcc(*codec)
            video_path = filename.replace('.mp4', ext).replace('.avi', ext)
            out = cv2.VideoWriter(video_path, fourcc, fps, (width, height))
            
            if out.isOpened():
                print(f"âœ… {codec} ì½”ë±ìœ¼ë¡œ VideoWriter ìƒì„± ì„±ê³µ")
                return out, video_path
            else:
                out.release()
        except Exception as e:
            print(f"âš ï¸ {codec} ì½”ë± ì‹¤íŒ¨: {e}")
            continue
    
    # ëª¨ë“  ì½”ë±ì´ ì‹¤íŒ¨í•œ ê²½ìš°
    print("âŒ ëª¨ë“  ì½”ë± ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œë„")
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    video_path = filename.replace('.mp4', '.avi')
    return cv2.VideoWriter(video_path, fourcc, fps, (width, height)), video_path

def record_action(action_name, sample_idx):
    """íŠ¹ì • ì•¡ì…˜ì„ ë…¹í™”í•˜ê³  ì˜ìƒ ì €ì¥"""
    print(f"\nğŸ¬ {action_name.upper()} ì•¡ì…˜ ë…¹í™” ì‹œì‘ - ìƒ˜í”Œ {sample_idx+1}/{num_samples}")
    
    frames = []
    frame_timestamps = []  # í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
    
    # í”„ë ˆì„ë ˆì´íŠ¸ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”
    fps_controller = FrameRateController(actual_fps)
    
    # 3ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ - ë ‰ ì—†ëŠ” ë°©ì‹
    print("ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘...")
    countdown_start = time.time()
    
    for i in range(3, 0, -1):
        # ë¶€ë“œëŸ¬ìš´ ì¹´ìš´íŠ¸ë‹¤ìš´ì„ ìœ„í•´ 0.1ì´ˆì”© ì²´í¬
        target_time = countdown_start + (3 - i)
        
        while time.time() < target_time:
            ret, img = cap.read()
            if ret:
                img = cv2.flip(img, 1)
                cv2.putText(img, f'Get ready for {action_name.upper()}: {i}', 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 3)
                cv2.putText(img, 'Recording will start soon...', 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.imshow('Recording', img)
            
            # ì§§ì€ ëŒ€ê¸°ë¡œ ë¶€ë“œëŸ¬ìš´ ì—…ë°ì´íŠ¸
            if cv2.waitKey(50) & 0xFF == ord('q'):
                return False
            
            time.sleep(0.05)  # 50ms ëŒ€ê¸°ë¡œ ë¶€ë“œëŸ¬ìš´ ì¹´ìš´íŠ¸ë‹¤ìš´
    
    # ë…¹í™” ì‹œì‘ - ê°œì„ ëœ í”„ë ˆì„ë ˆì´íŠ¸ ì œì–´
    start_time = time.time()
    
    while time.time() - start_time < secs_for_action:
        # í”„ë ˆì„ë ˆì´íŠ¸ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ ì •í™•í•œ íƒ€ì´ë° ì œì–´
        if fps_controller.wait_for_next_frame():
            ret, img = cap.read()
            if not ret:
                continue
            
            img = cv2.flip(img, 1)
            original_img = img.copy()
            
            # í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
            frame_timestamps.append(time.time() - start_time)
            
            # ë…¹í™” ì •ë³´ í‘œì‹œ
            elapsed = time.time() - start_time
            remaining = secs_for_action - elapsed
            
            # FPS ì»¨íŠ¸ë¡¤ëŸ¬ í†µê³„ ê°€ì ¸ì˜¤ê¸°
            stats = fps_controller.get_stats()
            current_fps = stats['actual_fps'] if stats else 0
            
            cv2.putText(img, f'Recording {action_name.upper()}: {elapsed:.1f}s / {secs_for_action}s', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, f'Remaining: {remaining:.1f}s', 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(img, f'Sample: {sample_idx+1}/{num_samples}', 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
            cv2.putText(img, f'Target FPS: {actual_fps:.1f}', 
                       (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(img, f'Actual FPS: {current_fps:.1f}', 
                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(img, f'Frames: {len(frames)}', 
                       (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # í”„ë ˆì„ ì €ì¥
            frames.append(original_img)
            
            cv2.imshow('Recording', img)
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # ì˜ìƒ ì €ì¥ - ê°œì„ ëœ VideoWriter ì‚¬ìš©
    if len(frames) > 0:
        video_filename = f'video_{action_name}_{created_time}_{sample_idx:03d}.mp4'
        video_path = os.path.join(dataset_dir, action_name, video_filename)
        
        # ê°œì„ ëœ VideoWriter ìƒì„±
        out, final_video_path = create_video_writer(video_path, actual_fps)
        
        # í”„ë ˆì„ ì €ì¥
        for frame in frames:
            out.write(frame)
        
        out.release()
        
        # ìµœì¢… í†µê³„ ê³„ì‚°
        stats = fps_controller.get_stats()
        expected_frames = int(secs_for_action * actual_fps)
        
        print(f"âœ… ì˜ìƒ ì €ì¥: {os.path.basename(final_video_path)}")
        print(f"   - ì €ì¥ëœ í”„ë ˆì„: {len(frames)}")
        print(f"   - ì˜ˆìƒ í”„ë ˆì„: {expected_frames}")
        print(f"   - ëª©í‘œ FPS: {actual_fps:.1f}")
        
        if stats:
            print(f"   - ì‹¤ì œ FPS: {stats['actual_fps']:.1f}")
            print(f"   - ë…¹í™” ì‹œê°„: {stats['elapsed_time']:.2f}ì´ˆ")
            print(f"   - í”„ë ˆì„ ì •í™•ë„: {(len(frames) / expected_frames * 100):.1f}%")
        
        # í”„ë ˆì„ ê°„ê²© ë¶„ì„
        if len(frame_timestamps) > 1:
            intervals = [frame_timestamps[i] - frame_timestamps[i-1] for i in range(1, len(frame_timestamps))]
            avg_interval = sum(intervals) / len(intervals)
            target_interval = 1.0 / actual_fps
            print(f"   - í‰ê·  í”„ë ˆì„ ê°„ê²©: {avg_interval:.3f}ì´ˆ (ëª©í‘œ: {target_interval:.3f}ì´ˆ)")
            print(f"   - ê°„ê²© ì •í™•ë„: {(target_interval / avg_interval * 100):.1f}%")
        
        return True
    else:
        print(f"âŒ {action_name} ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return False

def record_action_alternative(action_name, sample_idx):
    """ëŒ€ì•ˆì ì¸ ë…¹í™” ë°©ë²• - ë” ì •í™•í•œ í”„ë ˆì„ë ˆì´íŠ¸ ì œì–´"""
    print(f"\nğŸ¬ {action_name.upper()} ì•¡ì…˜ ë…¹í™” ì‹œì‘ (ëŒ€ì•ˆ ë°©ë²•) - ìƒ˜í”Œ {sample_idx+1}/{num_samples}")
    
    frames = []
    frame_timestamps = []
    
    # 3ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ - ë ‰ ì—†ëŠ” ë°©ì‹
    print("ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘ (ëŒ€ì•ˆ ë°©ë²•)...")
    countdown_start = time.time()
    
    for i in range(3, 0, -1):
        # ë¶€ë“œëŸ¬ìš´ ì¹´ìš´íŠ¸ë‹¤ìš´ì„ ìœ„í•´ 0.1ì´ˆì”© ì²´í¬
        target_time = countdown_start + (3 - i)
        
        while time.time() < target_time:
            ret, img = cap.read()
            if ret:
                img = cv2.flip(img, 1)
                cv2.putText(img, f'Get ready for {action_name.upper()}: {i}', 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 3)
                cv2.putText(img, 'Alternative method - Recording will start soon...', 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                cv2.imshow('Recording', img)
            
            # ì§§ì€ ëŒ€ê¸°ë¡œ ë¶€ë“œëŸ¬ìš´ ì—…ë°ì´íŠ¸
            if cv2.waitKey(50) & 0xFF == ord('q'):
                return False
            
            time.sleep(0.05)  # 50ms ëŒ€ê¸°ë¡œ ë¶€ë“œëŸ¬ìš´ ì¹´ìš´íŠ¸ë‹¤ìš´
    
    # ë…¹í™” ì‹œì‘ - ëŒ€ì•ˆì  ë°©ë²•
    start_time = time.time()
    frame_interval = 1.0 / actual_fps
    next_frame_time = start_time
    
    while time.time() - start_time < secs_for_action:
        current_time = time.time()
        
        # ì •í™•í•œ íƒ€ì´ë° ì œì–´
        if current_time >= next_frame_time:
            ret, img = cap.read()
            if not ret:
                continue
            
            img = cv2.flip(img, 1)
            original_img = img.copy()
            
            # í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
            frame_timestamps.append(current_time - start_time)
            
            # ë…¹í™” ì •ë³´ í‘œì‹œ
            elapsed = current_time - start_time
            remaining = secs_for_action - elapsed
            current_fps = len(frames) / elapsed if elapsed > 0 else 0
            
            cv2.putText(img, f'Recording {action_name.upper()}: {elapsed:.1f}s / {secs_for_action}s', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, f'Remaining: {remaining:.1f}s', 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(img, f'Sample: {sample_idx+1}/{num_samples}', 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
            cv2.putText(img, f'Target FPS: {actual_fps:.1f}', 
                       (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(img, f'Current FPS: {current_fps:.1f}', 
                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(img, f'Frames: {len(frames)}', 
                       (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(img, 'ALT METHOD', 
                       (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            # í”„ë ˆì„ ì €ì¥
            frames.append(original_img)
            
            cv2.imshow('Recording', img)
            
            # ë‹¤ìŒ í”„ë ˆì„ ì‹œê°„ ê³„ì‚° (ëˆ„ì  ì˜¤ì°¨ ë°©ì§€)
            next_frame_time = start_time + (len(frames) * frame_interval)
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # ì˜ìƒ ì €ì¥
    if len(frames) > 0:
        video_filename = f'video_{action_name}_{created_time}_{sample_idx:03d}_alt.mp4'
        video_path = os.path.join(dataset_dir, action_name, video_filename)
        
        # ê°œì„ ëœ VideoWriter ìƒì„±
        out, final_video_path = create_video_writer(video_path, actual_fps)
        
        # í”„ë ˆì„ ì €ì¥
        for frame in frames:
            out.write(frame)
        
        out.release()
        
        # í†µê³„ ê³„ì‚°
        expected_frames = int(secs_for_action * actual_fps)
        actual_fps_calculated = len(frames) / secs_for_action
        
        print(f"âœ… ì˜ìƒ ì €ì¥ (ëŒ€ì•ˆ ë°©ë²•): {os.path.basename(final_video_path)}")
        print(f"   - ì €ì¥ëœ í”„ë ˆì„: {len(frames)}")
        print(f"   - ì˜ˆìƒ í”„ë ˆì„: {expected_frames}")
        print(f"   - ëª©í‘œ FPS: {actual_fps:.1f}")
        print(f"   - ì‹¤ì œ FPS: {actual_fps_calculated:.1f}")
        print(f"   - í”„ë ˆì„ ì •í™•ë„: {(len(frames) / expected_frames * 100):.1f}%")
        
        # í”„ë ˆì„ ê°„ê²© ë¶„ì„
        if len(frame_timestamps) > 1:
            intervals = [frame_timestamps[i] - frame_timestamps[i-1] for i in range(1, len(frame_timestamps))]
            avg_interval = sum(intervals) / len(intervals)
            target_interval = 1.0 / actual_fps
            print(f"   - í‰ê·  í”„ë ˆì„ ê°„ê²©: {avg_interval:.3f}ì´ˆ (ëª©í‘œ: {target_interval:.3f}ì´ˆ)")
            print(f"   - ê°„ê²© ì •í™•ë„: {(target_interval / avg_interval * 100):.1f}%")
        
        return True
    else:
        print(f"âŒ {action_name} ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return False

def main():
    """ë©”ì¸ ë…¹í™” í”„ë¡œì„¸ìŠ¤"""
    print("ğŸ¬ YOLO Pose ê¸°ë°˜ ì œìŠ¤ì²˜ ë°ì´í„°ì…‹ ìƒì„±")
    print("=" * 50)
    print(f"ğŸ“¹ ì¹´ë©”ë¼ í•´ìƒë„: {camera_width}x{camera_height} ({RESOLUTION_MODE} ëª¨ë“œ)")
    print(f"ğŸ“¹ ì¹´ë©”ë¼ í”„ë ˆì„ë ˆì´íŠ¸: {actual_fps} FPS")
    print("COME: í•œ ì† ë“¤ê³  í”ë“¤ê¸° (í˜¸ì¶œ ì œìŠ¤ì²˜)")
    print("NORMAL: ì§€ë‚˜ê°€ê¸°, íŒ”ì§±ë¼ê¸°, ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê¸° ë“±")
    print(f"ğŸ“¹ ë…¹í™” ì‹œê°„: {secs_for_action}ì´ˆ")
    print(f"ğŸ“Š ê° ì•¡ì…˜ë‹¹: {num_samples}ê°œ ìƒ˜í”Œ")
    print(f"ğŸ¬ ì˜ˆìƒ í”„ë ˆì„ ìˆ˜: {int(secs_for_action * actual_fps)} í”„ë ˆì„/ì˜ìƒ")
    
    # í•´ìƒë„ë³„ ì˜ˆìƒ íŒŒì¼ í¬ê¸° ê³„ì‚°
    estimated_frame_size = camera_width * camera_height * 3  # RGB ê¸°ì¤€
    estimated_video_size_mb = (estimated_frame_size * int(secs_for_action * actual_fps)) / (1024 * 1024)
    total_videos = num_samples * len(actions)
    total_size_gb = (estimated_video_size_mb * total_videos) / 1024
    
    print(f"ğŸ’¾ ì˜ˆìƒ ì˜ìƒ í¬ê¸°: {estimated_video_size_mb:.1f}MB/ì˜ìƒ")
    print(f"ğŸ’¾ ì´ ì˜ˆìƒ ìš©ëŸ‰: {total_size_gb:.1f}GB ({total_videos}ê°œ ì˜ìƒ)")
    
    # í•´ìƒë„ ë³€ê²½ ê°€ì´ë“œ
    print("\nâš™ï¸ í•´ìƒë„ ë³€ê²½í•˜ë ¤ë©´:")
    print("   íŒŒì¼ ìƒë‹¨ì˜ RESOLUTION_MODE ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”")
    print("   - 'low': 640x480 (ë¹ ë¥¸ ì²˜ë¦¬)")
    print("   - 'medium': 1280x720 (HD)")
    print("   - 'high': 1920x1080 (Full HD)")
    print("   - 'full': ì¹´ë©”ë¼ ìµœëŒ€ í•´ìƒë„")
    
    # ì •í™•í•œ ì‹œê°„ ê³„ì‚°
    total_recording_time = num_samples * len(actions) * secs_for_action  # ë…¹í™” ì‹œê°„
    total_countdown_time = num_samples * len(actions) * 3  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œê°„
    total_wait_time = (num_samples - 1) * len(actions) * 1  # ë‹¤ìŒ ìƒ˜í”Œ ëŒ€ê¸° ì‹œê°„ (1ì´ˆë¡œ ë‹¨ì¶•)
    total_time = total_recording_time + total_countdown_time + total_wait_time
    
    print(f"â±ï¸ ì´ ì˜ˆìƒ ì‹œê°„: {total_time / 60:.1f}ë¶„")
    print(f"   - ë…¹í™”: {total_recording_time / 60:.1f}ë¶„")
    print(f"   - ëŒ€ê¸°: {(total_countdown_time + total_wait_time) / 60:.1f}ë¶„")
    print("=" * 50)
    
    print("\nğŸ¯ ë°ì´í„° ì¦ê°• ê°€ì´ë“œ:")
    print("COME ì œìŠ¤ì²˜ ë‹¤ì–‘ì„±:")
    print("  - ì™¼ì†/ì˜¤ë¥¸ì†/ì–‘ì†ìœ¼ë¡œ í”ë“¤ê¸°")
    print("  - ë†’ì´: ì–´ê¹¨/ë¨¸ë¦¬/ê°€ìŠ´ ë†’ì´")
    print("  - ì†ë„: ì²œì²œíˆ/ë³´í†µ/ë¹ ë¥´ê²Œ")
    print("  - ë°©í–¥: ì¢Œìš°/ìƒí•˜/ì›í˜•")
    print("  - ê±°ë¦¬: ê°€ê¹Œì´/ë©€ë¦¬")
    print("  - ê°ë„: 45ë„/90ë„/180ë„")
    print("\nNORMAL í–‰ë™ ë‹¤ì–‘ì„±:")
    print("  - ê±·ê¸°: ì•/ë’¤/ì˜†ìœ¼ë¡œ")
    print("  - ì„œìˆê¸°: íŒ”ì§±/ì†ì£¼ë¨¸ë‹ˆ/íŒ”ë²Œë¦¬ê¸°")
    print("  - ì•‰ê¸°: ì˜ì/ë°”ë‹¥")
    print("  - ê¸°íƒ€: ì „í™”/ì±…ë³´ê¸°/ìŒë£Œë§ˆì‹œê¸°")
    print("=" * 50)
    
    for action in actions:
        print(f"\nğŸ“¹ {action.upper()} ì•¡ì…˜ ë…¹í™” ì‹œì‘")
        print(f"ê° ì•¡ì…˜ë‹¹ {num_samples}ê°œ ìƒ˜í”Œì„ {secs_for_action}ì´ˆì”© ë…¹í™”í•©ë‹ˆë‹¤.")
        
        successful_samples = 0
        
        for sample_idx in range(num_samples):
            print(f"\n--- {action.upper()} ìƒ˜í”Œ {sample_idx+1}/{num_samples} ---")
            
            # ì•ˆë‚´ ë©”ì‹œì§€
            if action == 'come':
                print("ğŸ’¡ í•œ ì†ì„ ë“¤ê³  í”ë“¤ì–´ì£¼ì„¸ìš” (í˜¸ì¶œ ì œìŠ¤ì²˜)")
            else:
                print("ğŸ’¡ í‰ìƒì‹œ í–‰ë™ì„ í•´ì£¼ì„¸ìš” (ì§€ë‚˜ê°€ê¸°, íŒ”ì§±ë¼ê¸°, ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê¸° ë“±)")
            
            # ë…¹í™” ì‹œì‘
            if record_action(action, sample_idx):
                successful_samples += 1
            
            # ë‹¤ìŒ ìƒ˜í”Œ ì¤€ë¹„ (1ì´ˆë§Œ ëŒ€ê¸°) - ë ‰ ì—†ëŠ” ë°©ì‹
            if sample_idx < num_samples - 1:
                print("â³ ë‹¤ìŒ ìƒ˜í”Œ ì¤€ë¹„ ì¤‘... (1ì´ˆ)")
                wait_start = time.time()
                
                while time.time() - wait_start < 1.0:
                    ret, img = cap.read()
                    if ret:
                        img = cv2.flip(img, 1)
                        remaining = 1.0 - (time.time() - wait_start)
                        cv2.putText(img, f'Next sample in: {remaining:.1f}s', 
                                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                        cv2.putText(img, f'Sample {sample_idx+2}/{num_samples} coming up...', 
                                   (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        cv2.imshow('Recording', img)
                    
                    # ì§§ì€ ëŒ€ê¸°ë¡œ ë¶€ë“œëŸ¬ìš´ ì—…ë°ì´íŠ¸
                    if cv2.waitKey(50) & 0xFF == ord('q'):
                        cap.release()
                        cv2.destroyAllWindows()
                        return
                    
                    time.sleep(0.05)  # 50ms ëŒ€ê¸°
        
        print(f"\nâœ… {action.upper()} ì™„ë£Œ: {successful_samples}/{num_samples} ì„±ê³µ")
    
    cap.release()
    cv2.destroyAllWindows()
    
    print(f"\nğŸ‰ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {dataset_dir}/")
    print(f"ğŸ“‚ COME ì˜ìƒ: {dataset_dir}/come/")
    print(f"ğŸ“‚ NORMAL ì˜ìƒ: {dataset_dir}/normal/")
    print(f"ğŸ“Š ì´ ìƒ˜í”Œ: {num_samples * len(actions)}ê°œ")
    print(f"ğŸ¬ ë‹¤ìŒ ë‹¨ê³„: ì˜ìƒ í¸ì§‘ í›„ ê´€ì ˆì  ì¶”ì¶œ")

if __name__ == "__main__":
    main() 