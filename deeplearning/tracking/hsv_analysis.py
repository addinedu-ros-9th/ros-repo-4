import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
import os
from datetime import datetime

# Qt í”Œë«í¼ í”ŒëŸ¬ê·¸ì¸ ì˜¤ë¥˜ ë°©ì§€
os.environ['QT_QPA_PLATFORM'] = 'xcb'
os.environ['QT_DEBUG_PLUGINS'] = '0'
os.environ['QT_AUTO_SCREEN_SCALE_FACTOR'] = '0'
os.environ['QT_SCALE_FACTOR'] = '1'

# matplotlib ë°±ì—”ë“œë¥¼ Aggë¡œ ì„¤ì •
plt.switch_backend('Agg')

def estimate_distance(bbox_height, ref_height=300, ref_distance=1.0):
    distance = ref_height / (bbox_height + 1e-6) * ref_distance
    return round(distance, 2)

def estimate_distance_from_mask(mask, ref_height=300, ref_distance=1.0):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•œ ë” ì •í™•í•œ ê±°ë¦¬ ê³„ì‚°"""
    # ë§ˆìŠ¤í¬ì—ì„œ ì‹¤ì œ ì‚¬ëŒ ì˜ì—­ì˜ ë†’ì´ ê³„ì‚°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # ê°€ì¥ í° ì»¨íˆ¬ì–´ (ì‚¬ëŒ) ì„ íƒ
        cnt = max(contours, key=cv2.contourArea)
        
        # ì»¨íˆ¬ì–´ì˜ ë°”ìš´ë”© ë°•ìŠ¤
        x, y, w, h = cv2.boundingRect(cnt)
        
        # ì‹¤ì œ ì‚¬ëŒ ë†’ì´ (í”½ì…€ ë‹¨ìœ„)
        person_height = h
        
        # ê±°ë¦¬ ê³„ì‚° (ì—­ë¹„ë¡€ ê´€ê³„)
        distance = ref_height / (person_height + 1e-6) * ref_distance
        return round(distance, 2)
    
    # ì»¨íˆ¬ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
    return 2.0

def estimate_distance_advanced(mask, ref_height=300, ref_distance=1.0):
    """ê³ ê¸‰ ê±°ë¦¬ ê³„ì‚° - ë§ˆìŠ¤í¬ì˜ ì‹¤ì œ í”½ì…€ ìˆ˜ì™€ í˜•íƒœ ê³ ë ¤"""
    # ë§ˆìŠ¤í¬ì—ì„œ ì‹¤ì œ ì‚¬ëŒ ì˜ì—­ ë¶„ì„
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        cnt = max(contours, key=cv2.contourArea)
        
        # ì»¨íˆ¬ì–´ì˜ ë°”ìš´ë”© ë°•ìŠ¤
        x, y, w, h = cv2.boundingRect(cnt)
        
        # ì‹¤ì œ ì‚¬ëŒ ì˜ì—­ì˜ í”½ì…€ ìˆ˜
        person_pixels = cv2.contourArea(cnt)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­
        bbox_area = w * h
        
        # ì‚¬ëŒì´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì–¼ë§ˆë‚˜ ì±„ìš°ëŠ”ì§€ (ë°€ë„)
        density = person_pixels / (bbox_area + 1e-6)
        
        # ë°€ë„ë¥¼ ê³ ë ¤í•œ ì¡°ì •ëœ ë†’ì´
        adjusted_height = h * density
        
        # ê±°ë¦¬ ê³„ì‚°
        distance = ref_height / (adjusted_height + 1e-6) * ref_distance
        
        return round(distance, 2), {
            'person_height': h,
            'person_pixels': person_pixels,
            'bbox_area': bbox_area,
            'density': density,
            'adjusted_height': adjusted_height
        }
    
    return 2.0, {}

class HSVAnalyzer:
    def __init__(self):
        self.model = YOLO('yolov8s-seg.pt')
        self.people_data = {}  # ID: {histograms: [], timestamps: [], images: []}
        self.next_id = 0
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.process_every_n_frames = 3  # 3í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ì„±ëŠ¥ í–¥ìƒ)
        self.frame_skip_counter = 0
        
        # ë§¤ì¹­ ê´€ë ¨ ì„¤ì •
        self.match_threshold = 0.35  # ë§¤ì¹­ ì„ê³„ê°’
        self.reentry_threshold = 0.30  # ì¬ì§„ì… ì„ê³„ê°’
        self.min_detection_confidence = 0.6  # ìµœì†Œ ê°ì§€ ì‹ ë¢°ë„
        self.min_person_area = 5000  # ìµœì†Œ ì‚¬ëŒ ì˜ì—­
        self.max_frames_without_seen = 300  # 10ì´ˆ í›„ì—ë„ ê¸°ì–µ
        
        # íˆìŠ¤í† ê·¸ë¨ ê¸°ì–µ ì„¤ì •
        self.max_histograms_per_person = 10  # ì‚¬ëŒë‹¹ ìµœëŒ€ íˆìŠ¤í† ê·¸ë¨ ì €ì¥ ìˆ˜
        self.histogram_memory_duration = 30  # 30ì´ˆê°„ íˆìŠ¤í† ê·¸ë¨ ê¸°ì–µ
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        self.analysis_dir = "./hsv_analysis"
        if not os.path.exists(self.analysis_dir):
            os.makedirs(self.analysis_dir)
            print(f"ğŸ“ ë¶„ì„ ë””ë ‰í† ë¦¬ ìƒì„±: {self.analysis_dir}")
    
    def extract_histogram(self, img, mask, bins=16):
        """HSVì˜ ëª¨ë“  ì±„ë„(H, S, V)ì„ ê³ ë ¤í•œ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ"""
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # ê° ì±„ë„ë³„ íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
        h_hist = cv2.calcHist([hsv], [0], mask, [bins], [0, 180])
        s_hist = cv2.calcHist([hsv], [1], mask, [bins], [0, 256])
        v_hist = cv2.calcHist([hsv], [2], mask, [bins], [0, 256])
        
        # ì •ê·œí™”
        h_hist = cv2.normalize(h_hist, h_hist).flatten()
        s_hist = cv2.normalize(s_hist, s_hist).flatten()
        v_hist = cv2.normalize(v_hist, v_hist).flatten()
        
        # ëª¨ë“  ì±„ë„ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ê²°í•©
        combined_hist = np.concatenate([h_hist, s_hist, v_hist])
        
        return combined_hist, h_hist, s_hist, v_hist
    
    def calculate_similarity_metrics(self, hist1, hist2):
        """ë‹¤ì–‘í•œ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        # Bhattacharyya ê±°ë¦¬
        bhatt_dist = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_BHATTACHARYYA)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        dot_product = np.dot(hist1, hist2)
        norm1 = np.linalg.norm(hist1)
        norm2 = np.linalg.norm(hist2)
        cosine_sim = dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0.0
        
        # ìƒê´€ê³„ìˆ˜
        corr = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CORREL)
        
        # Chi-Square ê±°ë¦¬
        chi_square = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CHISQR)
        
        # Intersection
        intersection = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_INTERSECT)
        
        return {
            'bhattacharyya': bhatt_dist,
            'cosine_similarity': cosine_sim,
            'correlation': corr,
            'chi_square': chi_square,
            'intersection': intersection
        }
    
    def find_best_match(self, current_hist, current_bbox, used_ids):
        """ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ëŒ ì°¾ê¸° (ê°œì„ ëœ ë²„ì „)"""
        best_match_id = None
        best_score = 0.0
        best_metrics = {}
        
        x1, y1, x2, y2 = current_bbox
        current_area = (x2 - x1) * (y2 - y1)
        current_center = ((x1 + x2) // 2, (y1 + y2) // 2)
        
        # í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ ëª¨ë“  ì‚¬ëŒê³¼ ë¹„êµ
        for pid, pdata in self.people_data.items():
            # ì´ë¯¸ ì‚¬ìš©ëœ IDëŠ” ì œì™¸
            if pid in used_ids:
                continue
                
            if len(pdata['histograms']) == 0:
                continue
            
            # ëª¨ë“  íˆìŠ¤í† ê·¸ë¨ê³¼ ë¹„êµ (ìµœê·¼ 10ê°œ)
            hist_scores = []
            for i, stored_hist in enumerate(pdata['histograms'][-self.max_histograms_per_person:]):
                metrics = self.calculate_similarity_metrics(current_hist, stored_hist)
                hist_score = max(1.0 - metrics['bhattacharyya'], metrics['cosine_similarity'])
                hist_scores.append(hist_score)
            
            # ìµœê³  íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜ ì‚¬ìš©
            best_hist_score = max(hist_scores) if hist_scores else 0.0
            
            # ê³µê°„ì  ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ ëŒ€í­ ê°ì†Œ: 30% â†’ 10%)
            latest_bbox = pdata['bboxes'][-1]
            stored_area = (latest_bbox[2] - latest_bbox[0]) * (latest_bbox[3] - latest_bbox[1])
            stored_center = ((latest_bbox[0] + latest_bbox[2]) // 2, (latest_bbox[1] + latest_bbox[3]) // 2)
            
            # ì¤‘ì‹¬ì  ê±°ë¦¬ ê³„ì‚°
            center_distance = np.sqrt((current_center[0] - stored_center[0])**2 + 
                                     (current_center[1] - stored_center[1])**2)
            max_distance = np.sqrt(640**2 + 480**2)
            spatial_score = 1.0 - (center_distance / max_distance)
            
            # ì¢…í•© ì ìˆ˜ (íˆìŠ¤í† ê·¸ë¨ 90%, ê³µê°„ì  ìœ„ì¹˜ 10%) - ìœ„ì¹˜ ê°€ì¤‘ì¹˜ ëŒ€í­ ê°ì†Œ
            total_score = 0.9 * best_hist_score + 0.1 * spatial_score
            
            # ë” ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ë§¤ì¹­ ì„ íƒ
            if total_score > best_score:
                best_score = total_score
                best_match_id = pid
                best_metrics = {
                    'hist_score': best_hist_score,
                    'spatial_score': spatial_score,
                    'hist_scores': hist_scores
                }
        
        return best_match_id, best_score, best_metrics
    
    def visualize_histogram_comparison(self, hist1, hist2, person_id1, person_id2, frame_count, save_path):
        """íˆìŠ¤í† ê·¸ë¨ ë¹„êµ ì‹œê°í™”"""
        bins = 16
        h_hist1 = hist1[:bins]
        s_hist1 = hist1[bins:2*bins]
        v_hist1 = hist1[2*bins:]
        h_hist2 = hist2[:bins]
        s_hist2 = hist2[bins:2*bins]
        v_hist2 = hist2[2*bins:]
        
        # ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = self.calculate_similarity_metrics(hist1, hist2)
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle(f'HSV Histogram Comparison: {person_id1} vs {person_id2} (Frame {frame_count})', fontsize=16)
        
        # H ì±„ë„ ë¹„êµ
        axes[0, 0].bar(np.arange(bins) - 0.2, h_hist1, 0.4, label=person_id1, alpha=0.7, color='blue')
        axes[0, 0].bar(np.arange(bins) + 0.2, h_hist2, 0.4, label=person_id2, alpha=0.7, color='red')
        axes[0, 0].set_title('Hue Channel')
        axes[0, 0].set_xlabel('Hue Bins')
        axes[0, 0].set_ylabel('Normalized Frequency')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # S ì±„ë„ ë¹„êµ
        axes[0, 1].bar(np.arange(bins) - 0.2, s_hist1, 0.4, label=person_id1, alpha=0.7, color='blue')
        axes[0, 1].bar(np.arange(bins) + 0.2, s_hist2, 0.4, label=person_id2, alpha=0.7, color='red')
        axes[0, 1].set_title('Saturation Channel')
        axes[0, 1].set_xlabel('Saturation Bins')
        axes[0, 1].set_ylabel('Normalized Frequency')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # V ì±„ë„ ë¹„êµ
        axes[0, 2].bar(np.arange(bins) - 0.2, v_hist1, 0.4, label=person_id1, alpha=0.7, color='blue')
        axes[0, 2].bar(np.arange(bins) + 0.2, v_hist2, 0.4, label=person_id2, alpha=0.7, color='red')
        axes[0, 2].set_title('Value Channel')
        axes[0, 2].set_xlabel('Value Bins')
        axes[0, 2].set_ylabel('Normalized Frequency')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # ì°¨ì´ ë¶„ì„
        axes[1, 0].bar(np.arange(bins), np.abs(h_hist1 - h_hist2), color='orange', alpha=0.7)
        axes[1, 0].set_title(f'Hue Difference (Sum: {np.sum(np.abs(h_hist1 - h_hist2)):.4f})')
        axes[1, 0].set_xlabel('Hue Bins')
        axes[1, 0].set_ylabel('Absolute Difference')
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].bar(np.arange(bins), np.abs(s_hist1 - s_hist2), color='orange', alpha=0.7)
        axes[1, 1].set_title(f'Saturation Difference (Sum: {np.sum(np.abs(s_hist1 - s_hist2)):.4f})')
        axes[1, 1].set_xlabel('Saturation Bins')
        axes[1, 1].set_ylabel('Absolute Difference')
        axes[1, 1].grid(True, alpha=0.3)
        
        axes[1, 2].bar(np.arange(bins), np.abs(v_hist1 - v_hist2), color='orange', alpha=0.7)
        axes[1, 2].set_title(f'Value Difference (Sum: {np.sum(np.abs(v_hist1 - v_hist2)):.4f})')
        axes[1, 2].set_xlabel('Value Bins')
        axes[1, 2].set_ylabel('Absolute Difference')
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return metrics
    
    def create_similarity_matrix(self, save_path):
        """ëª¨ë“  ì‚¬ëŒ ê°„ì˜ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
        if len(self.people_data) < 2:
            print("âš ï¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ ìµœì†Œ 2ëª…ì˜ ì‚¬ëŒì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        people_ids = list(self.people_data.keys())
        n_people = len(people_ids)
        
        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”
        similarity_matrix = np.zeros((n_people, n_people))
        bhatt_matrix = np.zeros((n_people, n_people))
        cosine_matrix = np.zeros((n_people, n_people))
        
        print(f"\nğŸ“Š {n_people}ëª…ì˜ ì‚¬ëŒ ê°„ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì¤‘...")
        
        for i, pid1 in enumerate(people_ids):
            for j, pid2 in enumerate(people_ids):
                if i == j:
                    similarity_matrix[i, j] = 1.0
                    bhatt_matrix[i, j] = 0.0
                    cosine_matrix[i, j] = 1.0
                else:
                    # ê° ì‚¬ëŒì˜ ìµœì‹  íˆìŠ¤í† ê·¸ë¨ ì‚¬ìš©
                    hist1 = self.people_data[pid1]['histograms'][-1]
                    hist2 = self.people_data[pid2]['histograms'][-1]
                    
                    metrics = self.calculate_similarity_metrics(hist1, hist2)
                    
                    # ì¢…í•© ìœ ì‚¬ë„ ì ìˆ˜
                    hist_score = max(1.0 - metrics['bhattacharyya'], metrics['cosine_similarity'])
                    similarity_matrix[i, j] = hist_score
                    bhatt_matrix[i, j] = metrics['bhattacharyya']
                    cosine_matrix[i, j] = metrics['cosine_similarity']
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(1, 3, figsize=(20, 6))
        
        # ì¢…í•© ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        im1 = axes[0].imshow(similarity_matrix, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[0].set_title('Overall Similarity Matrix')
        axes[0].set_xticks(range(n_people))
        axes[0].set_yticks(range(n_people))
        axes[0].set_xticklabels(people_ids, rotation=45)
        axes[0].set_yticklabels(people_ids)
        plt.colorbar(im1, ax=axes[0])
        
        # ê°’ í‘œì‹œ
        for i in range(n_people):
            for j in range(n_people):
                axes[0].text(j, i, f'{similarity_matrix[i, j]:.3f}', 
                           ha='center', va='center', fontsize=8)
        
        # Bhattacharyya ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤
        im2 = axes[1].imshow(bhatt_matrix, cmap='Reds', vmin=0, vmax=1)
        axes[1].set_title('Bhattacharyya Distance Matrix')
        axes[1].set_xticks(range(n_people))
        axes[1].set_yticks(range(n_people))
        axes[1].set_xticklabels(people_ids, rotation=45)
        axes[1].set_yticklabels(people_ids)
        plt.colorbar(im2, ax=axes[1])
        
        # ê°’ í‘œì‹œ
        for i in range(n_people):
            for j in range(n_people):
                axes[1].text(j, i, f'{bhatt_matrix[i, j]:.3f}', 
                           ha='center', va='center', fontsize=8)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        im3 = axes[2].imshow(cosine_matrix, cmap='Blues', vmin=0, vmax=1)
        axes[2].set_title('Cosine Similarity Matrix')
        axes[2].set_xticks(range(n_people))
        axes[2].set_yticks(range(n_people))
        axes[2].set_xticklabels(people_ids, rotation=45)
        axes[2].set_yticklabels(people_ids)
        plt.colorbar(im3, ax=axes[2])
        
        # ê°’ í‘œì‹œ
        for i in range(n_people):
            for j in range(n_people):
                axes[2].text(j, i, f'{cosine_matrix[i, j]:.3f}', 
                           ha='center', va='center', fontsize=8)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì €ì¥: {save_path}")
        
        # ìˆ˜ì¹˜ì  ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“ˆ ìˆ˜ì¹˜ì  ë¶„ì„ ê²°ê³¼:")
        print(f"   - í‰ê·  ìœ ì‚¬ë„: {np.mean(similarity_matrix):.3f}")
        print(f"   - ìµœëŒ€ ìœ ì‚¬ë„: {np.max(similarity_matrix):.3f}")
        print(f"   - ìµœì†Œ ìœ ì‚¬ë„: {np.min(similarity_matrix):.3f}")
        print(f"   - í‘œì¤€í¸ì°¨: {np.std(similarity_matrix):.3f}")
        
        # ê°€ì¥ ìœ ì‚¬í•œ ìŒê³¼ ê°€ì¥ ë‹¤ë¥¸ ìŒ ì°¾ê¸°
        max_sim_idx = np.unravel_index(np.argmax(similarity_matrix), similarity_matrix.shape)
        min_sim_idx = np.unravel_index(np.argmin(similarity_matrix), similarity_matrix.shape)
        
        if max_sim_idx[0] != max_sim_idx[1]:
            print(f"   - ê°€ì¥ ìœ ì‚¬í•œ ìŒ: {people_ids[max_sim_idx[0]]} vs {people_ids[max_sim_idx[1]]} (ìœ ì‚¬ë„: {similarity_matrix[max_sim_idx]:.3f})")
        if min_sim_idx[0] != min_sim_idx[1]:
            print(f"   - ê°€ì¥ ë‹¤ë¥¸ ìŒ: {people_ids[min_sim_idx[0]]} vs {people_ids[min_sim_idx[1]]} (ìœ ì‚¬ë„: {similarity_matrix[min_sim_idx]:.3f})")
    
    def run_analysis(self, duration_seconds=30):
        """HSV íˆìŠ¤í† ê·¸ë¨ ë¶„ì„ ì‹¤í–‰"""
        cap = cv2.VideoCapture(0)  # 2ì—ì„œ 0ìœ¼ë¡œ ë³€ê²½
        
        if not cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ì—°ê²° ì‹¤íŒ¨")
            return
        
       
        frame_count = 0
        start_time = datetime.now()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            elapsed_time = (datetime.now() - start_time).total_seconds()
            
            if elapsed_time > duration_seconds:
                break
            
            # í”„ë ˆì„ ì²˜ë¦¬ ê°„ê²© ì¡°ì ˆ
            if self.frame_skip_counter < self.process_every_n_frames - 1:
                self.frame_skip_counter += 1
                continue
            
            self.frame_skip_counter = 0 # ì¹´ìš´í„° ì´ˆê¸°í™”
            
            # ì‚¬ëŒ ê°ì§€
            results = self.model(frame, classes=[0])  # class 0 = person
            annotated = frame.copy()
            
            # í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ ëª¨ë“  ì‚¬ëŒì˜ ì •ë³´ë¥¼ ë¨¼ì € ìˆ˜ì§‘
            current_detections = []
            
            for result in results:
                for i in range(len(result.boxes)):
                    seg = result.masks.data[i]
                    box = result.boxes[i]
                    confidence = box.conf[0].item()
                    
                    if confidence < self.min_detection_confidence:
                        continue
                    
                    mask = seg.cpu().numpy().astype(np.uint8) * 255
                    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)
                    
                    # ë…¸ì´ì¦ˆ ì œê±°
                    kernel = np.ones((5,5), np.uint8)
                    mask_cleaned = cv2.morphologyEx(mask_resized, cv2.MORPH_CLOSE, kernel)
                    mask_cleaned = cv2.morphologyEx(mask_cleaned, cv2.MORPH_OPEN, kernel)
                    
                    # HSV íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
                    combined_hist, h_hist, s_hist, v_hist = self.extract_histogram(frame, mask_cleaned)
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                    bbox = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = bbox
                    area = (x2 - x1) * (y2 - y1)
                    
                    if area < self.min_person_area:
                        continue
                    
                    # ê±°ë¦¬ ì¶”ì • (ì‚¬ìš©ìê°€ ì¶”ê°€í•œ í•¨ìˆ˜ ì‚¬ìš©)
                    person_height = y2 - y1
                    distance = estimate_distance(person_height, ref_height=300, ref_distance=1.0)  # m ë‹¨ìœ„
                    
                    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•œ ë” ì •í™•í•œ ê±°ë¦¬ ê³„ì‚°
                    est_dist, dist_info = estimate_distance_advanced(mask_cleaned, ref_height=300, ref_distance=1.0)
                    
                    current_detections.append({
                        'hist': combined_hist,
                        'bbox': bbox,
                        'mask': mask_cleaned,
                        'confidence': confidence,
                        'area': area,
                        'distance': est_dist,  # ë” ì •í™•í•œ ê±°ë¦¬ ì‚¬ìš©
                        'dist_info': dist_info  # ê±°ë¦¬ ê³„ì‚° ì •ë³´ë„ ì €ì¥
                    })
            
            # ê°ì§€ëœ ì‚¬ëŒë“¤ì„ ì˜ì—­ í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ (í° ì‚¬ëŒë¶€í„° ì²˜ë¦¬)
            current_detections.sort(key=lambda x: x['area'], reverse=True)
            
            # ì´ë¯¸ ë§¤ì¹­ëœ IDë“¤ì„ ì¶”ì 
            used_ids = set()
            
            # ê° ê°ì§€ëœ ì‚¬ëŒì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰
            for detection in current_detections:
                combined_hist = detection['hist']
                bbox = detection['bbox']
                
                # ë§¤ì¹­ ì‹œë„
                matched_id, match_score, metrics = self.find_best_match(combined_hist, bbox, used_ids)
                
                print(f"ğŸ¯ ë§¤ì¹­ ê²°ê³¼: {matched_id}, ì ìˆ˜: {match_score:.3f}, ê±°ë¦¬: {detection['distance']:.2f}m, ì„ê³„ê°’: {self.match_threshold:.3f}")
                
                # ê±°ë¦¬ ê³„ì‚° ìƒì„¸ ì •ë³´ ì¶œë ¥
                if detection['dist_info']:
                    print(f"   ğŸ“ ê±°ë¦¬ ê³„ì‚° ìƒì„¸: ë†’ì´={detection['dist_info']['person_height']}px, ë°€ë„={detection['dist_info']['density']:.3f}")
                
                # ë§¤ì¹­ ì„±ê³µ ì—¬ë¶€ì— ë”°ë¥¸ ì²˜ë¦¬
                if matched_id is not None and match_score > self.match_threshold:
                    # ê¸°ì¡´ ì‚¬ëŒ ì—…ë°ì´íŠ¸
                    self.people_data[matched_id]['histograms'].append(combined_hist)
                    self.people_data[matched_id]['bboxes'].append(bbox)
                    self.people_data[matched_id]['timestamps'].append(elapsed_time)
                    used_ids.add(matched_id)  # ID ì‚¬ìš©ë¨ í‘œì‹œ
                    
                    # íˆìŠ¤í† ê·¸ë¨ ë©”ëª¨ë¦¬ ê´€ë¦¬ (ìµœëŒ€ ê°œìˆ˜ ì œí•œ)
                    if len(self.people_data[matched_id]['histograms']) > self.max_histograms_per_person:
                        # ê°€ì¥ ì˜¤ë˜ëœ íˆìŠ¤í† ê·¸ë¨ ì œê±°
                        self.people_data[matched_id]['histograms'].pop(0)
                        self.people_data[matched_id]['bboxes'].pop(0)
                        self.people_data[matched_id]['timestamps'].pop(0)
                    
                    color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (ê¸°ì¡´ ì‚¬ëŒ)
                    print(f"ğŸ”„ ê¸°ì¡´ ì‚¬ëŒ ì¬ì‹ë³„: {matched_id} (ì ìˆ˜: {match_score:.3f})")
                    print(f"   - íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜: {metrics['hist_score']:.3f}")
                    print(f"   - ê³µê°„ì  ì ìˆ˜: {metrics['spatial_score']:.3f}")
                    print(f"   - ì €ì¥ëœ íˆìŠ¤í† ê·¸ë¨ ìˆ˜: {len(self.people_data[matched_id]['histograms'])}")
                    
                else:
                    # ìƒˆë¡œìš´ ì‚¬ëŒ (ë§¤ì¹­ ì‹¤íŒ¨ ë˜ëŠ” ì„ê³„ê°’ ë¯¸ë‹¬)
                    new_id = f"Person_{self.next_id}"
                    self.people_data[new_id] = {
                        'histograms': [combined_hist],
                        'bboxes': [bbox],
                        'timestamps': [elapsed_time],
                        'images': []
                    }
                    self.next_id += 1
                    used_ids.add(new_id)  # ID ì‚¬ìš©ë¨ í‘œì‹œ
                    
                    color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ìƒˆë¡œìš´ ì‚¬ëŒ)
                    print(f"ğŸ†• ìƒˆë¡œìš´ ì‚¬ëŒ ê°ì§€: {new_id} (ìµœê³  ì ìˆ˜: {match_score:.3f}, ì„ê³„ê°’ ë¯¸ë‹¬)")
                    print(f"   - ë§¤ì¹­ ì‹¤íŒ¨ë¡œ ì¸í•œ ìƒˆë¡œìš´ ì‚¬ëŒ ë“±ë¡")
                
                # ì‹œê°í™”
                x1, y1, x2, y2 = map(int, bbox)
                cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
                
                # ID í‘œì‹œ
                id_text = matched_id if matched_id else new_id
                cv2.putText(annotated, id_text, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                
                # Confidence í‘œì‹œ
                conf_text = f"Conf: {detection['confidence']:.2f}"
                cv2.putText(annotated, conf_text, (x1, y2+20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                
                # ê±°ë¦¬ í‘œì‹œ (m ë‹¨ìœ„) - ë” ì •í™•í•œ ê±°ë¦¬ ê³„ì‚° ì‚¬ìš©
                distance_text = f"Dist: {detection['distance']:.2f}m"
                cv2.putText(annotated, distance_text, (x1, y2+40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                
                # ë°€ë„ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
                if detection['dist_info']:
                    density_text = f"Density: {detection['dist_info']['density']:.2f}"
                    cv2.putText(annotated, density_text, (x1, y2+60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                
                # ìœ ì‚¬ë„ ì ìˆ˜ í‘œì‹œ
                score_text = f"{match_score:.3f}"
                cv2.putText(annotated, score_text, (x1, y2+80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            
            # ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ
            info_text = f"People: {len(self.people_data)} | Frame: {frame_count} | Time: {elapsed_time:.1f}s"
            cv2.putText(annotated, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # ì„±ëŠ¥ ìµœì í™”: 5í”„ë ˆì„ë§ˆë‹¤ë§Œ í™”ë©´ ì—…ë°ì´íŠ¸
            if frame_count % 5 == 0:
                cv2.imshow("HSV Histogram Analysis", annotated)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
        
        cap.release()
        cv2.destroyAllWindows()
        
        # ë¶„ì„ ê²°ê³¼ ìƒì„±
        print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ!")
        print(f"   - ì´ í”„ë ˆì„: {frame_count}")
        print(f"   - ê°ì§€ëœ ì‚¬ëŒ ìˆ˜: {len(self.people_data)}")
        
        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        if len(self.people_data) > 1:
            matrix_path = os.path.join(self.analysis_dir, "similarity_matrix.png")
            self.create_similarity_matrix(matrix_path)
        
        # ê° ì‚¬ëŒì˜ íˆìŠ¤í† ê·¸ë¨ ë³€í™” ë¶„ì„
        for pid, pdata in self.people_data.items():
            if len(pdata['histograms']) > 1:
                print(f"\nğŸ‘¤ {pid} HSV íˆìŠ¤í† ê·¸ë¨ ë³€í™” ë¶„ì„:")
                histograms = np.array(pdata['histograms'])
                
                # ì‹œê°„ì— ë”°ë¥¸ íˆìŠ¤í† ê·¸ë¨ ë³€í™”
                hist_variance = np.var(histograms, axis=0)
                hist_mean = np.mean(histograms, axis=0)
                hist_max = np.max(histograms, axis=0)
                hist_min = np.min(histograms, axis=0)
                
                # HSV ì±„ë„ë³„ ë¶„ì„
                bins = 16
                h_variance = hist_variance[:bins]
                s_variance = hist_variance[bins:2*bins]
                v_variance = hist_variance[2*bins:]
                
                h_mean = hist_mean[:bins]
                s_mean = hist_mean[bins:2*bins]
                v_mean = hist_mean[2*bins:]
                
                h_max = hist_max[:bins]
                s_max = hist_max[bins:2*bins]
                v_max = hist_max[2*bins:]
                
                print(f"   ğŸ“Š ì „ì²´ íˆìŠ¤í† ê·¸ë¨ í†µê³„:")
                print(f"      - ë¶„ì‚° (í‰ê· ): {np.mean(hist_variance):.6f}")
                print(f"      - ë¶„ì‚° (ìµœëŒ€): {np.max(hist_variance):.6f}")
                print(f"      - ë¶„ì‚° (ìµœì†Œ): {np.min(hist_variance):.6f}")
                print(f"      - ë¶„ì‚° (í‘œì¤€í¸ì°¨): {np.std(hist_variance):.6f}")
                
                print(f"   ğŸ¨ HSV ì±„ë„ë³„ ë¶„ì‚° ë¶„ì„:")
                print(f"      - Hue ë¶„ì‚° (í‰ê· ): {np.mean(h_variance):.6f}")
                print(f"      - Saturation ë¶„ì‚° (í‰ê· ): {np.mean(s_variance):.6f}")
                print(f"      - Value ë¶„ì‚° (í‰ê· ): {np.mean(v_variance):.6f}")
                
                print(f"   ğŸ“ˆ HSV ì±„ë„ë³„ í‰ê· ê°’:")
                print(f"      - Hue í‰ê· : {np.mean(h_mean):.4f}")
                print(f"      - Saturation í‰ê· : {np.mean(s_mean):.4f}")
                print(f"      - Value í‰ê· : {np.mean(v_mean):.4f}")
                
                print(f"   ğŸ”¥ HSV ì±„ë„ë³„ ìµœëŒ€ê°’:")
                print(f"      - Hue ìµœëŒ€: {np.max(h_max):.4f}")
                print(f"      - Saturation ìµœëŒ€: {np.max(s_max):.4f}")
                print(f"      - Value ìµœëŒ€: {np.max(v_max):.4f}")
                
                # ì•ˆì •ì„± í‰ê°€
                stability_score = 1.0 - np.mean(hist_variance)
                print(f"   ğŸ¯ ì•ˆì •ì„± í‰ê°€:")
                print(f"      - ì „ì²´ ì•ˆì •ì„± ì ìˆ˜: {stability_score:.4f}")
                print(f"      - Hue ì•ˆì •ì„±: {1.0 - np.mean(h_variance):.4f}")
                print(f"      - Saturation ì•ˆì •ì„±: {1.0 - np.mean(s_variance):.4f}")
                print(f"      - Value ì•ˆì •ì„±: {1.0 - np.mean(v_variance):.4f}")
                
                # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
                first_hist = histograms[0]
                last_hist = histograms[-1]
                metrics = self.calculate_similarity_metrics(first_hist, last_hist)
                print(f"   ğŸ”„ ì²«-ë§ˆì§€ë§‰ í”„ë ˆì„ ë¹„êµ:")
                print(f"      - Bhattacharyya ê±°ë¦¬: {metrics['bhattacharyya']:.4f}")
                print(f"      - ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {metrics['cosine_similarity']:.4f}")
                print(f"      - ìƒê´€ê³„ìˆ˜: {metrics['correlation']:.4f}")
                print(f"      - ì¢…í•© ìœ ì‚¬ë„: {max(1.0 - metrics['bhattacharyya'], metrics['cosine_similarity']):.4f}")
                
                # íŠ¸ë˜í‚¹ ì§€ì† ê°€ëŠ¥ì„± í‰ê°€
                if stability_score > 0.8:
                    tracking_assessment = "ğŸŸ¢ ë§¤ìš° ì•ˆì •ì  - ì¥ê¸° íŠ¸ë˜í‚¹ ê°€ëŠ¥"
                elif stability_score > 0.6:
                    tracking_assessment = "ğŸŸ¡ ë³´í†µ ì•ˆì •ì  - ì¤‘ê¸° íŠ¸ë˜í‚¹ ê°€ëŠ¥"
                elif stability_score > 0.4:
                    tracking_assessment = "ğŸŸ  ë¶ˆì•ˆì • - ë‹¨ê¸° íŠ¸ë˜í‚¹ë§Œ ê°€ëŠ¥"
                else:
                    tracking_assessment = "ğŸ”´ ë§¤ìš° ë¶ˆì•ˆì • - íŠ¸ë˜í‚¹ ì–´ë ¤ì›€"
                
                print(f"   ğŸ¯ íŠ¸ë˜í‚¹ ì§€ì† ê°€ëŠ¥ì„±: {tracking_assessment}")
                
                # ì—°ì†ì„± ë¶„ì„
                consecutive_similarities = []
                for i in range(1, len(histograms)):
                    prev_hist = histograms[i-1]
                    curr_hist = histograms[i]
                    metrics = self.calculate_similarity_metrics(prev_hist, curr_hist)
                    similarity = max(1.0 - metrics['bhattacharyya'], metrics['cosine_similarity'])
                    consecutive_similarities.append(similarity)
                
                if consecutive_similarities:
                    print(f"   ğŸ“Š ì—°ì† í”„ë ˆì„ ìœ ì‚¬ë„:")
                    print(f"      - í‰ê· : {np.mean(consecutive_similarities):.4f}")
                    print(f"      - ìµœì†Œ: {np.min(consecutive_similarities):.4f}")
                    print(f"      - ìµœëŒ€: {np.max(consecutive_similarities):.4f}")
                    print(f"      - í‘œì¤€í¸ì°¨: {np.std(consecutive_similarities):.4f}")

if __name__ == "__main__":
    analyzer = HSVAnalyzer()
    
    analyzer.run_analysis(duration_seconds=60)