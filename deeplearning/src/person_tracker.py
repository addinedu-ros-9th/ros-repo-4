import cv2
import numpy as np
import torch
from ultralytics import YOLO
from collections import deque
import threading
import queue
import time
import gc
import os

from shared_models import get_shared_seg_model, SEG_MODEL_LOCK

# ìºì‹œ ë¹„ìš°ê¸° ì˜µì…˜
CLEAR_CACHE_AFTER_INFERENCE = os.environ.get("CLEAR_CACHE_AFTER_INFERENCE", "0").lower() == "1"

def free_cuda_cache():
    if torch.cuda.is_available():
        try:
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
        except Exception:
            pass

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# GPU ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì • (PersonTrackerìš© 40%)
if torch.cuda.is_available():
    try:
        total_memory = torch.cuda.get_device_properties(0).total_memory
        person_tracker_memory = int(total_memory * 0.4)
        torch.cuda.set_per_process_memory_fraction(0.4, 0)  # 40% ì œí•œ
        print(f"ğŸ® PersonTracker GPU ë©”ëª¨ë¦¬ ì œí•œ: {person_tracker_memory / 1024**3:.1f}GB")
    except Exception as e:
        print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì • ì‹¤íŒ¨: {e}")


def estimate_distance(bbox_height, ref_height=300, ref_distance=1.0):
    distance = ref_height / (bbox_height + 1e-6) * ref_distance
    return round(distance, 2)

def estimate_distance_from_mask(mask, ref_height=300, ref_distance=1.0):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•œ ë” ì •í™•í•œ ê±°ë¦¬ ê³„ì‚°"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        cnt = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(cnt)
        person_height = h
        distance = ref_height / (person_height + 1e-6) * ref_distance
        return round(distance, 2)
    
    return 2.0

def estimate_distance_advanced(mask, ref_height=300, ref_distance=1.0):
    """ê³ ê¸‰ ê±°ë¦¬ ê³„ì‚° - ë§ˆìŠ¤í¬ì˜ ì‹¤ì œ í”½ì…€ ìˆ˜ì™€ í˜•íƒœ ê³ ë ¤"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        cnt = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(cnt)
        person_pixels = cv2.contourArea(cnt)
        bbox_area = w * h
        density = person_pixels / (bbox_area + 1e-6)
        adjusted_height = h * density
        distance = ref_height / (adjusted_height + 1e-6) * ref_distance
        
        return round(distance, 2), {
            'person_height': h,
            'person_pixels': person_pixels,
            'bbox_area': bbox_area,
            'density': density,
            'adjusted_height': adjusted_height
        }
    
    return 2.0, {}


class PersonTracker:
    def __init__(self):
        # YOLO ëª¨ë¸ ì´ˆê¸°í™” â†’ ê³µìœ  ëª¨ë¸ ì‚¬ìš©
        self.model = get_shared_seg_model()
        self.model_lock = SEG_MODEL_LOCK
        
        # ì‚¬ëŒ ì¬ì‹ë³„ ë°ì´í„°
        self.people_data = {}
        self.next_id = 0
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.process_every_n_frames = 1  # 3 â†’ 1ë¡œ ë³€ê²½ (ë§¤ í”„ë ˆì„ ì²˜ë¦¬)
        self.frame_skip_counter = 0
        
        # ë§¤ì¹­ ê´€ë ¨ ì„¤ì • (ë² ì´ì§€ìƒ‰/ê²€ì •ìƒ‰ êµ¬ë¶„ ê°•í™”)
        self.match_threshold = 0.60  # 0.65 â†’ 0.60ë¡œ ì™„í™”
        self.reentry_threshold = 0.55  # 0.60 â†’ 0.55ë¡œ ì™„í™”
        self.min_detection_confidence = 0.45  # 0.6 â†’ 0.45ë¡œ ì™„í™”
        self.min_person_area = 3000  # 5000 â†’ 3000ìœ¼ë¡œ ì™„í™”
        self.max_frames_without_seen = 300
        
        # íˆìŠ¤í† ê·¸ë¨ ê¸°ì–µ ì„¤ì • (ë” ë§ì€ íˆìŠ¤í† ê·¸ë¨ ì €ì¥)
        self.max_histograms_per_person = 25  # 20 â†’ 25ë¡œ ì¦ê°€ (ë” ë§ì€ ìƒ˜í”Œ)
        self.histogram_memory_duration = 30
        
        # ìŠ¤ë ˆë“œ ì„¤ì • (gesture_recognizerì™€ ì¼ê´€ì„±)
        self.frame_queue = queue.Queue(maxsize=1)  # 3 â†’ 1ë¡œ ì¤„ì—¬ì„œ ì§€ì—° ìµœì†Œí™”
        self.running = True
        self.lock = threading.Lock()
        
        # ê²°ê³¼ ì €ì¥
        self.latest_detections = []
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬
        self.last_memory_cleanup = time.time()
        self.memory_cleanup_interval = 30.0  # 10 â†’ 30ì´ˆë¡œ ëŠ˜ë¦¼ (ì •ë¦¬ ë¹ˆë„ ê°ì†Œ)
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ìë™ ì‹œì‘
        self.worker_thread = threading.Thread(target=self.tracking_worker)
        self.worker_thread.start()
        
        print("âœ… Person Tracker ì´ˆê¸°í™” ì™„ë£Œ")
    
    def cleanup_gpu_memory(self):
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if torch.cuda.is_available():
            try:
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                gc.collect()
                
                # ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                if hasattr(self, '_cleanup_count'):
                    self._cleanup_count += 1
                else:
                    self._cleanup_count = 0
                
                # 5ë²ˆë§ˆë‹¤ í•œ ë²ˆë§Œ ë¡œê·¸ ì¶œë ¥ (ë¹ˆë„ ê°ì†Œ)
                if self._cleanup_count % 5 == 0:
                    allocated = torch.cuda.memory_allocated() / 1024**2
                    reserved = torch.cuda.memory_reserved() / 1024**2
                    print(f"ğŸ§¹ PersonTracker GPU ë©”ëª¨ë¦¬ ì •ë¦¬: {allocated:.1f}MB í• ë‹¹, {reserved:.1f}MB ì˜ˆì•½")
            except Exception as e:
                print(f"GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def tracking_worker(self):
        """ì‚¬ëŒ ì¶”ì  ì›Œì»¤"""
        while self.running:
            try:
                frame_data = self.frame_queue.get(timeout=1.0)
                if frame_data is None:
                    continue
                
                frame, frame_id, elapsed_time = frame_data
                
                # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                current_time = time.time()
                if current_time - self.last_memory_cleanup > self.memory_cleanup_interval:
                    self.cleanup_gpu_memory()
                    self.last_memory_cleanup = current_time
                
                # YOLO ê°ì§€ (ê³µìœ  ëª¨ë¸ ë½ìœ¼ë¡œ ì§ë ¬í™”)
                with self.model_lock:
                    infer_device = 0 if torch.cuda.is_available() else 'cpu'
                    results = self.model(frame, imgsz=640, device=infer_device, verbose=False)
                if CLEAR_CACHE_AFTER_INFERENCE:
                    free_cuda_cache()
                
                current_detections = []
                current_detection_ids = set()  # í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ IDë“¤
                
                if results[0].masks is not None:
                    for i, (mask, box) in enumerate(zip(results[0].masks.data, results[0].boxes.data)):
                        if results[0].names[int(box[5])] == 'person':
                            confidence = box[4].item()
                            if confidence >= self.min_detection_confidence:
                                x1, y1, x2, y2 = map(int, box[:4])
                                area = (x2 - x1) * (y2 - y1)
                                
                                if area >= self.min_person_area:
                                    # íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
                                    mask_np = mask.cpu().numpy().astype(np.uint8)
                                    combined_hist, _, _, _ = self.extract_histogram(frame, mask_np)
                                    
                                    # ë§¤ì¹­ ì‹œë„
                                    bbox = [x1, y1, x2, y2]
                                    best_match_id, best_score, metrics = self.find_best_match(
                                        combined_hist, bbox, [], elapsed_time
                                    )
                                    
                                    # ê³µê°„ì  ì œì•½ ì¶”ê°€ (ë°”ìš´ë”© ë°•ìŠ¤ê°€ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ ìƒˆë¡œìš´ ì‚¬ëŒ)
                                    spatial_constraint_passed = True
                                    if best_match_id is not None and best_match_id in self.people_data:
                                        latest_bbox = self.people_data[best_match_id]['bboxes'][-1]
                                        current_center = ((x1 + x2) // 2, (y1 + y2) // 2)
                                        stored_center = ((latest_bbox[0] + latest_bbox[2]) // 2, (latest_bbox[1] + latest_bbox[3]) // 2)
                                        center_distance = np.sqrt((current_center[0] - stored_center[0])**2 + 
                                                                 (current_center[1] - stored_center[1])**2)
                                        
                                        # 100í”½ì…€ ì´ìƒ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ ìƒˆë¡œìš´ ì‚¬ëŒìœ¼ë¡œ ì²˜ë¦¬
                                        if center_distance > 100:
                                            spatial_constraint_passed = False
                                            if frame_id % 30 == 0:
                                                print(f"ğŸ“ ê³µê°„ì  ì œì•½ ì‹¤íŒ¨: {best_match_id} (ê±°ë¦¬: {center_distance:.1f}í”½ì…€)")
                                    
                                    # ë§¤ì¹­ ì¡°ê±´ì„ ë” ì—„ê²©í•˜ê²Œ ì„¤ì •
                                    if (best_match_id is not None and 
                                        best_score > self.match_threshold and
                                        metrics.get('hist_score', 0) > 0.4 and
                                        spatial_constraint_passed):  # ê³µê°„ì  ì œì•½ë„ ì²´í¬
                                        
                                        # ê¸°ì¡´ ì‚¬ëŒ ë§¤ì¹­
                                        person_id = best_match_id
                                        
                                        # ë§¤ì¹­ ë””ë²„ê¹… (30í”„ë ˆì„ë§ˆë‹¤)
                                        if frame_id % 180 == 0:  # 30 â†’ 180ìœ¼ë¡œ ëŠ˜ë¦¼
                                            print(f"ğŸ”„ ê¸°ì¡´ ì‚¬ëŒ ë§¤ì¹­: {person_id} (ì ìˆ˜: {best_score:.3f})")
                                            print(f"   - íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜: {metrics.get('hist_score', 0):.3f}")
                                            print(f"   - ë§¤ì¹­ ì„ê³„ê°’: {self.match_threshold}")
                                    else:
                                        # ìƒˆë¡œìš´ ì‚¬ëŒ (ë§¤ì¹­ ì‹¤íŒ¨ ë˜ëŠ” ì„ê³„ê°’ ë¯¸ë‹¬)
                                        person_id = f"Person_{self.next_id}"
                                        self.next_id += 1
                                        self.people_data[person_id] = {
                                            'histograms': [],
                                            'bboxes': [],
                                            'timestamps': []
                                        }
                                        
                                        # ë§¤ì¹­ ì‹¤íŒ¨ ë””ë²„ê¹… (30í”„ë ˆì„ë§ˆë‹¤)
                                        if frame_id % 180 == 0:  # 30 â†’ 180ìœ¼ë¡œ ëŠ˜ë¦¼
                                            if best_match_id is not None:
                                                print(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {best_match_id} (ì ìˆ˜: {best_score:.3f} < ì„ê³„ê°’: {self.match_threshold})")
                                                print(f"   - íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜: {metrics.get('hist_score', 0):.3f}")
                                                if not spatial_constraint_passed:
                                                    print(f"   - ê³µê°„ì  ì œì•½ ì‹¤íŒ¨")
                                            else:
                                                print(f"ğŸ†• ìƒˆë¡œìš´ ì‚¬ëŒ ë“±ë¡: {person_id} (ë§¤ì¹­ ê°€ëŠ¥í•œ ì‚¬ëŒ ì—†ìŒ)")
                                    
                                    # ë°ì´í„° ì—…ë°ì´íŠ¸
                                    self.people_data[person_id]['histograms'].append(combined_hist)
                                    self.people_data[person_id]['bboxes'].append(bbox)
                                    self.people_data[person_id]['timestamps'].append(elapsed_time)
                                    
                                    # íˆìŠ¤í† ê·¸ë¨ ê°œìˆ˜ ì œí•œ
                                    if len(self.people_data[person_id]['histograms']) > self.max_histograms_per_person:
                                        self.people_data[person_id]['histograms'].pop(0)
                                        self.people_data[person_id]['bboxes'].pop(0)
                                        self.people_data[person_id]['timestamps'].pop(0)
                                    
                                    current_detections.append({
                                        'id': person_id,
                                        'bbox': bbox,
                                        'confidence': confidence,
                                        'score': best_score if best_match_id else 0.0
                                    })
                                    
                                    current_detection_ids.add(person_id)
                
                # ì‚¬ë¼ì§„ ì‚¬ëŒ ì •ë¦¬ (í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ë˜ì§€ ì•Šì€ ì‚¬ëŒë“¤)
                people_to_remove = []
                for person_id in list(self.people_data.keys()):
                    if person_id not in current_detection_ids:
                        # ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„ í™•ì¸
                        if person_id in self.people_data and self.people_data[person_id]['timestamps']:
                            last_seen = self.people_data[person_id]['timestamps'][-1]
                            time_since_last_seen = elapsed_time - last_seen
                            
                            # ì¼ì • ì‹œê°„ ì´ìƒ ì‚¬ë¼ì§„ ì‚¬ëŒ ì œê±°
                            if time_since_last_seen > 10.0:  # 10ì´ˆ ì´ìƒ ì‚¬ë¼ì§€ë©´ ì œê±°
                                people_to_remove.append(person_id)
                                if frame_id % 30 == 0:
                                    print(f"ğŸ—‘ï¸ ì‚¬ë¼ì§„ ì‚¬ëŒ ì œê±°: {person_id} (ë§ˆì§€ë§‰ ê°ì§€: {time_since_last_seen:.1f}ì´ˆ ì „)")
                
                # ì‚¬ë¼ì§„ ì‚¬ëŒ ë°ì´í„° ì •ë¦¬
                for person_id in people_to_remove:
                    del self.people_data[person_id]
                
                # ê²°ê³¼ ì €ì¥
                with self.lock:
                    self.latest_detections = current_detections
                
                self.frame_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"PersonTracker ì›Œì»¤ ì˜¤ë¥˜: {e}")
                continue
    
    def get_latest_detections(self):
        """ìµœì‹  ê°ì§€ ê²°ê³¼ ë°˜í™˜"""
        with self.lock:
            return self.latest_detections.copy()
    
    def add_frame(self, frame, frame_id, elapsed_time):
        """í”„ë ˆì„ ì¶”ê°€ (ë¹„ë™ê¸°)"""
        try:
            self.frame_queue.put_nowait((frame, frame_id, elapsed_time))
        except queue.Full:
            pass
    
    def extract_histogram(self, img, mask, bins=16):
        """HSVì˜ ëª¨ë“  ì±„ë„(H, S, V)ì„ ê³ ë ¤í•œ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # ì „ì²´ ë§ˆìŠ¤í¬ì—ì„œ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
        h_hist = cv2.calcHist([hsv], [0], mask, [bins], [0, 180])
        s_hist = cv2.calcHist([hsv], [1], mask, [bins], [0, 256])
        v_hist = cv2.calcHist([hsv], [2], mask, [bins], [0, 256])
        
        # ìƒì²´ ë¶€ë¶„ (ë¨¸ë¦¬/ëª¨ì/ìƒì˜)ì— ì§‘ì¤‘í•œ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            cnt = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(cnt)
            
            # ìƒì²´ ë¶€ë¶„ ë§ˆìŠ¤í¬ ìƒì„± (ì „ì²´ ë†’ì´ì˜ ìƒìœ„ 60%)
            upper_mask = np.zeros_like(mask)
            upper_y = y + int(h * 0.6)  # ìƒìœ„ 60% ë¶€ë¶„
            upper_mask[y:upper_y, x:x+w] = mask[y:upper_y, x:x+w]
            
            # ìƒì²´ ë¶€ë¶„ íˆìŠ¤í† ê·¸ë¨
            h_hist_upper = cv2.calcHist([hsv], [0], upper_mask, [bins], [0, 180])
            s_hist_upper = cv2.calcHist([hsv], [1], upper_mask, [bins], [0, 256])
            v_hist_upper = cv2.calcHist([hsv], [2], upper_mask, [bins], [0, 256])
        else:
            h_hist_upper = h_hist.copy()
            s_hist_upper = s_hist.copy()
            v_hist_upper = v_hist.copy()
        
        # ì •ê·œí™”
        h_hist = cv2.normalize(h_hist, h_hist).flatten()
        s_hist = cv2.normalize(s_hist, s_hist).flatten()
        v_hist = cv2.normalize(v_hist, v_hist).flatten()
        
        h_hist_upper = cv2.normalize(h_hist_upper, h_hist_upper).flatten()
        s_hist_upper = cv2.normalize(s_hist_upper, s_hist_upper).flatten()
        v_hist_upper = cv2.normalize(v_hist_upper, v_hist_upper).flatten()
        
        # ì „ì²´ + ìƒì²´ íˆìŠ¤í† ê·¸ë¨ ê²°í•© (ìƒì²´ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        combined_hist = np.concatenate([
            h_hist * 0.3, s_hist * 0.3, v_hist * 0.3,  # ì „ì²´ (30%)
            h_hist_upper * 0.7, s_hist_upper * 0.7, v_hist_upper * 0.7  # ìƒì²´ (70%)
        ])
        
        return combined_hist, h_hist, s_hist, v_hist
    
    def calculate_similarity_metrics(self, hist1, hist2):
        """ë‹¤ì–‘í•œ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        bhatt_dist = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_BHATTACHARYYA)
        
        dot_product = np.dot(hist1, hist2)
        norm1 = np.linalg.norm(hist1)
        norm2 = np.linalg.norm(hist2)
        cosine_sim = dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0.0
        
        corr = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CORREL)
        chi_square = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CHISQR)
        intersection = cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_INTERSECT)
        
        return {
            'bhattacharyya': bhatt_dist,
            'cosine_similarity': cosine_sim,
            'correlation': corr,
            'chi_square': chi_square,
            'intersection': intersection
        }
    
    def find_best_match(self, current_hist, current_bbox, used_ids, elapsed_time=0.0):
        """ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ëŒ ì°¾ê¸° (ê°œì„ ëœ ë²„ì „)"""
        best_match_id = None
        best_score = 0.0
        best_metrics = {}
        
        x1, y1, x2, y2 = current_bbox
        current_center = ((x1 + x2) // 2, (y1 + y2) // 2)
        current_area = (x2 - x1) * (y2 - y1)
        
        for pid, pdata in self.people_data.items():
            if pid in used_ids:
                continue
                
            if len(pdata['histograms']) == 0:
                continue
            
            # 1. íˆìŠ¤í† ê·¸ë¨ ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¥ ì¤‘ìš”)
            hist_scores = []
            for i, stored_hist in enumerate(pdata['histograms'][-self.max_histograms_per_person:]):
                metrics = self.calculate_similarity_metrics(current_hist, stored_hist)
                # Bhattacharyya ê±°ë¦¬ì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ëª¨ë‘ ê³ ë ¤
                hist_score = max(1.0 - metrics['bhattacharyya'], metrics['cosine_similarity'])
                hist_scores.append(hist_score)
            
            # ìµœê³  íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜ (ê°€ì¥ ìœ ì‚¬í•œ íˆìŠ¤í† ê·¸ë¨ ì‚¬ìš©)
            best_hist_score = max(hist_scores) if hist_scores else 0.0
            
            # 2. ê³µê°„ì  ìœ ì‚¬ë„ ê³„ì‚°
            latest_bbox = pdata['bboxes'][-1]
            stored_center = ((latest_bbox[0] + latest_bbox[2]) // 2, (latest_bbox[1] + latest_bbox[3]) // 2)
            stored_area = (latest_bbox[2] - latest_bbox[0]) * (latest_bbox[3] - latest_bbox[1])
            
            # ì¤‘ì‹¬ì  ê±°ë¦¬
            center_distance = np.sqrt((current_center[0] - stored_center[0])**2 + 
                                     (current_center[1] - stored_center[1])**2)
            max_distance = np.sqrt(640**2 + 480**2)
            spatial_score = 1.0 - (center_distance / max_distance)
            
            # 3. í¬ê¸° ìœ ì‚¬ë„ (ì‚¬ëŒì´ ê°‘ìê¸° í¬ê²Œ ë³€í•˜ì§€ ì•ŠìŒ)
            area_ratio = min(current_area, stored_area) / max(current_area, stored_area)
            size_score = area_ratio
            
            # 4. ì‹œê°„ì  ì—°ì†ì„± (ìµœê·¼ì— ë³¸ ì‚¬ëŒì—ê²Œ ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            if pdata['timestamps']:
                time_since_last_seen = elapsed_time - pdata['timestamps'][-1]
                time_score = max(0.0, 1.0 - (time_since_last_seen / 10.0))  # 10ì´ˆ ë‚´ì— ë³¸ ì‚¬ëŒì—ê²Œ ë†’ì€ ì ìˆ˜
            else:
                time_score = 0.0
            
            # 5. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì¡°ì •)
            total_score = (
                0.7 * best_hist_score +      # íˆìŠ¤í† ê·¸ë¨ (ê°€ì¥ ì¤‘ìš”)
                0.15 * spatial_score +       # ê³µê°„ì  ìœ„ì¹˜
                0.1 * size_score +           # í¬ê¸° ìœ ì‚¬ë„
                0.05 * time_score            # ì‹œê°„ì  ì—°ì†ì„±
            )
            
            # 6. ìµœì†Œ ì„ê³„ê°’ ê²€ì‚¬ (íˆìŠ¤í† ê·¸ë¨ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì œì™¸)
            if best_hist_score < 0.40:  # 0.35 â†’ 0.40ë¡œ ì¦ê°€ (ë² ì´ì§€ìƒ‰/ê²€ì •ìƒ‰ êµ¬ë¶„ ê°•í™”)
                continue
            
            # 7. ë” ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ë§¤ì¹­ ì„ íƒ
            if total_score > best_score:
                best_score = total_score
                best_match_id = pid
                best_metrics = {
                    'hist_score': best_hist_score,
                    'spatial_score': spatial_score,
                    'size_score': size_score,
                    'time_score': time_score,
                    'hist_scores': hist_scores
                }
        
        return best_match_id, best_score, best_metrics
    
    def start(self):
        """ì¶”ì ê¸° ì‹œì‘"""
        print("ğŸš€ Person Tracker ì‹œì‘")
    
    def stop(self):
        """ì¶”ì ê¸° ì¤‘ì§€"""
        self.running = False
        try:
            self.frame_queue.put_nowait(None)
        except queue.Full:
            pass
        if hasattr(self, 'worker_thread'):
            self.worker_thread.join()
        print("ğŸ›‘ Person Tracker ì¤‘ì§€")